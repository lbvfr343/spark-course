{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --driver-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# conf = SparkConf()\n",
    "# conf.set(\"spark.app.name\", \"Sergey Grishaev Spark Dataframe app\")\n",
    "# sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark import SQLContext\n",
    "\n",
    "# sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Sergey Grishaev Spark Dataframe app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Sergey Grishaev Spark Dataframe app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-6.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sergey Grishaev Spark Dataframe app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb45ce605c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Session:\n",
    "\n",
    "    - Spark Context\n",
    "    - SQL Context\n",
    "    - Hive Context\n",
    "    - Streaming Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-6.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Sergey Grishaev Spark Dataframe app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=Sergey Grishaev Spark Dataframe app>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как создать DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочитать из внешнего источника"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.readwriter.DataFrameReader at 0x7fb450043c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline загрузки\n",
    "```python\n",
    "spark.read\\\n",
    "     .format(...)\\\n",
    "     .option(key, value)\\\n",
    "     .option(key, value)\\\n",
    "     .load(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|24|M|technician|85711\r\n",
      "2|53|F|other|94043\r\n",
      "3|23|M|writer|32067\r\n",
      "4|24|M|technician|43537\r\n",
      "5|33|F|other|15213\r\n",
      "6|42|M|executive|98101\r\n",
      "7|57|M|administrator|91344\r\n",
      "8|36|M|administrator|05201\r\n",
      "9|29|M|student|01002\r\n",
      "10|53|M|lawyer|90703\r\n",
      "11|39|F|other|30329\r\n",
      "12|28|F|other|06405\r\n",
      "13|47|M|educator|29206\r\n",
      "14|45|M|scientist|55106\r\n",
      "15|49|F|educator|97301\r\n",
      "16|21|M|entertainment|10309\r\n",
      "17|30|M|programmer|06355\r\n",
      "18|35|F|other|37212\r\n",
      "19|40|M|librarian|02138\r\n",
      "20|42|F|homemaker|95660\r\n",
      "21|26|M|writer|30068\r\n",
      "22|25|M|writer|40206\r\n",
      "23|30|F|artist|48197\r\n",
      "24|21|F|artist|94533\r\n",
      "25|39|M|engineer|55107\r\n",
      "26|49|M|engineer|21044\r\n",
      "27|40|F|librarian|30030\r\n",
      "28|32|M|writer|55369\r\n",
      "29|41|M|programmer|94043\r\n",
      "30|7|M|student|55436\r\n",
      "31|24|M|artist|10003\r\n",
      "32|28|F|student|78741\r\n",
      "33|23|M|student|27510\r\n",
      "34|38|F|administrator|42141\r\n",
      "35|20|F|homemaker|42459\r\n",
      "36|19|F|student|93117\r\n",
      "37|23|M|student|55105\r\n",
      "38|28|F|other|54467\r\n",
      "39|41|M|entertainment|01040\r\n",
      "40|38|M|scientist|27514\r\n",
      "41|33|M|engineer|80525\r\n",
      "42|30|M|administrator|17870\r\n",
      "43|29|F|librarian|20854\r\n",
      "44|26|M|technician|46260\r\n",
      "45|29|M|programmer|50233\r\n",
      "46|27|F|marketing|46538\r\n",
      "47|53|M|marketing|07102\r\n",
      "48|45|M|administrator|12550\r\n",
      "49|23|F|student|76111\r\n",
      "50|21|M|writer|52245\r\n",
      "51|28|M|educator|16509\r\n",
      "52|18|F|student|55105\r\n",
      "53|26|M|programmer|55414\r\n",
      "54|22|M|executive|66315\r\n",
      "55|37|M|programmer|01331\r\n",
      "56|25|M|librarian|46260\r\n",
      "57|16|M|none|84010\r\n",
      "58|27|M|programmer|52246\r\n",
      "59|49|M|educator|08403\r\n",
      "60|50|M|healthcare|06472\r\n",
      "61|36|M|engineer|30040\r\n",
      "62|27|F|administrator|97214\r\n",
      "63|31|M|marketing|75240\r\n",
      "64|32|M|educator|43202\r\n",
      "65|51|F|educator|48118\r\n",
      "66|23|M|student|80521\r\n",
      "67|17|M|student|60402\r\n",
      "68|19|M|student|22904\r\n",
      "69|24|M|engineer|55337\r\n",
      "70|27|M|engineer|60067\r\n",
      "71|39|M|scientist|98034\r\n",
      "72|48|F|administrator|73034\r\n",
      "73|24|M|student|41850\r\n",
      "74|39|M|scientist|T8H1N\r\n",
      "75|24|M|entertainment|08816\r\n",
      "76|20|M|student|02215\r\n",
      "77|30|M|technician|29379\r\n",
      "78|26|M|administrator|61801\r\n",
      "79|39|F|administrator|03755\r\n",
      "80|34|F|administrator|52241\r\n",
      "81|21|M|student|21218\r\n",
      "82|50|M|programmer|22902\r\n",
      "83|40|M|other|44133\r\n",
      "84|32|M|executive|55369\r\n",
      "85|51|M|educator|20003\r\n",
      "86|26|M|administrator|46005\r\n",
      "87|47|M|administrator|89503\r\n",
      "88|49|F|librarian|11701\r\n",
      "89|43|F|administrator|68106\r\n",
      "90|60|M|educator|78155\r\n",
      "91|55|M|marketing|01913\r\n",
      "92|32|M|entertainment|80525\r\n",
      "93|48|M|executive|23112\r\n",
      "94|26|M|student|71457\r\n",
      "95|31|M|administrator|10707\r\n",
      "96|25|F|artist|75206\r\n",
      "97|43|M|artist|98006\r\n",
      "98|49|F|executive|90291\r\n",
      "99|20|M|student|63129\r\n",
      "100|36|M|executive|90254\r\n",
      "101|15|M|student|05146\r\n",
      "102|38|M|programmer|30220\r\n",
      "103|26|M|student|55108\r\n",
      "104|27|M|student|55108\r\n",
      "105|24|M|engineer|94043\r\n",
      "106|61|M|retired|55125\r\n",
      "107|39|M|scientist|60466\r\n",
      "108|44|M|educator|63130\r\n",
      "109|29|M|other|55423\r\n",
      "110|19|M|student|77840\r\n",
      "111|57|M|engineer|90630\r\n",
      "112|30|M|salesman|60613\r\n",
      "113|47|M|executive|95032\r\n",
      "114|27|M|programmer|75013\r\n",
      "115|31|M|engineer|17110\r\n",
      "116|40|M|healthcare|97232\r\n",
      "117|20|M|student|16125\r\n",
      "118|21|M|administrator|90210\r\n",
      "119|32|M|programmer|67401\r\n",
      "120|47|F|other|06260\r\n",
      "121|54|M|librarian|99603\r\n",
      "122|32|F|writer|22206\r\n",
      "123|48|F|artist|20008\r\n",
      "124|34|M|student|60615\r\n",
      "125|30|M|lawyer|22202\r\n",
      "126|28|F|lawyer|20015\r\n",
      "127|33|M|none|73439\r\n",
      "128|24|F|marketing|20009\r\n",
      "129|36|F|marketing|07039\r\n",
      "130|20|M|none|60115\r\n",
      "131|59|F|administrator|15237\r\n",
      "132|24|M|other|94612\r\n",
      "133|53|M|engineer|78602\r\n",
      "134|31|M|programmer|80236\r\n",
      "135|23|M|student|38401\r\n",
      "136|51|M|other|97365\r\n",
      "137|50|M|educator|84408\r\n",
      "138|46|M|doctor|53211\r\n",
      "139|20|M|student|08904\r\n",
      "140|30|F|student|32250\r\n",
      "141|49|M|programmer|36117\r\n",
      "142|13|M|other|48118\r\n",
      "143|42|M|technician|08832\r\n",
      "144|53|M|programmer|20910\r\n",
      "145|31|M|entertainment|V3N4P\r\n",
      "146|45|M|artist|83814\r\n",
      "147|40|F|librarian|02143\r\n",
      "148|33|M|engineer|97006\r\n",
      "149|35|F|marketing|17325\r\n",
      "150|20|F|artist|02139\r\n",
      "151|38|F|administrator|48103\r\n",
      "152|33|F|educator|68767\r\n",
      "153|25|M|student|60641\r\n",
      "154|25|M|student|53703\r\n",
      "155|32|F|other|11217\r\n",
      "156|25|M|educator|08360\r\n",
      "157|57|M|engineer|70808\r\n",
      "158|50|M|educator|27606\r\n",
      "159|23|F|student|55346\r\n",
      "160|27|M|programmer|66215\r\n",
      "161|50|M|lawyer|55104\r\n",
      "162|25|M|artist|15610\r\n",
      "163|49|M|administrator|97212\r\n",
      "164|47|M|healthcare|80123\r\n",
      "165|20|F|other|53715\r\n",
      "166|47|M|educator|55113\r\n",
      "167|37|M|other|L9G2B\r\n",
      "168|48|M|other|80127\r\n",
      "169|52|F|other|53705\r\n",
      "170|53|F|healthcare|30067\r\n",
      "171|48|F|educator|78750\r\n",
      "172|55|M|marketing|22207\r\n",
      "173|56|M|other|22306\r\n",
      "174|30|F|administrator|52302\r\n",
      "175|26|F|scientist|21911\r\n",
      "176|28|M|scientist|07030\r\n",
      "177|20|M|programmer|19104\r\n",
      "178|26|M|other|49512\r\n",
      "179|15|M|entertainment|20755\r\n",
      "180|22|F|administrator|60202\r\n",
      "181|26|M|executive|21218\r\n",
      "182|36|M|programmer|33884\r\n",
      "183|33|M|scientist|27708\r\n",
      "184|37|M|librarian|76013\r\n",
      "185|53|F|librarian|97403\r\n",
      "186|39|F|executive|00000\r\n",
      "187|26|M|educator|16801\r\n",
      "188|42|M|student|29440\r\n",
      "189|32|M|artist|95014\r\n",
      "190|30|M|administrator|95938\r\n",
      "191|33|M|administrator|95161\r\n",
      "192|42|M|educator|90840\r\n",
      "193|29|M|student|49931\r\n",
      "194|38|M|administrator|02154\r\n",
      "195|42|M|scientist|93555\r\n",
      "196|49|M|writer|55105\r\n",
      "197|55|M|technician|75094\r\n",
      "198|21|F|student|55414\r\n",
      "199|30|M|writer|17604\r\n",
      "200|40|M|programmer|93402\r\n",
      "201|27|M|writer|E2A4H\r\n",
      "202|41|F|educator|60201\r\n",
      "203|25|F|student|32301\r\n",
      "204|52|F|librarian|10960\r\n",
      "205|47|M|lawyer|06371\r\n",
      "206|14|F|student|53115\r\n",
      "207|39|M|marketing|92037\r\n",
      "208|43|M|engineer|01720\r\n",
      "209|33|F|educator|85710\r\n",
      "210|39|M|engineer|03060\r\n",
      "211|66|M|salesman|32605\r\n",
      "212|49|F|educator|61401\r\n",
      "213|33|M|executive|55345\r\n",
      "214|26|F|librarian|11231\r\n",
      "215|35|M|programmer|63033\r\n",
      "216|22|M|engineer|02215\r\n",
      "217|22|M|other|11727\r\n",
      "218|37|M|administrator|06513\r\n",
      "219|32|M|programmer|43212\r\n",
      "220|30|M|librarian|78205\r\n",
      "221|19|M|student|20685\r\n",
      "222|29|M|programmer|27502\r\n",
      "223|19|F|student|47906\r\n",
      "224|31|F|educator|43512\r\n",
      "225|51|F|administrator|58202\r\n",
      "226|28|M|student|92103\r\n",
      "227|46|M|executive|60659\r\n",
      "228|21|F|student|22003\r\n",
      "229|29|F|librarian|22903\r\n",
      "230|28|F|student|14476\r\n",
      "231|48|M|librarian|01080\r\n",
      "232|45|M|scientist|99709\r\n",
      "233|38|M|engineer|98682\r\n",
      "234|60|M|retired|94702\r\n",
      "235|37|M|educator|22973\r\n",
      "236|44|F|writer|53214\r\n",
      "237|49|M|administrator|63146\r\n",
      "238|42|F|administrator|44124\r\n",
      "239|39|M|artist|95628\r\n",
      "240|23|F|educator|20784\r\n",
      "241|26|F|student|20001\r\n",
      "242|33|M|educator|31404\r\n",
      "243|33|M|educator|60201\r\n",
      "244|28|M|technician|80525\r\n",
      "245|22|M|student|55109\r\n",
      "246|19|M|student|28734\r\n",
      "247|28|M|engineer|20770\r\n",
      "248|25|M|student|37235\r\n",
      "249|25|M|student|84103\r\n",
      "250|29|M|executive|95110\r\n",
      "251|28|M|doctor|85032\r\n",
      "252|42|M|engineer|07733\r\n",
      "253|26|F|librarian|22903\r\n",
      "254|44|M|educator|42647\r\n",
      "255|23|M|entertainment|07029\r\n",
      "256|35|F|none|39042\r\n",
      "257|17|M|student|77005\r\n",
      "258|19|F|student|77801\r\n",
      "259|21|M|student|48823\r\n",
      "260|40|F|artist|89801\r\n",
      "261|28|M|administrator|85202\r\n",
      "262|19|F|student|78264\r\n",
      "263|41|M|programmer|55346\r\n",
      "264|36|F|writer|90064\r\n",
      "265|26|M|executive|84601\r\n",
      "266|62|F|administrator|78756\r\n",
      "267|23|M|engineer|83716\r\n",
      "268|24|M|engineer|19422\r\n",
      "269|31|F|librarian|43201\r\n",
      "270|18|F|student|63119\r\n",
      "271|51|M|engineer|22932\r\n",
      "272|33|M|scientist|53706\r\n",
      "273|50|F|other|10016\r\n",
      "274|20|F|student|55414\r\n",
      "275|38|M|engineer|92064\r\n",
      "276|21|M|student|95064\r\n",
      "277|35|F|administrator|55406\r\n",
      "278|37|F|librarian|30033\r\n",
      "279|33|M|programmer|85251\r\n",
      "280|30|F|librarian|22903\r\n",
      "281|15|F|student|06059\r\n",
      "282|22|M|administrator|20057\r\n",
      "283|28|M|programmer|55305\r\n",
      "284|40|M|executive|92629\r\n",
      "285|25|M|programmer|53713\r\n",
      "286|27|M|student|15217\r\n",
      "287|21|M|salesman|31211\r\n",
      "288|34|M|marketing|23226\r\n",
      "289|11|M|none|94619\r\n",
      "290|40|M|engineer|93550\r\n",
      "291|19|M|student|44106\r\n",
      "292|35|F|programmer|94703\r\n",
      "293|24|M|writer|60804\r\n",
      "294|34|M|technician|92110\r\n",
      "295|31|M|educator|50325\r\n",
      "296|43|F|administrator|16803\r\n",
      "297|29|F|educator|98103\r\n",
      "298|44|M|executive|01581\r\n",
      "299|29|M|doctor|63108\r\n",
      "300|26|F|programmer|55106\r\n",
      "301|24|M|student|55439\r\n",
      "302|42|M|educator|77904\r\n",
      "303|19|M|student|14853\r\n",
      "304|22|F|student|71701\r\n",
      "305|23|M|programmer|94086\r\n",
      "306|45|M|other|73132\r\n",
      "307|25|M|student|55454\r\n",
      "308|60|M|retired|95076\r\n",
      "309|40|M|scientist|70802\r\n",
      "310|37|M|educator|91711\r\n",
      "311|32|M|technician|73071\r\n",
      "312|48|M|other|02110\r\n",
      "313|41|M|marketing|60035\r\n",
      "314|20|F|student|08043\r\n",
      "315|31|M|educator|18301\r\n",
      "316|43|F|other|77009\r\n",
      "317|22|M|administrator|13210\r\n",
      "318|65|M|retired|06518\r\n",
      "319|38|M|programmer|22030\r\n",
      "320|19|M|student|24060\r\n",
      "321|49|F|educator|55413\r\n",
      "322|20|M|student|50613\r\n",
      "323|21|M|student|19149\r\n",
      "324|21|F|student|02176\r\n",
      "325|48|M|technician|02139\r\n",
      "326|41|M|administrator|15235\r\n",
      "327|22|M|student|11101\r\n",
      "328|51|M|administrator|06779\r\n",
      "329|48|M|educator|01720\r\n",
      "330|35|F|educator|33884\r\n",
      "331|33|M|entertainment|91344\r\n",
      "332|20|M|student|40504\r\n",
      "333|47|M|other|V0R2M\r\n",
      "334|32|M|librarian|30002\r\n",
      "335|45|M|executive|33775\r\n",
      "336|23|M|salesman|42101\r\n",
      "337|37|M|scientist|10522\r\n",
      "338|39|F|librarian|59717\r\n",
      "339|35|M|lawyer|37901\r\n",
      "340|46|M|engineer|80123\r\n",
      "341|17|F|student|44405\r\n",
      "342|25|F|other|98006\r\n",
      "343|43|M|engineer|30093\r\n",
      "344|30|F|librarian|94117\r\n",
      "345|28|F|librarian|94143\r\n",
      "346|34|M|other|76059\r\n",
      "347|18|M|student|90210\r\n",
      "348|24|F|student|45660\r\n",
      "349|68|M|retired|61455\r\n",
      "350|32|M|student|97301\r\n",
      "351|61|M|educator|49938\r\n",
      "352|37|F|programmer|55105\r\n",
      "353|25|M|scientist|28480\r\n",
      "354|29|F|librarian|48197\r\n",
      "355|25|M|student|60135\r\n",
      "356|32|F|homemaker|92688\r\n",
      "357|26|M|executive|98133\r\n",
      "358|40|M|educator|10022\r\n",
      "359|22|M|student|61801\r\n",
      "360|51|M|other|98027\r\n",
      "361|22|M|student|44074\r\n",
      "362|35|F|homemaker|85233\r\n",
      "363|20|M|student|87501\r\n",
      "364|63|M|engineer|01810\r\n",
      "365|29|M|lawyer|20009\r\n",
      "366|20|F|student|50670\r\n",
      "367|17|M|student|37411\r\n",
      "368|18|M|student|92113\r\n",
      "369|24|M|student|91335\r\n",
      "370|52|M|writer|08534\r\n",
      "371|36|M|engineer|99206\r\n",
      "372|25|F|student|66046\r\n",
      "373|24|F|other|55116\r\n",
      "374|36|M|executive|78746\r\n",
      "375|17|M|entertainment|37777\r\n",
      "376|28|F|other|10010\r\n",
      "377|22|M|student|18015\r\n",
      "378|35|M|student|02859\r\n",
      "379|44|M|programmer|98117\r\n",
      "380|32|M|engineer|55117\r\n",
      "381|33|M|artist|94608\r\n",
      "382|45|M|engineer|01824\r\n",
      "383|42|M|administrator|75204\r\n",
      "384|52|M|programmer|45218\r\n",
      "385|36|M|writer|10003\r\n",
      "386|36|M|salesman|43221\r\n",
      "387|33|M|entertainment|37412\r\n",
      "388|31|M|other|36106\r\n",
      "389|44|F|writer|83702\r\n",
      "390|42|F|writer|85016\r\n",
      "391|23|M|student|84604\r\n",
      "392|52|M|writer|59801\r\n",
      "393|19|M|student|83686\r\n",
      "394|25|M|administrator|96819\r\n",
      "395|43|M|other|44092\r\n",
      "396|57|M|engineer|94551\r\n",
      "397|17|M|student|27514\r\n",
      "398|40|M|other|60008\r\n",
      "399|25|M|other|92374\r\n",
      "400|33|F|administrator|78213\r\n",
      "401|46|F|healthcare|84107\r\n",
      "402|30|M|engineer|95129\r\n",
      "403|37|M|other|06811\r\n",
      "404|29|F|programmer|55108\r\n",
      "405|22|F|healthcare|10019\r\n",
      "406|52|M|educator|93109\r\n",
      "407|29|M|engineer|03261\r\n",
      "408|23|M|student|61755\r\n",
      "409|48|M|administrator|98225\r\n",
      "410|30|F|artist|94025\r\n",
      "411|34|M|educator|44691\r\n",
      "412|25|M|educator|15222\r\n",
      "413|55|M|educator|78212\r\n",
      "414|24|M|programmer|38115\r\n",
      "415|39|M|educator|85711\r\n",
      "416|20|F|student|92626\r\n",
      "417|27|F|other|48103\r\n",
      "418|55|F|none|21206\r\n",
      "419|37|M|lawyer|43215\r\n",
      "420|53|M|educator|02140\r\n",
      "421|38|F|programmer|55105\r\n",
      "422|26|M|entertainment|94533\r\n",
      "423|64|M|other|91606\r\n",
      "424|36|F|marketing|55422\r\n",
      "425|19|M|student|58644\r\n",
      "426|55|M|educator|01602\r\n",
      "427|51|M|doctor|85258\r\n",
      "428|28|M|student|55414\r\n",
      "429|27|M|student|29205\r\n",
      "430|38|M|scientist|98199\r\n",
      "431|24|M|marketing|92629\r\n",
      "432|22|M|entertainment|50311\r\n",
      "433|27|M|artist|11211\r\n",
      "434|16|F|student|49705\r\n",
      "435|24|M|engineer|60007\r\n",
      "436|30|F|administrator|17345\r\n",
      "437|27|F|other|20009\r\n",
      "438|51|F|administrator|43204\r\n",
      "439|23|F|administrator|20817\r\n",
      "440|30|M|other|48076\r\n",
      "441|50|M|technician|55013\r\n",
      "442|22|M|student|85282\r\n",
      "443|35|M|salesman|33308\r\n",
      "444|51|F|lawyer|53202\r\n",
      "445|21|M|writer|92653\r\n",
      "446|57|M|educator|60201\r\n",
      "447|30|M|administrator|55113\r\n",
      "448|23|M|entertainment|10021\r\n",
      "449|23|M|librarian|55021\r\n",
      "450|35|F|educator|11758\r\n",
      "451|16|M|student|48446\r\n",
      "452|35|M|administrator|28018\r\n",
      "453|18|M|student|06333\r\n",
      "454|57|M|other|97330\r\n",
      "455|48|M|administrator|83709\r\n",
      "456|24|M|technician|31820\r\n",
      "457|33|F|salesman|30011\r\n",
      "458|47|M|technician|Y1A6B\r\n",
      "459|22|M|student|29201\r\n",
      "460|44|F|other|60630\r\n",
      "461|15|M|student|98102\r\n",
      "462|19|F|student|02918\r\n",
      "463|48|F|healthcare|75218\r\n",
      "464|60|M|writer|94583\r\n",
      "465|32|M|other|05001\r\n",
      "466|22|M|student|90804\r\n",
      "467|29|M|engineer|91201\r\n",
      "468|28|M|engineer|02341\r\n",
      "469|60|M|educator|78628\r\n",
      "470|24|M|programmer|10021\r\n",
      "471|10|M|student|77459\r\n",
      "472|24|M|student|87544\r\n",
      "473|29|M|student|94708\r\n",
      "474|51|M|executive|93711\r\n",
      "475|30|M|programmer|75230\r\n",
      "476|28|M|student|60440\r\n",
      "477|23|F|student|02125\r\n",
      "478|29|M|other|10019\r\n",
      "479|30|M|educator|55409\r\n",
      "480|57|M|retired|98257\r\n",
      "481|73|M|retired|37771\r\n",
      "482|18|F|student|40256\r\n",
      "483|29|M|scientist|43212\r\n",
      "484|27|M|student|21208\r\n",
      "485|44|F|educator|95821\r\n",
      "486|39|M|educator|93101\r\n",
      "487|22|M|engineer|92121\r\n",
      "488|48|M|technician|21012\r\n",
      "489|55|M|other|45218\r\n",
      "490|29|F|artist|V5A2B\r\n",
      "491|43|F|writer|53711\r\n",
      "492|57|M|educator|94618\r\n",
      "493|22|M|engineer|60090\r\n",
      "494|38|F|administrator|49428\r\n",
      "495|29|M|engineer|03052\r\n",
      "496|21|F|student|55414\r\n",
      "497|20|M|student|50112\r\n",
      "498|26|M|writer|55408\r\n",
      "499|42|M|programmer|75006\r\n",
      "500|28|M|administrator|94305\r\n",
      "501|22|M|student|10025\r\n",
      "502|22|M|student|23092\r\n",
      "503|50|F|writer|27514\r\n",
      "504|40|F|writer|92115\r\n",
      "505|27|F|other|20657\r\n",
      "506|46|M|programmer|03869\r\n",
      "507|18|F|writer|28450\r\n",
      "508|27|M|marketing|19382\r\n",
      "509|23|M|administrator|10011\r\n",
      "510|34|M|other|98038\r\n",
      "511|22|M|student|21250\r\n",
      "512|29|M|other|20090\r\n",
      "513|43|M|administrator|26241\r\n",
      "514|27|M|programmer|20707\r\n",
      "515|53|M|marketing|49508\r\n",
      "516|53|F|librarian|10021\r\n",
      "517|24|M|student|55454\r\n",
      "518|49|F|writer|99709\r\n",
      "519|22|M|other|55320\r\n",
      "520|62|M|healthcare|12603\r\n",
      "521|19|M|student|02146\r\n",
      "522|36|M|engineer|55443\r\n",
      "523|50|F|administrator|04102\r\n",
      "524|56|M|educator|02159\r\n",
      "525|27|F|administrator|19711\r\n",
      "526|30|M|marketing|97124\r\n",
      "527|33|M|librarian|12180\r\n",
      "528|18|M|student|55104\r\n",
      "529|47|F|administrator|44224\r\n",
      "530|29|M|engineer|94040\r\n",
      "531|30|F|salesman|97408\r\n",
      "532|20|M|student|92705\r\n",
      "533|43|M|librarian|02324\r\n",
      "534|20|M|student|05464\r\n",
      "535|45|F|educator|80302\r\n",
      "536|38|M|engineer|30078\r\n",
      "537|36|M|engineer|22902\r\n",
      "538|31|M|scientist|21010\r\n",
      "539|53|F|administrator|80303\r\n",
      "540|28|M|engineer|91201\r\n",
      "541|19|F|student|84302\r\n",
      "542|21|M|student|60515\r\n",
      "543|33|M|scientist|95123\r\n",
      "544|44|F|other|29464\r\n",
      "545|27|M|technician|08052\r\n",
      "546|36|M|executive|22911\r\n",
      "547|50|M|educator|14534\r\n",
      "548|51|M|writer|95468\r\n",
      "549|42|M|scientist|45680\r\n",
      "550|16|F|student|95453\r\n",
      "551|25|M|programmer|55414\r\n",
      "552|45|M|other|68147\r\n",
      "553|58|M|educator|62901\r\n",
      "554|32|M|scientist|62901\r\n",
      "555|29|F|educator|23227\r\n",
      "556|35|F|educator|30606\r\n",
      "557|30|F|writer|11217\r\n",
      "558|56|F|writer|63132\r\n",
      "559|69|M|executive|10022\r\n",
      "560|32|M|student|10003\r\n",
      "561|23|M|engineer|60005\r\n",
      "562|54|F|administrator|20879\r\n",
      "563|39|F|librarian|32707\r\n",
      "564|65|M|retired|94591\r\n",
      "565|40|M|student|55422\r\n",
      "566|20|M|student|14627\r\n",
      "567|24|M|entertainment|10003\r\n",
      "568|39|M|educator|01915\r\n",
      "569|34|M|educator|91903\r\n",
      "570|26|M|educator|14627\r\n",
      "571|34|M|artist|01945\r\n",
      "572|51|M|educator|20003\r\n",
      "573|68|M|retired|48911\r\n",
      "574|56|M|educator|53188\r\n",
      "575|33|M|marketing|46032\r\n",
      "576|48|M|executive|98281\r\n",
      "577|36|F|student|77845\r\n",
      "578|31|M|administrator|M7A1A\r\n",
      "579|32|M|educator|48103\r\n",
      "580|16|M|student|17961\r\n",
      "581|37|M|other|94131\r\n",
      "582|17|M|student|93003\r\n",
      "583|44|M|engineer|29631\r\n",
      "584|25|M|student|27511\r\n",
      "585|69|M|librarian|98501\r\n",
      "586|20|M|student|79508\r\n",
      "587|26|M|other|14216\r\n",
      "588|18|F|student|93063\r\n",
      "589|21|M|lawyer|90034\r\n",
      "590|50|M|educator|82435\r\n",
      "591|57|F|librarian|92093\r\n",
      "592|18|M|student|97520\r\n",
      "593|31|F|educator|68767\r\n",
      "594|46|M|educator|M4J2K\r\n",
      "595|25|M|programmer|31909\r\n",
      "596|20|M|artist|77073\r\n",
      "597|23|M|other|84116\r\n",
      "598|40|F|marketing|43085\r\n",
      "599|22|F|student|R3T5K\r\n",
      "600|34|M|programmer|02320\r\n",
      "601|19|F|artist|99687\r\n",
      "602|47|F|other|34656\r\n",
      "603|21|M|programmer|47905\r\n",
      "604|39|M|educator|11787\r\n",
      "605|33|M|engineer|33716\r\n",
      "606|28|M|programmer|63044\r\n",
      "607|49|F|healthcare|02154\r\n",
      "608|22|M|other|10003\r\n",
      "609|13|F|student|55106\r\n",
      "610|22|M|student|21227\r\n",
      "611|46|M|librarian|77008\r\n",
      "612|36|M|educator|79070\r\n",
      "613|37|F|marketing|29678\r\n",
      "614|54|M|educator|80227\r\n",
      "615|38|M|educator|27705\r\n",
      "616|55|M|scientist|50613\r\n",
      "617|27|F|writer|11201\r\n",
      "618|15|F|student|44212\r\n",
      "619|17|M|student|44134\r\n",
      "620|18|F|writer|81648\r\n",
      "621|17|M|student|60402\r\n",
      "622|25|M|programmer|14850\r\n",
      "623|50|F|educator|60187\r\n",
      "624|19|M|student|30067\r\n",
      "625|27|M|programmer|20723\r\n",
      "626|23|M|scientist|19807\r\n",
      "627|24|M|engineer|08034\r\n",
      "628|13|M|none|94306\r\n",
      "629|46|F|other|44224\r\n",
      "630|26|F|healthcare|55408\r\n",
      "631|18|F|student|38866\r\n",
      "632|18|M|student|55454\r\n",
      "633|35|M|programmer|55414\r\n",
      "634|39|M|engineer|T8H1N\r\n",
      "635|22|M|other|23237\r\n",
      "636|47|M|educator|48043\r\n",
      "637|30|M|other|74101\r\n",
      "638|45|M|engineer|01940\r\n",
      "639|42|F|librarian|12065\r\n",
      "640|20|M|student|61801\r\n",
      "641|24|M|student|60626\r\n",
      "642|18|F|student|95521\r\n",
      "643|39|M|scientist|55122\r\n",
      "644|51|M|retired|63645\r\n",
      "645|27|M|programmer|53211\r\n",
      "646|17|F|student|51250\r\n",
      "647|40|M|educator|45810\r\n",
      "648|43|M|engineer|91351\r\n",
      "649|20|M|student|39762\r\n",
      "650|42|M|engineer|83814\r\n",
      "651|65|M|retired|02903\r\n",
      "652|35|M|other|22911\r\n",
      "653|31|M|executive|55105\r\n",
      "654|27|F|student|78739\r\n",
      "655|50|F|healthcare|60657\r\n",
      "656|48|M|educator|10314\r\n",
      "657|26|F|none|78704\r\n",
      "658|33|M|programmer|92626\r\n",
      "659|31|M|educator|54248\r\n",
      "660|26|M|student|77380\r\n",
      "661|28|M|programmer|98121\r\n",
      "662|55|M|librarian|19102\r\n",
      "663|26|M|other|19341\r\n",
      "664|30|M|engineer|94115\r\n",
      "665|25|M|administrator|55412\r\n",
      "666|44|M|administrator|61820\r\n",
      "667|35|M|librarian|01970\r\n",
      "668|29|F|writer|10016\r\n",
      "669|37|M|other|20009\r\n",
      "670|30|M|technician|21114\r\n",
      "671|21|M|programmer|91919\r\n",
      "672|54|F|administrator|90095\r\n",
      "673|51|M|educator|22906\r\n",
      "674|13|F|student|55337\r\n",
      "675|34|M|other|28814\r\n",
      "676|30|M|programmer|32712\r\n",
      "677|20|M|other|99835\r\n",
      "678|50|M|educator|61462\r\n",
      "679|20|F|student|54302\r\n",
      "680|33|M|lawyer|90405\r\n",
      "681|44|F|marketing|97208\r\n",
      "682|23|M|programmer|55128\r\n",
      "683|42|M|librarian|23509\r\n",
      "684|28|M|student|55414\r\n",
      "685|32|F|librarian|55409\r\n",
      "686|32|M|educator|26506\r\n",
      "687|31|F|healthcare|27713\r\n",
      "688|37|F|administrator|60476\r\n",
      "689|25|M|other|45439\r\n",
      "690|35|M|salesman|63304\r\n",
      "691|34|M|educator|60089\r\n",
      "692|34|M|engineer|18053\r\n",
      "693|43|F|healthcare|85210\r\n",
      "694|60|M|programmer|06365\r\n",
      "695|26|M|writer|38115\r\n",
      "696|55|M|other|94920\r\n",
      "697|25|M|other|77042\r\n",
      "698|28|F|programmer|06906\r\n",
      "699|44|M|other|96754\r\n",
      "700|17|M|student|76309\r\n",
      "701|51|F|librarian|56321\r\n",
      "702|37|M|other|89104\r\n",
      "703|26|M|educator|49512\r\n",
      "704|51|F|librarian|91105\r\n",
      "705|21|F|student|54494\r\n",
      "706|23|M|student|55454\r\n",
      "707|56|F|librarian|19146\r\n",
      "708|26|F|homemaker|96349\r\n",
      "709|21|M|other|N4T1A\r\n",
      "710|19|M|student|92020\r\n",
      "711|22|F|student|15203\r\n",
      "712|22|F|student|54901\r\n",
      "713|42|F|other|07204\r\n",
      "714|26|M|engineer|55343\r\n",
      "715|21|M|technician|91206\r\n",
      "716|36|F|administrator|44265\r\n",
      "717|24|M|technician|84105\r\n",
      "718|42|M|technician|64118\r\n",
      "719|37|F|other|V0R2H\r\n",
      "720|49|F|administrator|16506\r\n",
      "721|24|F|entertainment|11238\r\n",
      "722|50|F|homemaker|17331\r\n",
      "723|26|M|executive|94403\r\n",
      "724|31|M|executive|40243\r\n",
      "725|21|M|student|91711\r\n",
      "726|25|F|administrator|80538\r\n",
      "727|25|M|student|78741\r\n",
      "728|58|M|executive|94306\r\n",
      "729|19|M|student|56567\r\n",
      "730|31|F|scientist|32114\r\n",
      "731|41|F|educator|70403\r\n",
      "732|28|F|other|98405\r\n",
      "733|44|F|other|60630\r\n",
      "734|25|F|other|63108\r\n",
      "735|29|F|healthcare|85719\r\n",
      "736|48|F|writer|94618\r\n",
      "737|30|M|programmer|98072\r\n",
      "738|35|M|technician|95403\r\n",
      "739|35|M|technician|73162\r\n",
      "740|25|F|educator|22206\r\n",
      "741|25|M|writer|63108\r\n",
      "742|35|M|student|29210\r\n",
      "743|31|M|programmer|92660\r\n",
      "744|35|M|marketing|47024\r\n",
      "745|42|M|writer|55113\r\n",
      "746|25|M|engineer|19047\r\n",
      "747|19|M|other|93612\r\n",
      "748|28|M|administrator|94720\r\n",
      "749|33|M|other|80919\r\n",
      "750|28|M|administrator|32303\r\n",
      "751|24|F|other|90034\r\n",
      "752|60|M|retired|21201\r\n",
      "753|56|M|salesman|91206\r\n",
      "754|59|F|librarian|62901\r\n",
      "755|44|F|educator|97007\r\n",
      "756|30|F|none|90247\r\n",
      "757|26|M|student|55104\r\n",
      "758|27|M|student|53706\r\n",
      "759|20|F|student|68503\r\n",
      "760|35|F|other|14211\r\n",
      "761|17|M|student|97302\r\n",
      "762|32|M|administrator|95050\r\n",
      "763|27|M|scientist|02113\r\n",
      "764|27|F|educator|62903\r\n",
      "765|31|M|student|33066\r\n",
      "766|42|M|other|10960\r\n",
      "767|70|M|engineer|00000\r\n",
      "768|29|M|administrator|12866\r\n",
      "769|39|M|executive|06927\r\n",
      "770|28|M|student|14216\r\n",
      "771|26|M|student|15232\r\n",
      "772|50|M|writer|27105\r\n",
      "773|20|M|student|55414\r\n",
      "774|30|M|student|80027\r\n",
      "775|46|M|executive|90036\r\n",
      "776|30|M|librarian|51157\r\n",
      "777|63|M|programmer|01810\r\n",
      "778|34|M|student|01960\r\n",
      "779|31|M|student|K7L5J\r\n",
      "780|49|M|programmer|94560\r\n",
      "781|20|M|student|48825\r\n",
      "782|21|F|artist|33205\r\n",
      "783|30|M|marketing|77081\r\n",
      "784|47|M|administrator|91040\r\n",
      "785|32|M|engineer|23322\r\n",
      "786|36|F|engineer|01754\r\n",
      "787|18|F|student|98620\r\n",
      "788|51|M|administrator|05779\r\n",
      "789|29|M|other|55420\r\n",
      "790|27|M|technician|80913\r\n",
      "791|31|M|educator|20064\r\n",
      "792|40|M|programmer|12205\r\n",
      "793|22|M|student|85281\r\n",
      "794|32|M|educator|57197\r\n",
      "795|30|M|programmer|08610\r\n",
      "796|32|F|writer|33755\r\n",
      "797|44|F|other|62522\r\n",
      "798|40|F|writer|64131\r\n",
      "799|49|F|administrator|19716\r\n",
      "800|25|M|programmer|55337\r\n",
      "801|22|M|writer|92154\r\n",
      "802|35|M|administrator|34105\r\n",
      "803|70|M|administrator|78212\r\n",
      "804|39|M|educator|61820\r\n",
      "805|27|F|other|20009\r\n",
      "806|27|M|marketing|11217\r\n",
      "807|41|F|healthcare|93555\r\n",
      "808|45|M|salesman|90016\r\n",
      "809|50|F|marketing|30803\r\n",
      "810|55|F|other|80526\r\n",
      "811|40|F|educator|73013\r\n",
      "812|22|M|technician|76234\r\n",
      "813|14|F|student|02136\r\n",
      "814|30|M|other|12345\r\n",
      "815|32|M|other|28806\r\n",
      "816|34|M|other|20755\r\n",
      "817|19|M|student|60152\r\n",
      "818|28|M|librarian|27514\r\n",
      "819|59|M|administrator|40205\r\n",
      "820|22|M|student|37725\r\n",
      "821|37|M|engineer|77845\r\n",
      "822|29|F|librarian|53144\r\n",
      "823|27|M|artist|50322\r\n",
      "824|31|M|other|15017\r\n",
      "825|44|M|engineer|05452\r\n",
      "826|28|M|artist|77048\r\n",
      "827|23|F|engineer|80228\r\n",
      "828|28|M|librarian|85282\r\n",
      "829|48|M|writer|80209\r\n",
      "830|46|M|programmer|53066\r\n",
      "831|21|M|other|33765\r\n",
      "832|24|M|technician|77042\r\n",
      "833|34|M|writer|90019\r\n",
      "834|26|M|other|64153\r\n",
      "835|44|F|executive|11577\r\n",
      "836|44|M|artist|10018\r\n",
      "837|36|F|artist|55409\r\n",
      "838|23|M|student|01375\r\n",
      "839|38|F|entertainment|90814\r\n",
      "840|39|M|artist|55406\r\n",
      "841|45|M|doctor|47401\r\n",
      "842|40|M|writer|93055\r\n",
      "843|35|M|librarian|44212\r\n",
      "844|22|M|engineer|95662\r\n",
      "845|64|M|doctor|97405\r\n",
      "846|27|M|lawyer|47130\r\n",
      "847|29|M|student|55417\r\n",
      "848|46|M|engineer|02146\r\n",
      "849|15|F|student|25652\r\n",
      "850|34|M|technician|78390\r\n",
      "851|18|M|other|29646\r\n",
      "852|46|M|administrator|94086\r\n",
      "853|49|M|writer|40515\r\n",
      "854|29|F|student|55408\r\n",
      "855|53|M|librarian|04988\r\n",
      "856|43|F|marketing|97215\r\n",
      "857|35|F|administrator|V1G4L\r\n",
      "858|63|M|educator|09645\r\n",
      "859|18|F|other|06492\r\n",
      "860|70|F|retired|48322\r\n",
      "861|38|F|student|14085\r\n",
      "862|25|M|executive|13820\r\n",
      "863|17|M|student|60089\r\n",
      "864|27|M|programmer|63021\r\n",
      "865|25|M|artist|11231\r\n",
      "866|45|M|other|60302\r\n",
      "867|24|M|scientist|92507\r\n",
      "868|21|M|programmer|55303\r\n",
      "869|30|M|student|10025\r\n",
      "870|22|M|student|65203\r\n",
      "871|31|M|executive|44648\r\n",
      "872|19|F|student|74078\r\n",
      "873|48|F|administrator|33763\r\n",
      "874|36|M|scientist|37076\r\n",
      "875|24|F|student|35802\r\n",
      "876|41|M|other|20902\r\n",
      "877|30|M|other|77504\r\n",
      "878|50|F|educator|98027\r\n",
      "879|33|F|administrator|55337\r\n",
      "880|13|M|student|83702\r\n",
      "881|39|M|marketing|43017\r\n",
      "882|35|M|engineer|40503\r\n",
      "883|49|M|librarian|50266\r\n",
      "884|44|M|engineer|55337\r\n",
      "885|30|F|other|95316\r\n",
      "886|20|M|student|61820\r\n",
      "887|14|F|student|27249\r\n",
      "888|41|M|scientist|17036\r\n",
      "889|24|M|technician|78704\r\n",
      "890|32|M|student|97301\r\n",
      "891|51|F|administrator|03062\r\n",
      "892|36|M|other|45243\r\n",
      "893|25|M|student|95823\r\n",
      "894|47|M|educator|74075\r\n",
      "895|31|F|librarian|32301\r\n",
      "896|28|M|writer|91505\r\n",
      "897|30|M|other|33484\r\n",
      "898|23|M|homemaker|61755\r\n",
      "899|32|M|other|55116\r\n",
      "900|60|M|retired|18505\r\n",
      "901|38|M|executive|L1V3W\r\n",
      "902|45|F|artist|97203\r\n",
      "903|28|M|educator|20850\r\n",
      "904|17|F|student|61073\r\n",
      "905|27|M|other|30350\r\n",
      "906|45|M|librarian|70124\r\n",
      "907|25|F|other|80526\r\n",
      "908|44|F|librarian|68504\r\n",
      "909|50|F|educator|53171\r\n",
      "910|28|M|healthcare|29301\r\n",
      "911|37|F|writer|53210\r\n",
      "912|51|M|other|06512\r\n",
      "913|27|M|student|76201\r\n",
      "914|44|F|other|08105\r\n",
      "915|50|M|entertainment|60614\r\n",
      "916|27|M|engineer|N2L5N\r\n",
      "917|22|F|student|20006\r\n",
      "918|40|M|scientist|70116\r\n",
      "919|25|M|other|14216\r\n",
      "920|30|F|artist|90008\r\n",
      "921|20|F|student|98801\r\n",
      "922|29|F|administrator|21114\r\n",
      "923|21|M|student|E2E3R\r\n",
      "924|29|M|other|11753\r\n",
      "925|18|F|salesman|49036\r\n",
      "926|49|M|entertainment|01701\r\n",
      "927|23|M|programmer|55428\r\n",
      "928|21|M|student|55408\r\n",
      "929|44|M|scientist|53711\r\n",
      "930|28|F|scientist|07310\r\n",
      "931|60|M|educator|33556\r\n",
      "932|58|M|educator|06437\r\n",
      "933|28|M|student|48105\r\n",
      "934|61|M|engineer|22902\r\n",
      "935|42|M|doctor|66221\r\n",
      "936|24|M|other|32789\r\n",
      "937|48|M|educator|98072\r\n",
      "938|38|F|technician|55038\r\n",
      "939|26|F|student|33319\r\n",
      "940|32|M|administrator|02215\r\n",
      "941|20|M|student|97229\r\n",
      "942|48|F|librarian|78209\r\n",
      "943|22|M|student|77841\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /lectures/lecture02/data/ml-100k/u.user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"sep\", \"|\")\\\n",
    "          .load(\"/lectures/lecture02/data/ml-100k/u.user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------------+-----+\n",
      "|_c0|_c1|_c2|          _c3|  _c4|\n",
      "+---+---+---+-------------+-----+\n",
      "|  1| 24|  M|   technician|85711|\n",
      "|  2| 53|  F|        other|94043|\n",
      "|  3| 23|  M|       writer|32067|\n",
      "|  4| 24|  M|   technician|43537|\n",
      "|  5| 33|  F|        other|15213|\n",
      "|  6| 42|  M|    executive|98101|\n",
      "|  7| 57|  M|administrator|91344|\n",
      "|  8| 36|  M|administrator|05201|\n",
      "|  9| 29|  M|      student|01002|\n",
      "| 10| 53|  M|       lawyer|90703|\n",
      "+---+---+---+-------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "_c0: string, _c1: string, _c2: string, _c3: string, _c4: string\n",
      "Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Relation[_c0#10,_c1#11,_c2#12,_c3#13,_c4#14] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) FileScan csv [_c0#10,_c1#11,_c2#12,_c3#13,_c4#14] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ml-100k/u.user], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:string,_c1:string,_c2:string,_c3:string,_c4:string>\n"
     ]
    }
   ],
   "source": [
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='1', _c1='24', _c2='M', _c3='technician', _c4='85711'),\n",
       " Row(_c0='2', _c1='53', _c2='F', _c3='other', _c4='94043'),\n",
       " Row(_c0='3', _c1='23', _c2='M', _c3='writer', _c4='32067'),\n",
       " Row(_c0='4', _c1='24', _c2='M', _c3='technician', _c4='43537'),\n",
       " Row(_c0='5', _c1='33', _c2='F', _c3='other', _c4='15213')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"age\", IntegerType()),\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"occupation\", StringType()),\n",
    "    StructField(\"zip\", IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "          .schema(schema)\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"sep\", \"|\")\\\n",
    "          .load(\"/lectures/lecture02/data/ml-100k/u.user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, age: int, gender: string, occupation: string, zip: int]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- zip: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "|      3| 23|     M|    writer|32067|\n",
      "|      4| 24|     M|technician|43537|\n",
      "|      5| 33|     F|     other|15213|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+------+-------------+------------------+\n",
      "|summary|          user_id|              age|gender|   occupation|               zip|\n",
      "+-------+-----------------+-----------------+------+-------------+------------------+\n",
      "|  count|              925|              925|   925|          925|               925|\n",
      "|   mean|470.2908108108108|34.06054054054054|  null|         null| 50868.78810810811|\n",
      "| stddev|272.1030147185632|12.25807489536592|  null|         null|30891.373254138176|\n",
      "|    min|                1|                7|     F|administrator|                 0|\n",
      "|    25%|              236|               25|  null|         null|             21227|\n",
      "|    50%|              469|               31|  null|         null|             53711|\n",
      "|    75%|              705|               43|  null|         null|             78741|\n",
      "|    max|              943|               73|     M|       writer|             99835|\n",
      "+-------+-----------------+-----------------+------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Таким образом более приближенный к реальности pipeline выглядит как\n",
    "```python\n",
    "spark.read\\\n",
    "     .schema(schema)\\\n",
    "     .format(...)\\\n",
    "     .option(key, value)\\\n",
    "     .option(key, value)\\\n",
    "     .load(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Есть так же удобные wrapper'ы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/lectures/lecture02/data/ml-100k/u.user\", schema=schema, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, age: int, gender: string, occupation: string, zip: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "|      3| 23|     M|    writer|32067|\n",
      "|      4| 24|     M|technician|43537|\n",
      "|      5| 33|     F|     other|15213|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Много источников данных с унифицированным API!\n",
    "+ CSV\n",
    "+ JSON\n",
    "+ Hive\n",
    "+ HBase\n",
    "+ Cassandra\n",
    "+ MySQL\n",
    "+ PostgreSQL\n",
    "+ Parquet\n",
    "+ ORC\n",
    "+ Kafka\n",
    "+ ElasticSearch\n",
    "+ Amazon S3\n",
    "+ ...и еще больше через custom connectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим DataFrame из RDD, pandas.DataFrame или из list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"/lectures/lecture02/data/ml-100k/u.user\").map(lambda x: x.split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '24', 'M', 'technician', '85711'],\n",
       " ['2', '53', 'F', 'other', '94043'],\n",
       " ['3', '23', 'M', 'writer', '32067'],\n",
       " ['4', '24', 'M', 'technician', '43537'],\n",
       " ['5', '33', 'F', 'other', '15213']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: string, _2: string, _3: string, _4: string, _5: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, age: int, gender: string, occupation: string, zip: int]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o176.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 12, spark-node-2.newprolab.com, executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 730, in prepare\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1370, in verify_struct\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1315, in verify_integer\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1278, in verify_acceptable_types\n    >>> _make_type_verifier(schema)((1, None)) # doctest: +IGNORE_EXCEPTION_DETAIL\nTypeError: field user_id: IntegerType can not accept object '1' in type <class 'str'>\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 730, in prepare\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1370, in verify_struct\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1315, in verify_integer\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1278, in verify_acceptable_types\n    >>> _make_type_verifier(schema)((1, None)) # doctest: +IGNORE_EXCEPTION_DETAIL\nTypeError: field user_id: IntegerType can not accept object '1' in type <class 'str'>\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-eb589bae8d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o176.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 4 times, most recent failure: Lost task 0.3 in stage 9.0 (TID 12, spark-node-2.newprolab.com, executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 730, in prepare\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1370, in verify_struct\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1315, in verify_integer\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1278, in verify_acceptable_types\n    >>> _make_type_verifier(schema)((1, None)) # doctest: +IGNORE_EXCEPTION_DETAIL\nTypeError: field user_id: IntegerType can not accept object '1' in type <class 'str'>\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3369)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 377, in main\n    process()\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/worker.py\", line 372, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/serializers.py\", line 400, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/hadoop/yarn/local/usercache/teacher2/appcache/application_1665123529459_0521/container_e20_1665123529459_0521_01_000004/pyspark.zip/pyspark/util.py\", line 99, in wrapper\n    return f(*args, **kwargs)\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\", line 730, in prepare\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1370, in verify_struct\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1389, in verify\n    if isinstance(obj, dict):\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1315, in verify_integer\n  File \"/usr/hdp/current/spark2-client/python/pyspark/sql/types.py\", line 1278, in verify_acceptable_types\n    >>> _make_type_verifier(schema)((1, None)) # doctest: +IGNORE_EXCEPTION_DETAIL\nTypeError: field user_id: IntegerType can not accept object '1' in type <class 'str'>\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:456)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:592)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:575)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:410)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Может быть с неправильными типами можно справится путем игнорирования верификации schema???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=schema, verifySchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+----------+----+\n",
      "|user_id| age|gender|occupation| zip|\n",
      "+-------+----+------+----------+----+\n",
      "|   null|null|     M|technician|null|\n",
      "|   null|null|     F|     other|null|\n",
      "|   null|null|     M|    writer|null|\n",
      "|   null|null|     M|technician|null|\n",
      "|   null|null|     F|     other|null|\n",
      "+-------+----+------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Не выходит требуется конвертировать в правильные типы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = rdd.map(lambda x: (int(x[0]), int(x[1]), x[2], x[3], int(x[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rdd, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+------+----------+-----+\n",
      "|user_id|age|gender|occupation|  zip|\n",
      "+-------+---+------+----------+-----+\n",
      "|      1| 24|     M|technician|85711|\n",
      "|      2| 53|     F|     other|94043|\n",
      "|      3| 23|     M|    writer|32067|\n",
      "|      4| 24|     M|technician|43537|\n",
      "|      5| 33|     F|     other|15213|\n",
      "+-------+---+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поработаем с искусственным access логом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x64; Trident/5.0; .NET CLR 3.5.30729;)\r",
      "\r\n",
      "247.182.249.253\t20140426165946\thttp://news.yandex.ru/7686791\t1560\t202\tOpera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)\r",
      "\r\n",
      "197.72.248.141\t20140426170846\thttp://news.yandex.ru/1949655\t1175\t404\tOpera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)\r",
      "\r\n",
      "168.146.187.80\t20140426171807\thttp://news.mail.ru/7107147\t1020\t434\tOpera/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)\r",
      "\r\n",
      "75.208.40.166\t20140426180003\thttp://news.yandex.ru/4696319\t526\t449\tSafari/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)\r",
      "\r\n",
      "33.49.147.163\t20140426182902\thttp://news.mail.ru/2829289\t82\t510\tOpera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729)\r",
      "\r\n",
      "33.49.147.163\t20140426191049\thttp://news.rambler.ru/4707594\t1043\t206\tOpera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -tail /lectures/lecture02/data/logsM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "\n",
    "log_schema = StructType(fields=[\n",
    "    StructField(\"ip\", StringType()),\n",
    "    StructField(\"timestamp\", LongType()),\n",
    "    StructField(\"url\", StringType()),\n",
    "    StructField(\"size\", IntegerType()),\n",
    "    StructField(\"code\", IntegerType()),\n",
    "    StructField(\"ua\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = spark.read.csv(\"/lectures/lecture02/data/logsM.txt\", sep=\"\\t\", schema=log_schema).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = log.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                                           \n",
      " timestamp | 20140112193801                                                                                                           \n",
      " url       | http://news.mail.ru/7703130                                                                                              \n",
      " size      | 903                                                                                                                      \n",
      " code      | 504                                                                                                                      \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)                          \n",
      "-RECORD 1-----------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 168.146.187.80                                                                                                           \n",
      " timestamp | 20140309090040                                                                                                           \n",
      " url       | http://news.rambler.ru/3165291                                                                                           \n",
      " size      | 773                                                                                                                      \n",
      " code      | 456                                                                                                                      \n",
      " ua        | Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729) \n",
      "-RECORD 2-----------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 33.49.147.163                                                                                                            \n",
      " timestamp | 20140410014351                                                                                                           \n",
      " url       | http://newsru.com/9238321                                                                                                \n",
      " size      | 1088                                                                                                                     \n",
      " code      | 409                                                                                                                      \n",
      " ua        | Chrome/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)                                       \n",
      "-RECORD 3-----------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 49.203.96.67                                                                                                             \n",
      " timestamp | 20140412120146                                                                                                           \n",
      " url       | http://news.rambler.ru/3775760                                                                                           \n",
      " size      | 1524                                                                                                                     \n",
      " code      | 302                                                                                                                      \n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)                          \n",
      "-RECORD 4-----------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 75.208.40.166                                                                                                            \n",
      " timestamp | 20140115235616                                                                                                           \n",
      " url       | http://news.rambler.ru/9936776                                                                                           \n",
      " size      | 911                                                                                                                      \n",
      " code      | 424                                                                                                                      \n",
      " ua        | Safari/5.0 (Windows; U; MSIE 9.0; Windows NT 8.0; Win64; x64; Trident/5.0; .NET4.0E; en)                                 \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.show(5, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projections и filters\n",
    "Projection - это подмножемтво колокнок\n",
    "\n",
    "Filter - это подмножество строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ip', 'timestamp', 'url', 'size', 'code', 'ua']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.schema.fieldNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.select([\"ip\", \"timestamp\", \"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------------+\n",
      "|             ip|     timestamp|                 url|\n",
      "+---------------+--------------+--------------------+\n",
      "|  75.208.40.166|20140210083843|http://news.rambl...|\n",
      "| 168.255.93.197|20140112215951|http://news.rambl...|\n",
      "|135.124.143.193|20140313110843|http://news.mail....|\n",
      "|  33.49.147.163|20140420043616|http://lenta.ru/4...|\n",
      "|   49.105.15.79|20140118143400|http://lenta.ru/2...|\n",
      "+---------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(*log.schema.fieldNames()[:3]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|   49.105.15.79| 101|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "| 231.119.88.198| 511|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ip\", \"code\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|   49.105.15.79| 101|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "| 231.119.88.198| 511|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(log.ip, log.code).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'ip'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|             ip|response|\n",
      "+---------------+--------+\n",
      "|   49.105.15.79|     101|\n",
      "|135.124.143.193|     303|\n",
      "|135.124.143.193|     303|\n",
      "|135.124.143.193|     303|\n",
      "| 231.119.88.198|     511|\n",
      "+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(log.ip,\n",
    "           log.code.alias(\"response\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|   49.105.15.79| 101|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "| 231.119.88.198| 511|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(f.col(\"ip\"), \n",
    "           f.col(\"code\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good ol' Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|   49.105.15.79| 101|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "|135.124.143.193| 303|\n",
      "| 231.119.88.198| 511|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log[[\"ip\", \"code\"]].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|             ip|response|\n",
      "+---------------+--------+\n",
      "|   49.105.15.79|     101|\n",
      "|135.124.143.193|     303|\n",
      "|135.124.143.193|     303|\n",
      "|135.124.143.193|     303|\n",
      "| 231.119.88.198|     511|\n",
      "+---------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log[[log.ip, log.code.alias(\"response\")]].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|197.72.248.141|20140404122749|http://newsru.com...| 884| 200|Opera/5.0 (compat...|\n",
      "| 75.208.40.166|20140120192527|http://lenta.ru/8...| 722| 200|Safari/5.0 (compa...|\n",
      "|197.72.248.141|20140403130026|http://news.yande...| 856| 200|Opera/5.0 (compat...|\n",
      "|222.131.187.37|20140213225235|http://lenta.ru/7...| 636| 200|Opera/5.0 (compat...|\n",
      "|   14.8.59.211|20140228022039|http://news.yande...|1296| 200|Opera/5.0 (Window...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.where(\"code = 200\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----------------------------+----+----+------------------------------------------------------------------------------------------------------------------------+\n",
      "|ip            |timestamp     |url                          |size|code|ua                                                                                                                      |\n",
      "+--------------+--------------+-----------------------------+----+----+------------------------------------------------------------------------------------------------------------------------+\n",
      "|197.72.248.141|20140404122749|http://newsru.com/7833710    |884 |200 |Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)                          |\n",
      "|75.208.40.166 |20140120192527|http://lenta.ru/8240100      |722 |200 |Safari/5.0 (compatible; MSIE 9.0; Windows NT 8.0; WOW64; Trident/5.0; .NET CLR 2.7.40781; .NET4.0E; en-SG)              |\n",
      "|197.72.248.141|20140403130026|http://news.yandex.ru/2010781|856 |200 |Opera/5.0 (compatible; MSIE 9.0; Windows NT 8.0; WOW64; Trident/5.0; .NET CLR 2.7.40781; .NET4.0E; en-SG)               |\n",
      "|222.131.187.37|20140213225235|http://lenta.ru/7685590      |636 |200 |Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 2.0.50727; SLCC2; .NET CLR 3.5.30729)|\n",
      "|14.8.59.211   |20140228022039|http://news.yandex.ru/4333042|1296|200 |Opera/5.0 (Windows; U; MSIE 9.0; Windows NT 8.1; Trident/5.0; .NET4.0E; en-AU)                                          |\n",
      "+--------------+--------------+-----------------------------+----+----+------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.filter(log.code == 200).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 75.208.40.166                                                                                                                 \n",
      " timestamp | 20140310132240                                                                                                                \n",
      " url       | http://news.rambler.ru/9308492                                                                                                \n",
      " size      | 1107                                                                                                                          \n",
      " code      | 200                                                                                                                           \n",
      " ua        | Opera/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)                                \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 33.49.147.163                                                                                                                 \n",
      " timestamp | 20140131095711                                                                                                                \n",
      " url       | http://news.rambler.ru/3828463                                                                                                \n",
      " size      | 1908                                                                                                                          \n",
      " code      | 200                                                                                                                           \n",
      " ua        | Safari/5.0 (Windows; U; MSIE 9.0; Windows NT 8.1; Trident/5.0; .NET4.0E; en-AU)                                               \n",
      "-RECORD 2----------------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 33.49.147.163                                                                                                                 \n",
      " timestamp | 20140106045941                                                                                                                \n",
      " url       | http://news.rambler.ru/1817681                                                                                                \n",
      " size      | 671                                                                                                                           \n",
      " code      | 200                                                                                                                           \n",
      " ua        | Firefox/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;)                              \n",
      "-RECORD 3----------------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 197.72.248.141                                                                                                                \n",
      " timestamp | 20140318114526                                                                                                                \n",
      " url       | http://news.rambler.ru/6538102                                                                                                \n",
      " size      | 258                                                                                                                           \n",
      " code      | 200                                                                                                                           \n",
      " ua        | Chrome/5.0 (Windows; U; MSIE 9.0; Windows NT 6.0; Win64; x64; Trident/5.0; .NET CLR 3.8.50799; Media Center PC 6.0; .NET4.0E) \n",
      "-RECORD 4----------------------------------------------------------------------------------------------------------------------------------\n",
      " ip        | 168.255.93.197                                                                                                                \n",
      " timestamp | 20140226235035                                                                                                                \n",
      " url       | http://news.rambler.ru/2826991                                                                                                \n",
      " size      | 1493                                                                                                                          \n",
      " code      | 200                                                                                                                           \n",
      " ua        | Opera/5.0 compatible; MSIE 9.0; Windows NT 7.0; Trident/5.0; .NET CLR 2.2.50767;)                                             \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.filter(\"code == 200 AND url LIKE '%rambler%'\").show(5, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|197.72.248.141|20140222074905|http://news.rambl...|1264| 200|Chrome/5.0 compat...|\n",
      "| 75.208.40.166|20140202002148|http://news.rambl...|1338| 404|Opera/5.0 (compat...|\n",
      "|197.72.248.141|20140210221913|http://news.rambl...|1654| 404|Safari/5.0 (Windo...|\n",
      "|  25.62.10.220|20140107010805|http://news.rambl...|1284| 200|Chrome/5.0 compat...|\n",
      "| 33.49.147.163|20140109101634|http://news.rambl...|1971| 404|Opera/5.0 (compat...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.filter((log.code.isin([200, 404])) & (log.url.like(\"%rambler%\"))).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good ol' Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "|            ip|     timestamp|                 url|size|code|                  ua|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "| 75.208.40.166|20140310132240|http://news.rambl...|1107| 200|Opera/5.0 (compat...|\n",
      "| 33.49.147.163|20140131095711|http://news.rambl...|1908| 200|Safari/5.0 (Windo...|\n",
      "| 33.49.147.163|20140106045941|http://news.rambl...| 671| 200|Firefox/5.0 (comp...|\n",
      "|197.72.248.141|20140318114526|http://news.rambl...| 258| 200|Chrome/5.0 (Windo...|\n",
      "|168.255.93.197|20140226235035|http://news.rambl...|1493| 200|Opera/5.0 compati...|\n",
      "+--------------+--------------+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log[(log.code == 200) & (log.url.like(\"%rambler%\"))].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Все вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|247.182.249.253| 200|\n",
      "|  75.208.40.166| 200|\n",
      "|   25.62.10.220| 200|\n",
      "|  33.49.147.163| 200|\n",
      "| 197.72.248.141| 200|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log[(log.code == 200) & (log.url.like(\"%rambler%\"))][[\"ip\", \"code\"]].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что же насчет SQL?! Он тут как тут)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ip, code FROM log_table\n",
    "WHERE code == 200 AND url LIKE '%rambler%'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: log_table; line 2 pos 21'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o68.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: log_table; line 2 pos 21\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:47)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:798)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:750)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:780)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$apply$1.apply(AnalysisHelper.scala:90)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:89)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1$$anonfun$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:87)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveOperatorsUp$1.apply(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:194)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$class.resolveOperatorsUp(AnalysisHelper.scala:86)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsUp(LogicalPlan.scala:29)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:773)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:719)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:87)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:84)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:76)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:127)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:121)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:106)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:643)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.sql.catalyst.analysis.NoSuchTableException: Table or view 'log_table' not found in database 'default';\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalog$class.requireTableExists(ExternalCatalog.scala:48)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.requireTableExists(InMemoryCatalog.scala:45)\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.getTable(InMemoryCatalog.scala:326)\n\tat org.apache.spark.sql.catalyst.catalog.ExternalCatalogWithListener.getTable(ExternalCatalogWithListener.scala:138)\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.lookupRelation(SessionCatalog.scala:706)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:795)\n\t... 63 more\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-685af25b5f04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: log_table; line 2 pos 21'"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Надо зарегистрировать свой DataFrame как table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.createOrReplaceTempView(\"log_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|             ip|code|\n",
      "+---------------+----+\n",
      "|247.182.249.253| 200|\n",
      "|  75.208.40.166| 200|\n",
      "|   25.62.10.220| 200|\n",
      "|  33.49.147.163| 200|\n",
      "| 197.72.248.141| 200|\n",
      "+---------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как Spark будет выполнять запрос?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project ['ip, 'code]\n",
      "+- 'Filter (('code = 200) && 'url LIKE %rambler%)\n",
      "   +- 'UnresolvedRelation `log_table`\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ip: string, code: int\n",
      "Project [ip#572, code#576]\n",
      "+- Filter ((code#576 = 200) && url#574 LIKE %rambler%)\n",
      "   +- SubqueryAlias `log_table`\n",
      "      +- Repartition 6, true\n",
      "         +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Repartition 6, true\n",
      "+- Project [ip#572, code#576]\n",
      "   +- Filter (((isnotnull(code#576) && isnotnull(url#574)) && (code#576 = 200)) && Contains(url#574, rambler))\n",
      "      +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "Exchange RoundRobinPartitioning(6)\n",
      "+- *(1) Project [ip#572, code#576]\n",
      "   +- *(1) Filter (((isnotnull(code#576) && isnotnull(url#574)) && (code#576 = 200)) && Contains(url#574, rambler))\n",
      "      +- InMemoryTableScan [code#576, ip#572, url#574], [isnotnull(code#576), isnotnull(url#574), (code#576 = 200), Contains(url#574, rambler)]\n",
      "            +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                  +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Функции есть 3 типа\n",
    "\n",
    "+ mapping (one to one)\n",
    "+ generating (one to many)\n",
    "+ aggregating (many to one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                  ua|length(ua)|\n",
      "+--------------------+----------+\n",
      "|Safari/5.0 (compa...|        95|\n",
      "|Safari/5.0 (compa...|        95|\n",
      "|Safari/5.0 (compa...|        95|\n",
      "|Safari/5.0 (compa...|        95|\n",
      "|Safari/5.0 (compa...|        95|\n",
      "+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.length(\"ua\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                  ua|length|\n",
      "+--------------------+------+\n",
      "|Safari/5.0 (compa...|    95|\n",
      "|Safari/5.0 (compa...|    95|\n",
      "|Safari/5.0 (compa...|    95|\n",
      "|Safari/5.0 (compa...|    95|\n",
      "|Safari/5.0 (compa...|    95|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.length(\"ua\").alias(\"length\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`?utm_medium=email`' given input columns: [url, ua, ip, timestamp, code, size];;\\n'Project [concat(url#574, '?utm_medium=email) AS concat(url, ?utm_medium=email)#1531]\\n+- Repartition 6, true\\n   +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o266.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`?utm_medium=email`' given input columns: [url, ua, ip, timestamp, code, size];;\n'Project [concat(url#574, '?utm_medium=email) AS concat(url, ?utm_medium=email)#1531]\n+- Repartition 6, true\n   +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:111)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$3.applyOrElse(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:280)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:279)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.org$apache$spark$sql$catalyst$trees$TreeNode$$mapChild$2(TreeNode.scala:297)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4$$anonfun$apply$13.apply(TreeNode.scala:356)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:356)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$3.apply(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:328)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:326)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:277)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$1.apply(QueryPlan.scala:105)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:69)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:116)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$2.apply(QueryPlan.scala:121)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:121)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$2.apply(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:186)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:93)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:126)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:95)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:108)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$$anonfun$executeAndCheck$1.apply(Analyzer.scala:105)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:105)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:58)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:48)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:78)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:3412)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1340)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-1ddb07dc3729>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"?utm_medium=email\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \"\"\"\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`?utm_medium=email`' given input columns: [url, ua, ip, timestamp, code, size];;\\n'Project [concat(url#574, '?utm_medium=email) AS concat(url, ?utm_medium=email)#1531]\\n+- Repartition 6, true\\n   +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\\n\""
     ]
    }
   ],
   "source": [
    "log.select(f.concat(\"url\", \"?utm_medium=email\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`concat` необходим `Column` как аргумент. `lit` создает новую `Column` из literal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------+\n",
      "|newurl                                         |\n",
      "+-----------------------------------------------+\n",
      "|http://news.yandex.ru/4761980?utm_medium=email |\n",
      "|http://newsru.com/9387648?utm_medium=email     |\n",
      "|http://news.rambler.ru/2396720?utm_medium=email|\n",
      "|http://news.rambler.ru/7522218?utm_medium=email|\n",
      "|http://newsru.com/5728483?utm_medium=email     |\n",
      "+-----------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(f.concat(\"url\", f.lit(\"?utm_medium=email\")).alias(\"newurl\")).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explosions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------\n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            \n",
      " word_list | [Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, chromeframe/12.0.742.112)] \n",
      "-RECORD 1---------------------------------------------------------------------------------------------------------------\n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            \n",
      " word_list | [Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, chromeframe/12.0.742.112)] \n",
      "-RECORD 2---------------------------------------------------------------------------------------------------------------\n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            \n",
      " word_list | [Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, chromeframe/12.0.742.112)] \n",
      "-RECORD 3---------------------------------------------------------------------------------------------------------------\n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            \n",
      " word_list | [Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, chromeframe/12.0.742.112)] \n",
      "-RECORD 4---------------------------------------------------------------------------------------------------------------\n",
      " ua        | Safari/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0; chromeframe/12.0.742.112)            \n",
      " word_list | [Safari/5.0, (compatible;, MSIE, 9.0;, Windows, NT, 6.1;, WOW64;, Trident/5.0;, chromeframe/12.0.742.112)] \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.split(\"ua\", \" \").alias(\"word_list\")).show(5, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Можно выбирать отдельные элементы из list!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|word_list[0]|word_list[1]|\n",
      "+------------+------------+\n",
      "|  Safari/5.0|(compatible;|\n",
      "|  Safari/5.0|(compatible;|\n",
      "|  Safari/5.0|(compatible;|\n",
      "|  Safari/5.0|(compatible;|\n",
      "|  Safari/5.0|(compatible;|\n",
      "+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.split(\"ua\", \" \").alias(\"word_list\"))\\\n",
    "   .select(f.col(\"word_list\")[0], f.col(\"word_list\")[1])\\\n",
    "   .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                word|\n",
      "+--------------------+\n",
      "|          Safari/5.0|\n",
      "|        (compatible;|\n",
      "|                MSIE|\n",
      "|                9.0;|\n",
      "|             Windows|\n",
      "|                  NT|\n",
      "|                6.1;|\n",
      "|              WOW64;|\n",
      "|        Trident/5.0;|\n",
      "|chromeframe/12.0....|\n",
      "|          Safari/5.0|\n",
      "|        (compatible;|\n",
      "|                MSIE|\n",
      "|                9.0;|\n",
      "|             Windows|\n",
      "|                  NT|\n",
      "|                6.1;|\n",
      "|              WOW64;|\n",
      "|        Trident/5.0;|\n",
      "|chromeframe/12.0....|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.split(\"ua\", \" \").alias(\"word_list\"))\\\n",
    "   .select(f.explode(\"word_list\").alias(\"word\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|        word|count|\n",
      "+------------+-----+\n",
      "|        MSIE|10092|\n",
      "|        9.0;|10092|\n",
      "|          NT|10092|\n",
      "|     Windows|10092|\n",
      "|Trident/5.0;| 9121|\n",
      "+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log.select(\"ua\", f.split(\"ua\", \" \").alias(\"word_list\"))\\\n",
    "   .select(f.explode(\"word_list\").alias(\"word\"))\\\n",
    "   .groupby(\"word\").count()\\\n",
    "   .orderBy(\"count\", ascending=False)\\\n",
    "   .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.67\tKhanty–Mansi\r\n",
      "197.72.248.141\tChechnya\r\n",
      "33.49.147.163\tNizhny Novgorod Oblast\r\n",
      "56.167.169.126\tVoronezh Oblast\r\n",
      "3.183.113.77\tAstrakhan Oblast\r\n",
      "56.167.169.126\tTver Oblast\r\n",
      "56.167.169.126\tKabardino-Balkaria\r\n",
      "56.167.169.126\tNenets Autonomous Okrug\r\n",
      "33.49.147.163\tOmsk Oblast\r\n",
      "14.8.59.211\tKhabarovsk Krai\r\n",
      "75.208.40.166\tSakha\r\n",
      "135.124.143.193\tSamara Oblast\r\n",
      "75.208.40.166\tNovosibirsk Oblast\r\n",
      "75.208.40.166\tAmur Oblast\r\n",
      "75.208.40.166\tKarelia\r\n",
      "75.208.40.166\tSaint Petersburg\r\n",
      "181.217.177.35\tSamara Oblast\r\n",
      "33.49.147.163\tIrkutsk Oblast\r\n",
      "56.167.169.126\tLipetsk Oblast\r\n",
      "181.217.177.35\tKalmykia\r\n",
      "168.255.93.197\tVolgograd Oblast\r\n",
      "168.255.93.197\tOryol Oblast\r\n",
      "168.255.93.197\tKurgan Oblast\r\n",
      "168.146.187.80\tPrimorsky Krai\r\n",
      "49.105.15.79\tNorth Ossetia–Alania\r\n",
      "197.72.248.141\tStavropol Krai\r\n",
      "14.8.59.211\tKemerovo Oblast\r\n",
      "49.203.96.67\tUlyanovsk Oblast\r\n",
      "222.131.187.37\tYamalo-Nenets\r\n",
      "197.72.248.141\tZabaykalsky Krai\r\n",
      "222.131.187.37\tKaluga Oblast\r\n",
      "3.183.113.77\tSaratov Oblast\r\n",
      "168.255.93.197\tAstrakhan Oblast\r\n",
      "75.208.40.166\tNovgorod Oblast\r\n",
      "135.124.143.193\tTambov Oblast\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -tail /lectures/lecture02/data/ipDataM.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_schema = StructType(fields=[\n",
    "    StructField(\"ip\", StringType()),\n",
    "    StructField(\"region\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ips = spark.read.csv(\"/lectures/lecture02/data/ipDataM.txt\", schema=ip_schema, sep=\"\\t\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|            ip|            region|\n",
      "+--------------+------------------+\n",
      "|  49.105.15.79|              Komi|\n",
      "|110.91.102.196|Chelyabinsk Oblast|\n",
      "|56.167.169.126|  Saint Petersburg|\n",
      "| 75.208.40.166|  Ulyanovsk Oblast|\n",
      "|168.255.93.197|    Irkutsk Oblast|\n",
      "+--------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Есть трюк, который отключает автоматические broadcast'ы для joins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ips.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log.join(ips, on=\"ip\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string, region: string]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+----+----+----+----+-------------------+\n",
      "|            ip|timestamp| url|size|code|  ua|             region|\n",
      "+--------------+---------+----+----+----+----+-------------------+\n",
      "|154.64.206.187|     null|null|null|null|null|        Tver Oblast|\n",
      "|154.64.206.187|     null|null|null|null|null|Karachay–Cherkessia|\n",
      "|154.64.206.187|     null|null|null|null|null|            Karelia|\n",
      "|154.64.206.187|     null|null|null|null|null|        Omsk Oblast|\n",
      "|154.64.206.187|     null|null|null|null|null|   Leningrad Oblast|\n",
      "+--------------+---------+----+----+----+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_regions.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'200'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log_with_regions.coalesce(6).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query planner использует SortMergeJoin по дефолту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Repartition 6, false\n",
      "+- Project [coalesce(ip#572, ip#1742) AS ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "   +- Join FullOuter, (ip#572 = ip#1742)\n",
      "      :- Repartition 6, true\n",
      "      :  +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n",
      "      +- Relation[ip#1742,region#1743] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string, region: string\n",
      "Repartition 6, false\n",
      "+- Project [coalesce(ip#572, ip#1742) AS ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "   +- Join FullOuter, (ip#572 = ip#1742)\n",
      "      :- Repartition 6, true\n",
      "      :  +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n",
      "      +- Relation[ip#1742,region#1743] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "InMemoryRelation [ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   +- Coalesce 6\n",
      "      +- *(3) Project [coalesce(ip#572, ip#1742) AS ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "         +- SortMergeJoin [ip#572], [ip#1742], FullOuter\n",
      "            :- *(1) Sort [ip#572 ASC NULLS FIRST], false, 0\n",
      "            :  +- Exchange hashpartitioning(ip#572, 200)\n",
      "            :     +- Exchange RoundRobinPartitioning(6)\n",
      "            :        +- InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577]\n",
      "            :              +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            :                    +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "            +- *(2) Sort [ip#1742 ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(ip#1742, 200)\n",
      "                  +- InMemoryTableScan [ip#1742, region#1743]\n",
      "                        +- InMemoryRelation [ip#1742, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                              +- *(1) FileScan csv [ip#1742,region#1743] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "InMemoryTableScan [ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "   +- InMemoryRelation [ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- Coalesce 6\n",
      "            +- *(3) Project [coalesce(ip#572, ip#1742) AS ip#1785, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "               +- SortMergeJoin [ip#572], [ip#1742], FullOuter\n",
      "                  :- *(1) Sort [ip#572 ASC NULLS FIRST], false, 0\n",
      "                  :  +- Exchange hashpartitioning(ip#572, 200)\n",
      "                  :     +- Exchange RoundRobinPartitioning(6)\n",
      "                  :        +- InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577]\n",
      "                  :              +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                  :                    +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "                  +- *(2) Sort [ip#1742 ASC NULLS FIRST], false, 0\n",
      "                     +- Exchange hashpartitioning(ip#1742, 200)\n",
      "                        +- InMemoryTableScan [ip#1742, region#1743]\n",
      "                              +- InMemoryRelation [ip#1742, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                    +- *(1) FileScan csv [ip#1742,region#1743] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log.join(f.broadcast(ips), on=\"ip\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "+- *(3) BroadcastHashJoin [ip#572], [ip#1742], Inner, BuildRight\n",
      "   :- Exchange RoundRobinPartitioning(6)\n",
      "   :  +- *(1) Filter isnotnull(ip#572)\n",
      "   :     +- InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], [isnotnull(ip#572)]\n",
      "   :           +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :                 +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]))\n",
      "      +- *(2) Filter isnotnull(ip#1742)\n",
      "         +- InMemoryTableScan [ip#1742, region#1743], [isnotnull(ip#1742)]\n",
      "               +- InMemoryRelation [ip#1742, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     +- *(1) FileScan csv [ip#1742,region#1743] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Или можно использовать метод `hint()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log.join(ips.hint(\"broadcast\"), on=\"ip\", how=\"inner\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Join UsingJoin(Inner,Buffer(ip))\n",
      ":- Repartition 6, true\n",
      ":  +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n",
      "+- ResolvedHint (broadcast)\n",
      "   +- Relation[ip#1742,region#1743] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "ip: string, timestamp: bigint, url: string, size: int, code: int, ua: string, region: string\n",
      "Project [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "+- Join Inner, (ip#572 = ip#1742)\n",
      "   :- Repartition 6, true\n",
      "   :  +- Relation[ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] csv\n",
      "   +- ResolvedHint (broadcast)\n",
      "      +- Relation[ip#1742,region#1743] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   +- *(3) Project [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "      +- *(3) BroadcastHashJoin [ip#572], [ip#1742], Inner, BuildRight\n",
      "         :- Exchange RoundRobinPartitioning(6)\n",
      "         :  +- *(1) Filter isnotnull(ip#572)\n",
      "         :     +- InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], [isnotnull(ip#572)]\n",
      "         :           +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         :                 +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "         +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]))\n",
      "            +- *(2) Filter isnotnull(ip#1742)\n",
      "               +- InMemoryTableScan [ip#1742, region#1743], [isnotnull(ip#1742)]\n",
      "                     +- InMemoryRelation [ip#1742, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                           +- *(1) FileScan csv [ip#1742,region#1743] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n",
      "\n",
      "== Physical Plan ==\n",
      "InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "   +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *(3) Project [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577, region#1743]\n",
      "            +- *(3) BroadcastHashJoin [ip#572], [ip#1742], Inner, BuildRight\n",
      "               :- Exchange RoundRobinPartitioning(6)\n",
      "               :  +- *(1) Filter isnotnull(ip#572)\n",
      "               :     +- InMemoryTableScan [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], [isnotnull(ip#572)]\n",
      "               :           +- InMemoryRelation [ip#572, timestamp#573L, url#574, size#575, code#576, ua#577], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "               :                 +- *(1) FileScan csv [ip#572,timestamp#573L,url#574,size#575,code#576,ua#577] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/logsM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,timestamp:bigint,url:string,size:int,code:int,ua:string>\n",
      "               +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]))\n",
      "                  +- *(2) Filter isnotnull(ip#1742)\n",
      "                     +- InMemoryTableScan [ip#1742, region#1743], [isnotnull(ip#1742)]\n",
      "                           +- InMemoryRelation [ip#1742, region#1743], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                 +- *(1) FileScan csv [ip#1742,region#1743] Batched: false, Format: CSV, Location: InMemoryFileIndex[hdfs://spark-master-1.newprolab.com:8020/lectures/lecture02/data/ipDataM.txt], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ip:string,region:string>\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation pipeline выглядит следующим образом:\n",
    "```python\n",
    "df.groupBy(*cols)\\\n",
    "  .agg(*expressions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+------+\n",
      "|            region| count|   cnt|\n",
      "+------------------+------+------+\n",
      "|  Ulyanovsk Oblast|204275|204275|\n",
      "|            Jewish|134523|134523|\n",
      "|  Saint Petersburg|129362|129362|\n",
      "|Arkhangelsk Oblast|124937|124937|\n",
      "|    Vologda Oblast|122363|122363|\n",
      "|   Novgorod Oblast|122306|122306|\n",
      "|     Moscow Oblast|120336|120336|\n",
      "|  Krasnoyarsk Krai|119285|119285|\n",
      "|              Komi|117659|117659|\n",
      "|          Kalmykia|117172|117172|\n",
      "+------------------+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.groupBy(\"region\")\\\n",
    "                .agg(f.count(\"ip\").alias(\"count\"), f.count(f.lit(\"1\")).alias(\"cnt\"))\\\n",
    "                .orderBy(\"count\", ascending=False)\\\n",
    "                .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_regions = log_with_regions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|            region|row_count|\n",
      "+------------------+---------+\n",
      "|  Ulyanovsk Oblast|   204275|\n",
      "|            Jewish|   134523|\n",
      "|  Saint Petersburg|   129362|\n",
      "|Arkhangelsk Oblast|   124937|\n",
      "|    Vologda Oblast|   122363|\n",
      "|   Novgorod Oblast|   122306|\n",
      "|     Moscow Oblast|   120336|\n",
      "|  Krasnoyarsk Krai|   119285|\n",
      "|              Komi|   117659|\n",
      "|          Kalmykia|   117172|\n",
      "+------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_regions.groupBy(\"region\")\\\n",
    "                .count()\\\n",
    "                .withColumnRenamed(\"count\", \"row_count\")\\\n",
    "                .orderBy(\"row_count\", ascending=False)\\\n",
    "                .show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stat = log_with_regions.groupBy(f.length(\"url\").alias(\"url_length\"))\\\n",
    "                              .agg(f.count(\"*\").alias(\"row_count\"))\\\n",
    "                              .orderBy(\"row_count\", ascending=False).limit(2)\\\n",
    "                              .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>1676363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1644000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length  row_count\n",
       "0          23    1676363\n",
       "1          27    1644000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb442fd4780>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAENCAYAAADKcIhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHshJREFUeJzt3XuUFvWd5/H3JzQIjhcQ2kto1iaKCkpU6CjRiWN0RvESMRnN4Mlqj2HDajCZjBMjxuzg6DijcScmZNEMBgbMOhIOY5TJoCyruIlJUBtvgETtqAPttRUkXoKKfveP+rX90D7dT9PV3UXbn9c5fbrqW7+q3++pA3yoy1OliMDMzCyPjxU9ADMz6/scJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9yqih5AbxkxYkTU1tYWPQwzsz5l9erVr0REdaV2/SZMamtraWhoKHoYZmZ9iqT/7Ew7n+YyM7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZmuTlMzMwsN4eJmZnl1m++tNgdamf+R9FD4NlrTit6CGZmH+IjEzMzy81hYmZmuTlMzMwsN18zsa65Ys+iRwBXbCl6BGaWOEzMchq/cHzRQ2BN/ZqihwDA+kPGFj0Exv52fdFD6JcqnuaSNF/Sy5LWtql/TdITktZJ+m5J/TJJjWnZySX1yanWKGlmSX20pPslPSXpp5IGpfouab4xLa+t1IeZmRWjM0cmC4D/BdzcUpD0WWAK8MmIeFvS3qk+DpgKHAp8HPi/kg5Kq80B/gxoAh6UtDQiHgeuBa6PiEWSfgRMA25MvzdHxIGSpqZ2f9FeHxHxXp4dYWbWneZccE/RQ2DGj07otb4qHplExC+ATW3KFwLXRMTbqc3LqT4FWBQRb0fEM0AjcFT6aYyIpyPiHWARMEWSgBOAJWn9hcCZJdtamKaXACem9u31YWZmBenq3VwHAZ9Jp5/+n6RPpfpIYGNJu6ZUa68+HHgtIra1qW+3rbR8S2rf3rY+RNJ0SQ2SGpqbm7v0Qc3MrLKuhkkVMAyYBFwCLE5HDSrTNrpQp4vrbF+MmBsRdRFRV11d8RXGZmbWRV0Nkybgtsg8ALwPjEj1USXtaoDnO6i/AgyVVNWmTuk6afmeZKfb2tuWmZkVpKthcjvZtQ7SBfZBZMGwFJia7sQaDYwBHgAeBMakO7cGkV1AXxoRAawEzkrbrQfuSNNL0zxp+T2pfXt9mJlZQSrezSXpVuB4YISkJmAWMB+Yn24XfgeoT//Qr5O0GHgc2AbMaLnLStJFwHJgADA/ItalLi4FFkn6e+BhYF6qzwN+IqmR7IhkKkBEtNuHmZkVo2KYRMQ57Sz6r+20vxq4ukx9GbCsTP1pytyNFRFbgbN3pA8zMyuGn81lZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLrWKYSJov6eX0VsW2y74pKSSNSPOSNFtSo6THJE0oaVsv6an0U19SnyhpTVpntiSl+l6SVqT2KyQNq9SHmZkVozNHJguAyW2LkkYBfwZsKCmfQvZO9jHAdODG1HYvstf9Hk32VsVZLeGQ2kwvWa+lr5nA3RExBrg7zbfbh5mZFadimETEL8jewd7W9cC3gCipTQFujswqYKik/YCTgRURsSkiNgMrgMlp2R4R8Zv0DvmbgTNLtrUwTS9sUy/Xh5mZFaRL10wknQE8FxGPtlk0EthYMt+Uah3Vm8rUAfaJiBcA0u+9K/RRbpzTJTVIamhubu7kpzMzsx21w2EiaVfgcuBvyy0uU4su1DscQmfXiYi5EVEXEXXV1dUVNmtmZl3VlSOTA4DRwKOSngVqgIck7Ut2lDCqpG0N8HyFek2ZOsBLLaev0u+XU729bZmZWUF2OEwiYk1E7B0RtRFRS/aP+4SIeBFYCpyX7riaBGxJp6iWAydJGpYuvJ8ELE/LXpc0Kd3FdR5wR+pqKdBy11d9m3q5PszMrCBVlRpIuhU4HhghqQmYFRHz2mm+DDgVaATeAs4HiIhNkq4CHkztroyIlov6F5LdMTYEuDP9AFwDLJY0jeyOsbM76sPMzIpTMUwi4pwKy2tLpgOY0U67+cD8MvUG4LAy9VeBE8vU2+3DzMyK4W/Am5lZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcqsYJpLmS3pZ0tqS2nWSfivpMUk/kzS0ZNllkholPSHp5JL65FRrlDSzpD5a0v2SnpL0U0mDUn2XNN+YltdW6sPMzIrRmSOTBcDkNrUVwGER8UngSeAyAEnjgKnAoWmdGyQNkDQAmAOcAowDzkltAa4Fro+IMcBmYFqqTwM2R8SBwPWpXbt97ODnNjOzblQxTCLiF8CmNrX/ExHb0uwqoCZNTwEWRcTbEfEM2Xvaj0o/jRHxdES8AywCpkgScAKwJK2/EDizZFsL0/QS4MTUvr0+zMysIN1xzeTLwJ1peiSwsWRZU6q1Vx8OvFYSTC317baVlm9J7dvb1odImi6pQVJDc3Nzlz6cmZlVlitMJF0ObANuaSmVaRZdqHdlWx8uRsyNiLqIqKuuri7XxMzMukFVV1eUVA+cDpwYES3/mDcBo0qa1QDPp+ly9VeAoZKq0tFHafuWbTVJqgL2JDvd1lEfZmZWgC4dmUiaDFwKnBERb5UsWgpMTXdijQbGAA8ADwJj0p1bg8guoC9NIbQSOCutXw/cUbKt+jR9FnBPat9eH2ZmVpCKRyaSbgWOB0ZIagJmkd29tQuwIrsmzqqIuCAi1klaDDxOdvprRkS8l7ZzEbAcGADMj4h1qYtLgUWS/h54GJiX6vOAn0hqJDsimQrQUR9mZlaMimESEeeUKc8rU2tpfzVwdZn6MmBZmfrTlLkbKyK2AmfvSB9mZlYMfwPezMxyc5iYmVluDhMzM8vNYWJmZrk5TMzMLDeHiZmZ5eYwMTOz3BwmZmaWm8PEzMxyc5iYmVluDhMzM8vNYWJmZrk5TMzMLDeHiZmZ5eYwMTOz3BwmZmaWW8UwkTRf0suS1pbU9pK0QtJT6fewVJek2ZIaJT0maULJOvWp/VPp/fEt9YmS1qR1Ziu9urErfZiZWTE6c2SyAJjcpjYTuDsixgB3p3mAU8jeyT4GmA7cCFkwkL3u92iytyrOagmH1GZ6yXqTu9KHmZkVp2KYRMQvyN7BXmoKsDBNLwTOLKnfHJlVwFBJ+wEnAysiYlNEbAZWAJPTsj0i4jcREcDNbba1I32YmVlBunrNZJ+IeAEg/d471UcCG0vaNaVaR/WmMvWu9PEhkqZLapDU0NzcvEMf0MzMOq+7L8CrTC26UO9KHx8uRsyNiLqIqKuurq6wWTMz66quhslLLaeW0u+XU70JGFXSrgZ4vkK9pky9K32YmVlBuhomS4GWO7LqgTtK6uelO64mAVvSKarlwEmShqUL7ycBy9Oy1yVNSndxnddmWzvSh5mZFaSqUgNJtwLHAyMkNZHdlXUNsFjSNGADcHZqvgw4FWgE3gLOB4iITZKuAh5M7a6MiJaL+heS3TE2BLgz/bCjfZiZWXEqhklEnNPOohPLtA1gRjvbmQ/ML1NvAA4rU391R/swM7Ni+BvwZmaWm8PEzMxyc5iYmVluDhMzM8vNYWJmZrk5TMzMLDeHiZmZ5eYwMTOz3BwmZmaWm8PEzMxyc5iYmVluDhMzM8vNYWJmZrk5TMzMLDeHiZmZ5ZYrTCT9taR1ktZKulXSYEmjJd0v6SlJP5U0KLXdJc03puW1Jdu5LNWfkHRySX1yqjVKmllSL9uHmZkVo8thImkk8HWgLiIOAwYAU4FrgesjYgywGZiWVpkGbI6IA4HrUzskjUvrHQpMBm6QNEDSAGAOcAowDjgntaWDPszMrAB5T3NVAUMkVQG7Ai8AJwBL0vKFwJlpekqaJy0/Mb33fQqwKCLejohnyF7He1T6aYyIpyPiHWARMCWt014fZmZWgC6HSUQ8B/xPsvezvwBsAVYDr0XEttSsCRiZpkcCG9O621L74aX1Nuu0Vx/eQR/bkTRdUoOkhubm5q5+VDMzqyDPaa5hZEcVo4GPA39EdkqqrWhZpZ1l3VX/cDFibkTURURddXV1uSZmZtYN8pzm+lPgmYhojoh3gduAY4Ch6bQXQA3wfJpuAkYBpOV7AptK623Waa/+Sgd9mJlZAfKEyQZgkqRd03WME4HHgZXAWalNPXBHml6a5knL74mISPWp6W6v0cAY4AHgQWBMunNrENlF+qVpnfb6MDOzAuS5ZnI/2UXwh4A1aVtzgUuBiyU1kl3fmJdWmQcMT/WLgZlpO+uAxWRBdBcwIyLeS9dELgKWA+uBxaktHfRhZmYFqKrcpH0RMQuY1ab8NNmdWG3bbgXObmc7VwNXl6kvA5aVqZftw8zMiuFvwJuZWW4OEzMzy81hYmZmuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZmuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHLLFSaShkpaIum3ktZL+rSkvSStkPRU+j0stZWk2ZIaJT0maULJdupT+6ck1ZfUJ0pak9aZnV4PTHt9mJlZMfIemfwAuCsiDgEOJ3u97kzg7ogYA9yd5gFOIXu/+xhgOnAjZMFA9rbGo8nenjirJBxuTG1b1puc6u31YWZmBehymEjaAziO9P71iHgnIl4DpgALU7OFwJlpegpwc2RWAUMl7QecDKyIiE0RsRlYAUxOy/aIiN9ERAA3t9lWuT7MzKwAeY5MPgE0A/8i6WFJP5b0R8A+EfECQPq9d2o/EthYsn5TqnVUbypTp4M+tiNpuqQGSQ3Nzc1d/6RmZtahPGFSBUwAboyII4E36fh0k8rUogv1TouIuRFRFxF11dXVO7KqmZntgDxh0gQ0RcT9aX4JWbi8lE5RkX6/XNJ+VMn6NcDzFeo1Zep00IeZmRWgy2ESES8CGyUdnEonAo8DS4GWO7LqgTvS9FLgvHRX1yRgSzpFtRw4SdKwdOH9JGB5Wva6pEnpLq7z2myrXB9mZlaAqpzrfw24RdIg4GngfLKAWixpGrABODu1XQacCjQCb6W2RMQmSVcBD6Z2V0bEpjR9IbAAGALcmX4ArmmnDzMzK0CuMImIR4C6MotOLNM2gBntbGc+ML9MvQE4rEz91XJ9mJlZMfwNeDMzy81hYmZmuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW4OEzMzy81hYmZmuTlMzMwsN4eJmZnl5jAxM7PcHCZmZpabw8TMzHJzmJiZWW65w0TSAEkPS/p5mh8t6X5JT0n6aXoLI5J2SfONaXltyTYuS/UnJJ1cUp+cao2SZpbUy/ZhZmbF6I4jk78C1pfMXwtcHxFjgM3AtFSfBmyOiAOB61M7JI0DpgKHApOBG1JADQDmAKcA44BzUtuO+jAzswLkChNJNcBpwI/TvIATgCWpyULgzDQ9Jc2Tlp+Y2k8BFkXE2xHxDNk74o9KP40R8XREvAMsAqZU6MPMzAqQ98jk+8C3gPfT/HDgtYjYluabgJFpeiSwESAt35Laf1Bvs0579Y762I6k6ZIaJDU0Nzd39TOamVkFXQ4TSacDL0fE6tJymaZRYVl31T9cjJgbEXURUVddXV2uiZmZdYOqHOseC5wh6VRgMLAH2ZHKUElV6cihBng+tW8CRgFNkqqAPYFNJfUWpeuUq7/SQR9mZlaALh+ZRMRlEVETEbVkF9DviYgvASuBs1KzeuCONL00zZOW3xMRkepT091eo4ExwAPAg8CYdOfWoNTH0rROe32YmVkBeuJ7JpcCF0tqJLu+MS/V5wHDU/1iYCZARKwDFgOPA3cBMyLivXTUcRGwnOxuscWpbUd9mJlZAfKc5vpARNwL3Jumnya7E6ttm63A2e2sfzVwdZn6MmBZmXrZPszMrBj+BryZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma5OUzMzCw3h4mZmeXmMDEzs9wcJmZmlpvDxMzMcnOYmJlZbg4TMzPLzWFiZma55XkH/ChJKyWtl7RO0l+l+l6SVkh6Kv0eluqSNFtSo6THJE0o2VZ9av+UpPqS+kRJa9I6syWpoz7MzKwYeY5MtgF/ExFjgUnADEnjyN6geHdEjAHuTvMAp5C9kncMMB24EbJgAGYBR5O98GpWSTjcmNq2rDc51dvrw8zMCpDnHfAvRMRDafp1slfrjgSmAAtTs4XAmWl6CnBzZFYBQyXtB5wMrIiITRGxGVgBTE7L9oiI36T3vt/cZlvl+jAzswJ0yzUTSbXAkcD9wD4R8QJkgQPsnZqNBDaWrNaUah3Vm8rU6aCPtuOaLqlBUkNzc3NXP56ZmVWQ+x3wknYD/g34RkT8Pl3WKNu0TC26UO+0iJgLzAWoq6vboXWtb3v33Xdpampi69atPd7X98d9v8f7qGT9+vW90s/gwYOpqalh4MCBvdKf9R25wkTSQLIguSUibkvllyTtFxEvpFNVL6d6EzCqZPUa4PlUP75N/d5UrynTvqM+zABoampi9913p7a2lg7+g9Mt3n/l/R7dfmeMHTG2x/uICF599VWampoYPXp0j/dnfUueu7kEzAPWR8T3ShYtBVruyKoH7iipn5fu6poEbEmnqJYDJ0kali68nwQsT8telzQp9XVem22V68MMgK1btzJ8+PAeD5L+RBLDhw/vlaM963vyHJkcC5wLrJH0SKp9G7gGWCxpGrABODstWwacCjQCbwHnA0TEJklXAQ+mdldGxKY0fSGwABgC3Jl+6KAPsw84SLqf96m1p8thEhH3Uf66BsCJZdoHMKOdbc0H5pepNwCHlam/Wq4PMzMrRu4L8GZ9Qe3M/+jW7T17zWndur2dze23385BBx3EuHHjih6K9RF+nIpZL4gI3n+/+Av1nXX77bfz+OOPFz0M60McJmY95LkNz/G5Yz7HVd+6irNPOJt/X/zvfP64z3PmZ87ke1dm96zcdftdfPd/fBeAn/zzT5hclz3kYcMzGzj3tHPb3faah9fwpVO/xBeO/wJTT5rK66+/ztatWzn//PMZP348Rx55JCtXrgRgwYIFXHTRRR+se/rpp3PvvfcCsNtuu3H55Zdz+OGHM2nSJF566SV+/etfs3TpUi655BKOOOIIfve73/XE7rGPGIeJWQ96tvFZzvjiGdxw6w388JofMu+2eSxZuYS1D6/l7mV3U/fpOlavWg3AQ6seYs9he/LSCy/x8P0PM2HShLLbfPedd7nkK5cw8+qZ3Hbvbfz4337MkCFDmDNnDgBr1qzh1ltvpb6+vuKdV2+++SaTJk3i0Ucf5bjjjuOmm27imGOO4YwzzuC6667jkUce4YADDujenWIfSQ4Tsx708VEf5/C6w1n78Fo+deyn2GvEXlRVVXHan5/G6t+sZsQ+I3jrzbd48403efH5Fz+or161momTJpbd5jONzzBi7xGMP3I8ALvtvhtVVVXcd999nHtudjRzyCGHsP/++/Pkk092OL5BgwZx+umnAzBx4kSeffbZ7vvw1q84TMx60JBdhwDZNZP2HF53OD/7159Re2AtEyZNYPWq1Tza8ChHHn1k2fYRUfYW3fb6qKqq2u56TenRysCBAz/Y1oABA9i2bVvlD2VWhsPErBd8csInafh1A5tf3cx7773HnT+7k7pj6gCo+3QdC25YwMRJExk7fiwP3PcAgwYNYvc9di+7rU+M+QTNLzWz5uE1ALz5xpts27aN4447jltuuQWAJ598kg0bNnDwwQdTW1vLI488wvvvv8/GjRt54IEHKo5399135/XXX++mT2/9gW8Ntn6h6Ft5q/et5hvf+QZf/vyXiQg+86ef4YRTTgBgwqQJvPjci9QdU8eAAQPYd+S+jD6w/ceVDBw0kOtuuo5/vOwf2bp1K4MHD+ZX9/6Kr371q1xwwQWMHz+eqqoqFixYwC677MKxxx7L6NGjGT9+PIcddhgTJpS/FlNq6tSpfOUrX2H27NksWbLE102sInV0+P1RUldXFw0NDbm20d3fVeiKov9R/MAVexY9ArhiS7uL1q9fz9ixPf+8KoB1r6zrlX46cuiIQ3utr4727fpDemefd2Tsb3vnoZeVzLngnqKHwIwfnZB7G5JWR0RdpXY+zWVmZrn5NJfZTuzr9V/nuf98brvaxX97MceecGxBIzIrz2FithObvXB20UMw6xSf5rKPrP5yPbA3eZ9aexwm9pE0ePBgXn31Vf/j141aXo41ePDgoodiOyGf5rKPpJqaGpqammhubu7xvl5848Ue76OSjzX3zv8LW17ba9aWw8Q+kgYOHNhrr5b94sIv9ko/HVlTv6boIVg/16dPc0maLOkJSY2SZhY9HjOz/qrPhomkAcAc4BRgHHCOJL/Jx8ysAH02TICjgMaIeDoi3gEWAVMKHpOZWb/UZx+nIuksYHJE/Lc0fy5wdERcVNJmOjA9zR4MPNHrA/2wEcArRQ9iJ+F90cr7opX3RaudYV/sHxHVlRr15QvwH34GN2yXjBExF5jbO8PpHEkNnXnOTX/gfdHK+6KV90WrvrQv+vJpriZgVMl8DfB8QWMxM+vX+nKYPAiMkTRa0iBgKrC04DGZmfVLffY0V0Rsk3QRsBwYAMyPiOKfBV7ZTnXarWDeF628L1p5X7TqM/uiz16ANzOznUdfPs1lZmY7CYeJmZnl5jAxM7PcHCZmZpabw8TMzHJzmPQQSftKulHSHEnDJV0haY2kxZL2K3p8vUnSQ5K+I+mAosdSNEmTS6b3lDRP0mOS/lXSPkWOrbdJ2k3SlZLWSdoiqVnSKkl/WfTYepukKkn/XdJd6c/Do5LulHSBpIFFj68zHCY9ZwHwOLARWAn8ATgN+CXwo+KGVYhhwFBgpaQHJP21pI8XPaiC/EPJ9D8BLwCfI/sS7j8XMqLi3AI8DZwM/B0wGzgX+Kykf+hoxY+gnwBHAFcAp5L9W/F3wOHA/y5uWJ3n75n0EEkPR8SRaXpDRPyXkmWPRMQRxY2ud0l6KCImpOnPAOcAXwDWA7emZ6j1C232xXZ/Dvrhn4tHI+LwkvkHI+JTkj4GPB4RhxQ4vF4l6YmIOLidZU9GxEG9PaYd5SOTnlO6b29us2xAbw5kZxIRv4yIrwIjgWuBTxc8pN62t6SLJf0NsIek0geW9re/j29K+mMASZ8DNgFExPuUf5DrR9lmSWenIAVA0sck/QWwucBxdVqffZxKH3CHpN0i4o2I+E5LUdKB7ByPwu9NT7YtRMR7wF3ppz+5Cdg9TS8ke8R4s6R9gUcKG1UxLgRuknQQsBaYBiCpmuzFd/3JVLL/XM2R9FqqDSU7RT61sFHtAJ/m6kGSDiH7H/j9EfFGSX1yRPSrf0S9L1p5X7SSNJZsX6zyvtDRZK/R+B0wFphEdrpvWaED66T+dljdayR9DbgD+BqwVlLpWyD71cVF74tW3hetJH0d+BlwEd4Xs4AfADcA3yS7+L4rMFPS5UWOrbN8mqvnTAcmRsQbkmqBJZJqI+IH9L/zwd4XrbwvWn0FqPO+AOAssru5dgFeBGoi4veSrgPuB64ucnCd4TDpOQNaDtsj4llJx5P9Zdmf/vcXxfuilfdFK++LVtvSdcS3JP0uIn4PEBF/kPR+wWPrFJ/m6jkvSvrgNs/0l+Z0sguu4wsbVTG8L1p5X7Tyvmj1jqRd0/TElqKkPYE+ESa+AN9DJNWQ/W/jxTLLjo2IXxUwrEJ4X7TyvmjlfdFK0i4R8XaZ+ghgv4hYU8CwdojDxMzMcvNpLjMzy81hYmZmuTlMzMwsN4eJWTdJrxn4ZgfLF0g6qwf6/XbJdK2ktd3dh1klDhOzbiCpyO9sfbtyE7Oe5S8tmlWQvp3984g4LM1/E9gNOB74NXAssHQHtzkR+F7azivAX0bEC5LuJfvG82fJHvQ3LSJ+mb6DsAA4hOzR/bXADLJvTg+R9AiwDrgcGCDpJuAY4DlgSkT8oUsf3qyTfGRils/QiPiTiPinzq6Q3pz3Q+CsiJgIzGf7x2VURcRRwDeAWan2VWBzRHwSuIr0xbaImAn8ISKOiIgvpbZjgDkRcSjwGvDnXf94Zp3jIxOzfH7ahXUOBg4DVqTXmQwge+Nii9vS79VkRyAAf0z2IEAiYq2kxzrY/jMR0fI4+9JtmPUYh4lZZdvY/ih+cMn0m13YnoB1EdHei8Favgn9Hq1/R3fkWVWl36R+DxiyY8Mz23E+zWVW2Utkb0gcLmkXsudH5fEEUC3p05Cd9pJ0aIV17gO+mNqPY/tnV72bTp2ZFcZhYlZBRLwLXEl2YfznwG9zbu8dsgvn10p6lOwNi8dUWO0GsgB6DLgUeAzYkpbNBR6TdEuecZnl4WdzmfUBkgYAAyNiq6QDgLuBg1IwmRXO10zM+oZdgZXpdJaACx0ktjPxkYlZN5M0h+y7J6V+EBH/UsR4zHqDw8TMzHLzBXgzM8vNYWJmZrk5TMzMLDeHiZmZ5fb/ASyQ5xlWcA/HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_stat.plot(kind=\"bar\", x=\"url_length\", y=\"row_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_with_domains = log_with_regions.withColumn(\"domain\", f.regexp_extract(\"url\", \"http:\\/\\/(.*)\\/\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                  \n",
      " timestamp | 20140112193801                                                                                  \n",
      " url       | http://news.mail.ru/7703130                                                                     \n",
      " size      | 903                                                                                             \n",
      " code      | 504                                                                                             \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region    | Kaluga Oblast                                                                                   \n",
      " domain    | news.mail.ru                                                                                    \n",
      "-RECORD 1----------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                  \n",
      " timestamp | 20140112193801                                                                                  \n",
      " url       | http://news.mail.ru/7703130                                                                     \n",
      " size      | 903                                                                                             \n",
      " code      | 504                                                                                             \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region    | Yamalo-Nenets                                                                                   \n",
      " domain    | news.mail.ru                                                                                    \n",
      "-RECORD 2----------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                  \n",
      " timestamp | 20140112193801                                                                                  \n",
      " url       | http://news.mail.ru/7703130                                                                     \n",
      " size      | 903                                                                                             \n",
      " code      | 504                                                                                             \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region    | Yaroslavl Oblast                                                                                \n",
      " domain    | news.mail.ru                                                                                    \n",
      "-RECORD 3----------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                  \n",
      " timestamp | 20140112193801                                                                                  \n",
      " url       | http://news.mail.ru/7703130                                                                     \n",
      " size      | 903                                                                                             \n",
      " code      | 504                                                                                             \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region    | Kurgan Oblast                                                                                   \n",
      " domain    | news.mail.ru                                                                                    \n",
      "-RECORD 4----------------------------------------------------------------------------------------------------\n",
      " ip        | 222.131.187.37                                                                                  \n",
      " timestamp | 20140112193801                                                                                  \n",
      " url       | http://news.mail.ru/7703130                                                                     \n",
      " size      | 903                                                                                             \n",
      " code      | 504                                                                                             \n",
      " ua        | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region    | Nizhny Novgorod Oblast                                                                          \n",
      " domain    | news.mail.ru                                                                                    \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains.show(5, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Есть ли корреляция между `url_length` и `domain`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_stat = log_with_domains.groupBy(f.length(\"url\").alias(\"url_length\"), \"domain\")\\\n",
    "                              .agg(f.count(\"*\").alias(\"row_count\"))\\\n",
    "                              .orderBy(\"row_count\", ascending=False)\\\n",
    "                              .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>domain</th>\n",
       "      <th>row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>lenta.ru</td>\n",
       "      <td>1676363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>news.mail.ru</td>\n",
       "      <td>1644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>newsru.com</td>\n",
       "      <td>1639043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>news.yandex.ru</td>\n",
       "      <td>1638174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>news.rambler.ru</td>\n",
       "      <td>1617023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length           domain  row_count\n",
       "0          23         lenta.ru    1676363\n",
       "1          27     news.mail.ru    1644000\n",
       "2          25       newsru.com    1639043\n",
       "3          29   news.yandex.ru    1638174\n",
       "4          30  news.rambler.ru    1617023"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|url                    |\n",
      "+-----------------------+\n",
      "|http://lenta.ru/1741564|\n",
      "|http://lenta.ru/1741564|\n",
      "|http://lenta.ru/1741564|\n",
      "|http://lenta.ru/1741564|\n",
      "|http://lenta.ru/1741564|\n",
      "+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains[log_with_domains.domain == \"lenta.ru\"][[\"url\"]].show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'requirement failed: Currently correlation calculation for columns with dataType string not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o800.corr.\n: java.lang.IllegalArgumentException: requirement failed: Currently correlation calculation for columns with dataType string not supported.\n\tat scala.Predef$.require(Predef.scala:224)\n\tat org.apache.spark.sql.execution.stat.StatFunctions$$anonfun$collectStatisticalData$3.apply(StatFunctions.scala:159)\n\tat org.apache.spark.sql.execution.stat.StatFunctions$$anonfun$collectStatisticalData$3.apply(StatFunctions.scala:157)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat org.apache.spark.sql.execution.stat.StatFunctions$.collectStatisticalData(StatFunctions.scala:157)\n\tat org.apache.spark.sql.execution.stat.StatFunctions$.pearsonCorrelation(StatFunctions.scala:109)\n\tat org.apache.spark.sql.DataFrameStatFunctions.corr(DataFrameStatFunctions.scala:159)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-66dba9a4c46b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_with_domains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"domain\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"url_length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcorr\u001b[0;34m(self, col1, col2, method)\u001b[0m\n\u001b[1;32m   1914\u001b[0m             raise ValueError(\"Currently only the calculation of the Pearson Correlation \" +\n\u001b[1;32m   1915\u001b[0m                              \"coefficient is supported.\")\n\u001b[0;32m-> 1916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'requirement failed: Currently correlation calculation for columns with dataType string not supported.'"
     ]
    }
   ],
   "source": [
    "log_with_domains.withColumn(\"url_length\", f.length(\"url\")).corr(\"domain\", \"url_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Defined Functions\n",
    "UDF может иметь один из следующих типов:\n",
    "+ **SCALAR**. scalar UDF задает transformation: Одну или несколько `pandas.Series` -> `pandas.Series`. Scalar UDFs используются с `pyspark.sql.DataFrame.withColumn()` и `pyspark.sql.DataFrame.select()`\n",
    "+ **GROUPED_MAP**.grouped map UDF задает transformation: A `pandas.DataFrame` -> A `pandas.DataFrame`. Grouped map UDFs используются с `pyspark.sql.GroupedData.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(domain='news.rambler.ru'),\n",
       " Row(domain='news.yandex.ru'),\n",
       " Row(domain='newsru.com'),\n",
       " Row(domain='news.mail.ru'),\n",
       " Row(domain='lenta.ru')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_domains[[\"domain\"]].distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(IntegerType())\n",
    "def encode_domain(domains):\n",
    "    mapping = {\n",
    "        'lenta.ru': 0,\n",
    "        'newsru.com': 1,\n",
    "        'news.mail.ru': 2,\n",
    "        'news.yandex.ru': 3,\n",
    "        'news.rambler.ru': 4\n",
    "    }\n",
    "    return domains.apply(lambda x: mapping.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------\n",
      " ip             | 222.131.187.37                                                                                  \n",
      " timestamp      | 20140112193801                                                                                  \n",
      " url            | http://news.mail.ru/7703130                                                                     \n",
      " size           | 903                                                                                             \n",
      " code           | 504                                                                                             \n",
      " ua             | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region         | Kaluga Oblast                                                                                   \n",
      " domain         | news.mail.ru                                                                                    \n",
      " domain_encoded | 2                                                                                               \n",
      "-RECORD 1---------------------------------------------------------------------------------------------------------\n",
      " ip             | 222.131.187.37                                                                                  \n",
      " timestamp      | 20140112193801                                                                                  \n",
      " url            | http://news.mail.ru/7703130                                                                     \n",
      " size           | 903                                                                                             \n",
      " code           | 504                                                                                             \n",
      " ua             | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region         | Yamalo-Nenets                                                                                   \n",
      " domain         | news.mail.ru                                                                                    \n",
      " domain_encoded | 2                                                                                               \n",
      "-RECORD 2---------------------------------------------------------------------------------------------------------\n",
      " ip             | 222.131.187.37                                                                                  \n",
      " timestamp      | 20140112193801                                                                                  \n",
      " url            | http://news.mail.ru/7703130                                                                     \n",
      " size           | 903                                                                                             \n",
      " code           | 504                                                                                             \n",
      " ua             | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region         | Yaroslavl Oblast                                                                                \n",
      " domain         | news.mail.ru                                                                                    \n",
      " domain_encoded | 2                                                                                               \n",
      "-RECORD 3---------------------------------------------------------------------------------------------------------\n",
      " ip             | 222.131.187.37                                                                                  \n",
      " timestamp      | 20140112193801                                                                                  \n",
      " url            | http://news.mail.ru/7703130                                                                     \n",
      " size           | 903                                                                                             \n",
      " code           | 504                                                                                             \n",
      " ua             | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region         | Kurgan Oblast                                                                                   \n",
      " domain         | news.mail.ru                                                                                    \n",
      " domain_encoded | 2                                                                                               \n",
      "-RECORD 4---------------------------------------------------------------------------------------------------------\n",
      " ip             | 222.131.187.37                                                                                  \n",
      " timestamp      | 20140112193801                                                                                  \n",
      " url            | http://news.mail.ru/7703130                                                                     \n",
      " size           | 903                                                                                             \n",
      " code           | 504                                                                                             \n",
      " ua             | Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729;) \n",
      " region         | Nizhny Novgorod Oblast                                                                          \n",
      " domain         | news.mail.ru                                                                                    \n",
      " domain_encoded | 2                                                                                               \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains.withColumn(\"domain_encoded\", encode_domain(\"domain\")).show(5, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9939371499380237"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_domains.withColumn(\"domain_encoded\", encode_domain(\"domain\"))\\\n",
    "                .withColumn(\"url_length\", f.length(\"url\"))\\\n",
    "                .corr(\"domain_encoded\", \"url_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_with_domains.filter(f.isnull(\"url\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+----------------+\n",
      "|         domain|min(length(url))|max(length(url))|\n",
      "+---------------+----------------+----------------+\n",
      "|news.rambler.ru|              30|              30|\n",
      "| news.yandex.ru|              29|              29|\n",
      "|     newsru.com|              25|              25|\n",
      "|   news.mail.ru|              27|              27|\n",
      "|       lenta.ru|              23|              23|\n",
      "+---------------+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_with_domains.groupby(\"domain\").agg(f.min(f.length(\"url\")), f.max(f.length(\"url\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
