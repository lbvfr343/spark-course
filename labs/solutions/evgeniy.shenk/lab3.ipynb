{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Евгений Шенк\n",
    "\n",
    "## Лабораторная раота №3. Рекомендательная система видеоконтента с implicit feedback – Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "from pyspark.ml.feature import HashingTF, IDF, Normalizer, StopWordsRemover\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"ESShenk_spark_session\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2022-01-06 18:46 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2022-01-06 18:46 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2022-01-06 18:46 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2022-01-06 18:46 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = spark.read.csv(\"/labs/slaba03/laba03_items.csv\", header=True, sep=\"\\t\")\n",
    "df_test = spark.read.csv(\"/labs/slaba03/laba03_test.csv\", header=True)\n",
    "df_train = spark.read.csv(\"/labs/slaba03/laba03_train.csv\", header=True)\n",
    "df_views_programmes = spark.read.csv(\"/labs/slaba03/laba03_views_programmes.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test\\\n",
    "    .withColumn(\"user_id\", F.col(\"user_id\").cast(IntegerType()))\\\n",
    "    .withColumn(\"item_id\", F.col(\"item_id\").cast(IntegerType()))\\\n",
    "    .withColumn(\"purchase\", F.col(\"purchase\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train\\\n",
    "    .withColumn(\"user_id\", F.col(\"user_id\").cast(IntegerType()))\\\n",
    "    .withColumn(\"item_id\", F.col(\"item_id\").cast(IntegerType()))\\\n",
    "    .withColumn(\"purchase\", F.col(\"purchase\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Инфо по данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " item_id                     | 65667                \n",
      " channel_id                  | null                 \n",
      " datetime_availability_start | 1970-01-01T00:00:00Z \n",
      " datetime_availability_stop  | 2018-01-01T00:00:00Z \n",
      " datetime_show_start         | null                 \n",
      " datetime_show_stop          | null                 \n",
      " content_type                | 1                    \n",
      " title                       | на пробах только ... \n",
      " year                        | 2013.0               \n",
      " genres                      | Эротика              \n",
      " region_id                   | null                 \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items.show(n=1, truncate=True, vertical=True)  # channel_id, content_type, year, genres, region_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- channel_id: string (nullable = true)\n",
      " |-- datetime_availability_start: string (nullable = true)\n",
      " |-- datetime_availability_stop: string (nullable = true)\n",
      " |-- datetime_show_start: string (nullable = true)\n",
      " |-- datetime_show_stop: string (nullable = true)\n",
      " |-- content_type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- region_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------\n",
      " user_id  | 1654  \n",
      " item_id  | 94814 \n",
      " purchase | null  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test.count()  # 2156840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------\n",
      " user_id  | 1654  \n",
      " item_id  | 74107 \n",
      " purchase | 0     \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5032624"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train.count()  # 5032624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " user_id   | 0          \n",
      " item_id   | 7101053    \n",
      " ts_start  | 1491409931 \n",
      " ts_end    | 1491411600 \n",
      " item_type | live       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_views_programmes.show(n=1, truncate=False, vertical=True)  # item_type ts_end-ts_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_views_programmes = df_views_programmes\\\n",
    "    .withColumn(\"user_id\", df_views_programmes.user_id.cast(IntegerType()))\\\n",
    "    .withColumn(\"item_id\", df_views_programmes.item_id.cast(IntegerType()))\\\n",
    "    .withColumn(\"ts_start\", df_views_programmes.ts_start.cast(IntegerType()))\\\n",
    "    .withColumn(\"ts_end\", df_views_programmes.ts_end.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- ts_start: integer (nullable = true)\n",
      " |-- ts_end: integer (nullable = true)\n",
      " |-- item_type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_views_programmes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(IntegerType(), F.PandasUDFType.SCALAR)\n",
    "def col_diff(col_1, col_2):\n",
    "    return col_2 - col_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " user_id   | 0          \n",
      " item_id   | 7101053    \n",
      " ts_start  | 1491409931 \n",
      " ts_end    | 1491411600 \n",
      " item_type | live       \n",
      " ts_diff   | 1669       \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_views_programmes.select(\"*\")\\\n",
    ".filter(F.col(\"item_id\") == 7101053)\\\n",
    ".withColumn(\"ts_diff\", col_diff(\"ts_start\", \"ts_end\"))\\\n",
    ".show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20845607"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_views_programmes.count()  # 20845607"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка Признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_list = df_items.select(\"genres\").filter(F.col(\"content_type\") == 1).rdd.flatMap(lambda x:  x).collect()\n",
    "genres_result = []\n",
    "for x in genres_list:\n",
    "    if x:\n",
    "        genres_result += x.strip().split(',')\n",
    "\n",
    "genre_stats = {}\n",
    "for g in genres_result:\n",
    "    # Check if the word is already in dictionary\n",
    "    if g in genre_stats:\n",
    "        # Increment count of word by 1\n",
    "        genre_stats[g] = genre_stats[g] + 1\n",
    "    else:\n",
    "        # Add the word to dictionary with count 1\n",
    "        genre_stats[g] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Эротика', 'Комедии', 'Мелодрамы']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list = [x for x,y in genre_stats.items() if y > 10]\n",
    "genre_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_prep = df_items\\\n",
    "    .select(\"item_id\", \"year\", \"genres\")\\\n",
    "    .filter(F.col(\"content_type\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(IntegerType())\n",
    "def fill_col(col, x):\n",
    "    try:\n",
    "        if x in col:\n",
    "            return 1\n",
    "        else: \n",
    "            return 0\n",
    "    except TypeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in genre_list:\n",
    "    df_items_prep = df_items_prep.withColumn(x, fill_col(F.col(\"genres\"), F.lit(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items_prep = df_items_prep \\\n",
    "    .withColumn(\"item_id\", F.col(\"item_id\").cast(IntegerType())) \\\n",
    "    .withColumn(\"year\", F.col(\"year\").cast(IntegerType())) \\\n",
    "    .drop(F.col(\"genres\")) \\\n",
    "    .na.fill(-9999) \\\n",
    "    .withColumn(\"item_stats\", F.to_json(F.struct(genre_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_items_prep.show(n=1, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_joined = df_train.filter(F.col(\"purchase\") == 1).join(df_items_prep, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_joined.show(n=1, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_column = 'user_id'\n",
    "cols = [F.sum(F.col(x)).alias(x) for x in df_train_joined.columns if x != grouping_column]\n",
    "\n",
    "df_train_prep_grouped = df_train_joined \\\n",
    "    .groupBy(\"user_id\").agg(*cols) \\\n",
    "    .drop(F.col(\"item_id\")) \\\n",
    "    .drop(F.col(\"year\")) \\\n",
    "    .drop(F.col(\"purchase\")) \\\n",
    "    .withColumn(\"user_stats\", F.to_json(F.struct(genre_list))) \\\n",
    "    .select(\"user_id\", \"user_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_prep_grouped.show(n=1, truncate=100, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_count = df_train \\\n",
    "    .select(\"item_id\") \\\n",
    "    .filter(F.col(\"purchase\") == 1) \\\n",
    "    .groupBy(\"item_id\").agg(F.count(F.col(\"item_id\")).alias(\"item_prc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = df_train \\\n",
    "    .select(\"user_id\") \\\n",
    "    .filter(F.col(\"purchase\") == 1) \\\n",
    "    .groupBy(\"user_id\").agg(F.count(F.col(\"user_id\")).alias(\"user_prc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_year = df_train \\\n",
    "    .select(\"user_id\") \\\n",
    "    .filter(F.col(\"purchase\") == 1) \\\n",
    "    .join(df_train_joined.select(\"user_id\", \"year\"), on='user_id', how='left') \\\n",
    "    .groupBy(\"user_id\").agg(F.avg(F.col(\"year\")).alias(\"avg_year\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(IntegerType())\n",
    "def get_best_stat(user_col, item_col):\n",
    "    if user_col and item_col:\n",
    "        user_col = json.loads(user_col)\n",
    "        item_col = json.loads(item_col)\n",
    "        best = 0\n",
    "        for k, v in item_col.items():\n",
    "            if v > 0 and user_col[k] > best:\n",
    "                best = user_col[k]\n",
    "\n",
    "        return best\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(FloatType())\n",
    "def year_diff(user_col, item_col):\n",
    "    if user_col and item_col:\n",
    "        return item_col - user_col\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep = df_train \\\n",
    "    .join(user_count, on='user_id', how='left') \\\n",
    "    .join(item_count, on='item_id', how='left') \\\n",
    "    .join(df_train_prep_grouped, on='user_id', how='left') \\\n",
    "    .join(df_items_prep.select(\"item_id\", \"year\", \"item_stats\"), on='item_id', how='left') \\\n",
    "    .join(user_year, on='user_id', how='left') \\\n",
    "    .withColumn(\"stat_1\", get_best_stat(F.col(\"user_stats\"), F.col(\"item_stats\"))) \\\n",
    "    .withColumn(\"stat_2\", year_diff(F.col(\"avg_year\"), F.col(\"year\"))) \\\n",
    "    .na.fill(0) \\\n",
    "    .select('user_id', 'item_id', 'purchase', 'user_prc', 'item_prc', 'year', 'avg_year', 'stat_1', 'stat_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_prep = df_train_prep.sampleBy(\"purchase\", fractions={0: 0.02, 1: 1.0}, seed=27).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110899"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_prep.count()#.show(n=1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prep = df_test  \\\n",
    "    .join(user_count, on='user_id', how='left') \\\n",
    "    .join(item_count, on='item_id', how='left') \\\n",
    "    .join(df_train_prep_grouped, on='user_id', how='left') \\\n",
    "    .join(df_items_prep.select(\"item_id\", \"year\", \"item_stats\"), on='item_id', how='left') \\\n",
    "    .join(user_year, on='user_id', how='left') \\\n",
    "    .withColumn(\"stat_1\", get_best_stat(F.col(\"user_stats\"), F.col(\"item_stats\"))) \\\n",
    "    .withColumn(\"stat_2\", year_diff(F.col(\"avg_year\"), F.col(\"year\"))) \\\n",
    "    .na.fill(0) \\\n",
    "    .select('user_id', 'item_id', 'purchase', 'user_prc', 'item_prc', 'year', 'avg_year', 'stat_1', 'stat_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prep = df_test_prep.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = [\"item_id\", \"user_id\", \"purchase\"]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[x for x in df_train_prep.columns if x not in ignore_cols], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110899"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = (assembler.transform(df_train_prep).select(\"purchase\", \"features\"))\n",
    "train_data = train_data.repartition(16).cache()\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------\n",
      " purchase | 0                                                          \n",
      " features | (6,[1,2],[4.0,2015.0])                                     \n",
      "-RECORD 1--------------------------------------------------------------\n",
      " purchase | 0                                                          \n",
      " features | [11.0,2.0,2014.0,2001.090909090909,2.0,12.909090995788574] \n",
      "-RECORD 2--------------------------------------------------------------\n",
      " purchase | 0                                                          \n",
      " features | [2.0,2.0,2011.0,2014.0,2.0,-3.0]                           \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(n=3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxIter=10, maxDepth=4, seed=27, labelCol=\"purchase\")\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"purchase\", metricName='areaUnderROC')\n",
    "paramGrid = ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator, numFolds=3, parallelism=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 37.5 ms, total: 148 ms\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC ROC = 0.953232\n"
     ]
    }
   ],
   "source": [
    "auc_roc = model.avgMetrics[0]\n",
    "print(\"AUC ROC = %g\" % auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = assembler.transform(df_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------\n",
      " user_id  | 754230                                                       \n",
      " item_id  | 94619                                                        \n",
      " purchase | 0                                                            \n",
      " user_prc | 72                                                           \n",
      " item_prc | 1                                                            \n",
      " year     | 2013                                                         \n",
      " avg_year | 2009.9166666666667                                           \n",
      " stat_1   | 56                                                           \n",
      " stat_2   | 3.0833333                                                    \n",
      " features | [72.0,1.0,2013.0,2009.9166666666667,56.0,3.0833332538604736] \n",
      "-RECORD 1----------------------------------------------------------------\n",
      " user_id  | 754230                                                       \n",
      " item_id  | 10210                                                        \n",
      " purchase | 0                                                            \n",
      " user_prc | 72                                                           \n",
      " item_prc | 16                                                           \n",
      " year     | 2014                                                         \n",
      " avg_year | 2009.9166666666667                                           \n",
      " stat_1   | 0                                                            \n",
      " stat_2   | 4.0833335                                                    \n",
      " features | [72.0,16.0,2014.0,2009.9166666666667,0.0,4.083333492279053]  \n",
      "-RECORD 2----------------------------------------------------------------\n",
      " user_id  | 754230                                                       \n",
      " item_id  | 83549                                                        \n",
      " purchase | 0                                                            \n",
      " user_prc | 72                                                           \n",
      " item_prc | 1                                                            \n",
      " year     | 1958                                                         \n",
      " avg_year | 2009.9166666666667                                           \n",
      " stat_1   | 26                                                           \n",
      " stat_2   | -51.916668                                                   \n",
      " features | [72.0,1.0,1958.0,2009.9166666666667,26.0,-51.91666793823242] \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show(n=3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.transform(test_data.select(\"user_id\", \"item_id\", \"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------\n",
      " user_id       | 754230                                                       \n",
      " item_id       | 94619                                                        \n",
      " features      | [72.0,1.0,2013.0,2009.9166666666667,56.0,3.0833332538604736] \n",
      " rawPrediction | [0.10027600187598734,-0.10027600187598734]                   \n",
      " probability   | [0.5499706236274292,0.4500293763725708]                      \n",
      " prediction    | 0.0                                                          \n",
      "-RECORD 1---------------------------------------------------------------------\n",
      " user_id       | 754230                                                       \n",
      " item_id       | 10210                                                        \n",
      " features      | [72.0,16.0,2014.0,2009.9166666666667,0.0,4.083333492279053]  \n",
      " rawPrediction | [0.5693210822338086,-0.5693210822338086]                     \n",
      " probability   | [0.757430251546605,0.24256974845339496]                      \n",
      " prediction    | 0.0                                                          \n",
      "-RECORD 2---------------------------------------------------------------------\n",
      " user_id       | 754230                                                       \n",
      " item_id       | 83549                                                        \n",
      " features      | [72.0,1.0,1958.0,2009.9166666666667,26.0,-51.91666793823242] \n",
      " rawPrediction | [0.18058212758469805,-0.18058212758469805]                   \n",
      " probability   | [0.5893222381591885,0.4106777618408115]                      \n",
      " prediction    | 0.0                                                          \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds.show(n=3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(FloatType())\n",
    "def get_prob(col_1):\n",
    "    return float(col_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preds.select(F.col(\"user_id\"), F.col(\"item_id\"), get_prob(F.col(\"probability\")).alias(\"purchase\")) \\\n",
    ".orderBy(F.col(\"user_id\").asc(), F.col(\"item_id\").asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------\n",
      " user_id  | 1654        \n",
      " item_id  | 336         \n",
      " purchase | 0.07027356  \n",
      "-RECORD 1---------------\n",
      " user_id  | 1654        \n",
      " item_id  | 678         \n",
      " purchase | 0.07027356  \n",
      "-RECORD 2---------------\n",
      " user_id  | 1654        \n",
      " item_id  | 691         \n",
      " purchase | 0.067733474 \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(n=3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранить и выйти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.toPandas().to_csv(\"../lab03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
