{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лаба 4. Прогнозирование пола и возрастной категории — Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 8 --executor-memory 4g --executor-cores 2 --driver-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Laba_4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcdc95f5048>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[2]\") \\\n",
    "                    .appName(\"Laba_4\") \\\n",
    "                    .config(\"spark.driver.memory\", \"512m\") \\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, FloatType, ArrayType, StringType, IntegerType, LongType\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf, col, when, isnan, isnull, broadcast, desc, lower, pandas_udf, row_number, explode, expr, split\n",
    "from pyspark.sql.functions import array, collect_set, lit, from_json, to_json, struct, regexp_replace\n",
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs  655090069 2022-01-06 18:46 /labs/slaba04/gender_age_dataset.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/labs/slaba04/gender_age_dataset.txt'\n",
    "\n",
    "schema = (\n",
    "    StructType()\n",
    "    .add(\"gender\", StringType(), True)\n",
    "    .add(\"age\", StringType(), True)\n",
    "    .add(\"uid\", StringType(), True)\n",
    "    .add(\"user_json\", StringType(), True)\n",
    ")\n",
    "      \n",
    "train_data = (spark.read.format(\"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"sep\", \"\\t\")\n",
    "            .schema(schema)\n",
    "            .load(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+\n",
      "|gender|  age|                 uid|           user_json|\n",
      "+------+-----+--------------------+--------------------+\n",
      "|     F|18-24|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|\n",
      "|     M|25-34|d502331d-621e-472...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d50237ea-747e-48a...|{\"visits\": [{\"url...|\n",
      "|     F|25-34|d502f29f-d57a-46b...|{\"visits\": [{\"url...|\n",
      "|     M| >=55|d503c3b2-a0c2-4f4...|{\"visits\": [{\"url...|\n",
      "+------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41138"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.filter(train_data['gender'] != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36138"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "VisitsType = StructType([\n",
    "    StructField(\"visits\", ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"url\", StringType(), True),\n",
    "            StructField(\"timestamp\", LongType(), True) \n",
    "            ])\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = train_data \\\n",
    "    .withColumn(\"visits\", from_json(col(\"user_json\"), VisitsType)) \\\n",
    "    .withColumn(\"visit\", explode(\"visits.visits\").alias(\"visit\")) \\\n",
    "    .withColumn(\"host\", expr(\"parse_url(visit.url, 'HOST')\").alias(\"host\")) \\\n",
    "    .withColumn('domain', regexp_replace('host', 'www.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_res = clean_df \\\n",
    "    .groupBy(\"gender\", \"age\", \"uid\") \\\n",
    "    .agg(collect_set(\"domain\") \\\n",
    "    .alias(\"domains\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " gender  | F                                                                                                                                                                           \n",
      " age     | 18-24                                                                                                                                                                       \n",
      " uid     | 09b1ecd3-b2d2-4c1b-857a-025c0509d9ec                                                                                                                                        \n",
      " domains | [tankionline.com]                                                                                                                                                           \n",
      "-RECORD 1------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " gender  | F                                                                                                                                                                           \n",
      " age     | 18-24                                                                                                                                                                       \n",
      " uid     | 15faf063-5e44-4b65-b1fb-21fb8a18ffd1                                                                                                                                        \n",
      " domains | [hotels.1001tur.ru, yandex.ru, aw.mail.ru, allods.mail.ru, echo.msk.ru, world.fedpress.ru, news.yandex.ru, ru.wgleague.net, masterh4.adriver.ru, mk.ru, petrovka-beauty.ru] \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df_res.show(2,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher_freq = HashingTF(numFeatures=1000, binary=False, inputCol=\"domains\", outputCol=\"domains_vector\")\n",
    "df_train_vector = hasher_freq.transform(clean_df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol='domains_vector', outputCol=\"domains_norm\")\n",
    "df_train_norm = normalizer.transform(df_train_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = df_train_norm.replace(['F', 'M'], ['0','1'], \"gender\") \\\n",
    "                     .replace(['18-24', '25-34', '35-44', '45-54', '>=55'], ['1','3','5','7','9'], \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_norm = df_train_norm.select(col(\"gender\").cast('float').alias(\"gender\"),col(\"age\").cast('int').alias(\"age\"),col(\"uid\"),col(\"domains\"),col(\"domains_norm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------------+--------------------+--------------------+\n",
      "|gender|age|                 uid|             domains|        domains_norm|\n",
      "+------+---+--------------------+--------------------+--------------------+\n",
      "|   0.0|  1|09b1ecd3-b2d2-4c1...|   [tankionline.com]|  (1000,[509],[1.0])|\n",
      "|   0.0|  1|15faf063-5e44-4b6...|[hotels.1001tur.r...|(1000,[43,268,293...|\n",
      "|   0.0|  1|560142d9-6c9c-439...|[yandex.ru, vk.co...|(1000,[101,218,23...|\n",
      "|   0.0|  1|6709f443-7ddd-423...|       [muzofon.com]|  (1000,[696],[1.0])|\n",
      "|   0.0|  1|67e9bd68-ef03-49c...|[yandex.ru, tempf...|(1000,[402,706,77...|\n",
      "|   0.0|  1|757ff5c2-ecdb-489...|[msn.com, dns-sho...|(1000,[416,459,82...|\n",
      "|   0.0|  1|c430a9d4-5f48-47c...|[eporner.com, 100...|(1000,[553,646,67...|\n",
      "|   0.0|  1|d1d59923-51d7-4a1...|[go.mail.ru, shop...|(1000,[667,988],[...|\n",
      "|   0.0|  1|fca5deb7-77f4-4c4...|[sprashivai.ru, b...|(1000,[115,189],[...|\n",
      "|   0.0|  3|0521da78-b729-4a0...|[mirknig.com, yon...|(1000,[95,671,835...|\n",
      "|   0.0|  3|09023c5f-d98f-47f...|[pc.img-studio.ru...|(1000,[137,693,94...|\n",
      "|   0.0|  3|205ed1e2-1504-47c...|[ubr.ua, cm.g.dou...|(1000,[352,727],[...|\n",
      "|   0.0|  3|3c295020-fe8e-483...|[indianproductson...|(1000,[97,163,217...|\n",
      "|   0.0|  3|4359c398-4a7b-4d4...|[w1050.am15.net, ...|(1000,[35,681],[0...|\n",
      "|   0.0|  3|492f6cb0-d878-4b9...|         [moskva.fm]|  (1000,[678],[1.0])|\n",
      "|   0.0|  3|4f6b1af9-a797-412...|[masterh5.adriver...|(1000,[104,205,21...|\n",
      "|   0.0|  3|4faec36e-a3b7-4fb...|[yandex.ru, ksv.s...|(1000,[208,292,54...|\n",
      "|   0.0|  3|57cc412a-b75b-485...|[audit-it.ru, ast...|(1000,[47,52,288,...|\n",
      "|   0.0|  3|5c001f97-2c9d-485...|     [pohudeyka.net]|  (1000,[562],[1.0])|\n",
      "|   0.0|  3|71850253-e82b-46a...|[vk.com, bloknot.ru]|(1000,[433,483],[...|\n",
      "+------+---+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_norm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_gendr = LogisticRegression(featuresCol='domains_norm', labelCol=\"gender\", maxIter=29, regParam=0.020436539365475917)\n",
    "lr_gendr_model = lr_gendr.fit(df_train_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_age = RandomForestClassifier(labelCol=\"age\", featuresCol=\"domains_norm\")\n",
    "rf_age_model = rf_age.fit(df_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = 'spark-node-1.newprolab.com:6667'\n",
    "KAFKA_INPUT_TOPIC = 'input_ekaterina.fisenko'\n",
    "KAFKA_OUTPUT_TOPIC = 'ekaterina.fisenko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVER,\n",
    "    \"subscribe\": KAFKA_INPUT_TOPIC,\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "kafka_sdf = spark.readStream.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_console_sink(df):\n",
    "    return df \\\n",
    "            .writeStream \\\n",
    "            .format(\"console\") \\\n",
    "            .trigger(processingTime=\"5 seconds\") \\\n",
    "            .option(\"truncate\", \"false\") \\\n",
    "            .option(\"numRows\", \"20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_sdf = kafka_sdf.select(col(\"value\").cast(\"string\"), col(\"topic\"), col(\"partition\"), col(\"offset\"))\n",
    "\n",
    "sink = create_console_sink(parsed_sdf)\n",
    "\n",
    "sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_read_df = (\n",
    "    spark.read\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8877"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_read_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_schema = StructType([\n",
    "        StructField('uid', StringType(), True)\n",
    "        , StructField('visits', StringType(),True)\n",
    "        ])\n",
    "\n",
    "visit_schema = ArrayType(\n",
    "        StructType([\n",
    "            StructField('url', StringType(), True)\n",
    "            , StructField('timestamp', LongType(), True)\n",
    "        ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    kafka_read_df\n",
    "    .select(col('value').cast('string').alias('value'))\n",
    "    .select(from_json(col('value'), event_schema).alias('event'))\n",
    "    .select(\n",
    "        'event.uid', \n",
    "        from_json(col('event.visits'), visit_schema).alias('visits')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 uid|              visits|\n",
      "+--------------------+--------------------+\n",
      "|bd7a30e1-a25d-4cb...|[[http://www.inte...|\n",
      "|bd7a6f52-45db-49b...|[[https://www.pac...|\n",
      "|bd7a7fd9-ab06-42f...|[[http://www.mk.r...|\n",
      "|bd7c5d7a-0def-41d...|[[http://www.24op...|\n",
      "|bd7e54a2-0215-45c...|[[http://www.dns-...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df \\\n",
    "    .withColumn(\"visit\", explode(\"visits\").alias(\"visit\")) \\\n",
    "    .withColumn(\"host\", expr(\"parse_url(visit.url, 'HOST')\").alias(\"host\")) \\\n",
    "    .withColumn('domain', regexp_replace('host', 'www.', '')) \\\n",
    "    .groupBy(\"uid\") \\\n",
    "    .agg(collect_set(\"domain\").alias(\"domains\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_vector = hasher_freq.transform(clean_df)\n",
    "clean_df_norm = normalizer.transform(clean_df_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_norm_1 = lr_gendr_model.transform(clean_df_norm)\n",
    "clean_df_norm_2 = rf_age_model.transform(clean_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_norm_1.select(\"uid\", \"prediction\").createOrReplaceTempView(\"gender\")\n",
    "clean_df_norm_2.select(\"uid\", \"prediction\").createOrReplaceTempView(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = spark.sql(\"\"\"SELECT g.uid\n",
    "                , CAST(CAST(g.prediction AS INT) AS String) AS gender\n",
    "                , CAST(CAST(a.prediction AS INT) AS String) AS age\n",
    "                FROM gender g\n",
    "                JOIN age a\n",
    "                ON g.uid = a.uid\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---+\n",
      "|                 uid|gender|age|\n",
      "+--------------------+------+---+\n",
      "|0108d217-e476-493...|     1|  3|\n",
      "|0192cc54-559c-4c8...|     1|  3|\n",
      "|019acd5e-be9a-4cd...|     0|  3|\n",
      "|02e7f830-da57-4d5...|     1|  3|\n",
      "|1d160259-73d8-451...|     0|  3|\n",
      "+--------------------+------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.replace(['0','1'], ['F', 'M'], \"gender\") \\\n",
    "                     .replace(['1','3','5','7','9'], ['18-24', '25-34', '35-44', '45-54', '>=55'], \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+\n",
      "|                 uid|gender|  age|\n",
      "+--------------------+------+-----+\n",
      "|0108d217-e476-493...|     M|25-34|\n",
      "|0192cc54-559c-4c8...|     M|25-34|\n",
      "|019acd5e-be9a-4cd...|     F|25-34|\n",
      "|02e7f830-da57-4d5...|     M|25-34|\n",
      "|1d160259-73d8-451...|     F|25-34|\n",
      "+--------------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDF = out_df.select(lit(\"\").alias('key'), to_json(struct(*out_df.columns)).alias('value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|key|               value|\n",
      "+---+--------------------+\n",
      "|   |{\"uid\":\"0108d217-...|\n",
      "|   |{\"uid\":\"0192cc54-...|\n",
      "|   |{\"uid\":\"019acd5e-...|\n",
      "|   |{\"uid\":\"02e7f830-...|\n",
      "|   |{\"uid\":\"1d160259-...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pDF.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "    .write\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('topic', KAFKA_OUTPUT_TOPIC)\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
