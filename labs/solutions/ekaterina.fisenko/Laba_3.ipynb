{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 2 --driver-memory 4g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Laba_3\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Laba_3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3828f62358>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, FloatType, ArrayType, StringType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf, col, when, isnan, isnull, broadcast, lower, pandas_udf, row_number, explode, split\n",
    "from pyspark.sql.functions import array, collect_set, collect_list, lit, asc, desc, sum, count, PandasUDFType\n",
    "from pyspark.mllib.linalg import Vectors, SparseVector, DenseVector, VectorUDT\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2022-01-06 18:46 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2022-01-06 18:46 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2022-01-06 18:46 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2022-01-06 18:46 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id\tchannel_id\tdatetime_availability_start\tdatetime_availability_stop\tdatetime_show_start\tdatetime_show_stop\tcontent_type\ttitle\tyear\tgenres\tregion_id\r\n",
      "65667\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t1\tна пробах только девушки (all girl auditions)\t2013.0\tЭротика\t\r\n",
      "65669\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t1\tскуби ду: эротическая пародия (scooby doo: a xxx parody)\t2011.0\tЭротика\t\r\n",
      "65668\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t1\tгорячие девочки для горячих девочек (hot babes 4 hot babes)\t2011.0\tЭротика\t\r\n",
      "65671\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t1\tсоблазнительницы женатых мужчин (top heavy homewreckers)\t2011.0\tЭротика\t\r\n",
      "65670\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t1\tсекретные секс-материалы ii: темная секс пародия (the sex files ii: a dark xxx parody)\t2010.0\tЭротика\t\r\n",
      "65809\t\t1970-01-01T00:00:00Z\t2099-12-31"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -head /labs/slaba03/laba03_items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (StructType()\n",
    "      .add(\"user_id\", IntegerType(), True)\n",
    "      .add(\"item_id\", IntegerType(), True)\n",
    "      .add(\"purchase\", IntegerType(), True))\n",
    "      \n",
    "df_user = (spark.read.format(\"csv\")\n",
    "           .option(\"header\", True)\n",
    "           .schema(schema)\n",
    "           .load(\"/labs/slaba03/laba03_train.csv\")\n",
    "           .repartition(16)\n",
    "           .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "| 613775|  74106|       0|\n",
      "| 753356|   5359|       0|\n",
      "| 782217|  94658|       0|\n",
      "| 753619|  72394|       0|\n",
      "| 793430|  11277|       0|\n",
      "| 770209|   9840|       0|\n",
      "| 769240|  79851|       0|\n",
      "| 529632|  93621|       0|\n",
      "| 789967|  10689|       0|\n",
      "| 748500|  74517|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (StructType()\n",
    "      .add(\"user_id\", IntegerType(), True)\n",
    "      .add(\"item_id\", IntegerType(), True)) \n",
    "      \n",
    "      \n",
    "df_user_test = (spark.read.format(\"csv\")\n",
    "                .option(\"header\", True)\n",
    "                .schema(schema)\n",
    "                .load(\"/labs/slaba03/laba03_test.csv\")\n",
    "                .repartition(16)\n",
    "                .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_type</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>805112</td>\n",
       "      <td>6688671</td>\n",
       "      <td>live</td>\n",
       "      <td>13196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>800010</td>\n",
       "      <td>6699896</td>\n",
       "      <td>live</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>857986</td>\n",
       "      <td>7379100</td>\n",
       "      <td>live</td>\n",
       "      <td>9402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>785896</td>\n",
       "      <td>6316490</td>\n",
       "      <td>live</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>888511</td>\n",
       "      <td>6379455</td>\n",
       "      <td>live</td>\n",
       "      <td>13073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id item_type  duration\n",
       "0   805112  6688671      live     13196\n",
       "1   800010  6699896      live       958\n",
       "2   857986  7379100      live      9402\n",
       "3   785896  6316490      live      1838\n",
       "4   888511  6379455      live     13073"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_users_schema = StructType(fields=[\n",
    "    StructField('user_id', IntegerType()),\n",
    "    StructField('item_id', IntegerType()),\n",
    "    StructField('ts_start', IntegerType()),\n",
    "    StructField('ts_end', IntegerType()),\n",
    "    StructField('item_type', StringType()),\n",
    "])\n",
    "\n",
    "df_views_programmes = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(read_users_schema) \\\n",
    "      .load(\"/labs/slaba03/laba03_views_programmes.csv\")\n",
    "\n",
    "df_views_programmes = (df_views_programmes\n",
    "                       .withColumn('duration', df_views_programmes.ts_end - df_views_programmes.ts_start)\n",
    "                       .drop('ts_start', 'ts_end'))\n",
    "\n",
    "df_views_programmes = df_views_programmes.groupby('user_id', 'item_id', 'item_type').agg(sum(\"duration\").alias(\"duration\"))\n",
    "\n",
    "df_views_programmes = df_views_programmes.repartition(16).cache()\n",
    "\n",
    "df_views_programmes.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "read_items_schema = StructType(fields=[\n",
    "    StructField('item_id', IntegerType()), \n",
    "    StructField('channel_id', FloatType(), nullable=True),\n",
    "    StructField('datetime_availability_start', StringType(), nullable=True),\n",
    "    StructField('datetime_availability_stop', StringType(), nullable=True),\n",
    "    StructField('datetime_show_start', StringType(), nullable=True),\n",
    "    StructField('datetime_show_stop', StringType(), nullable=True),\n",
    "    StructField('content_type', IntegerType()),\n",
    "    StructField('title', StringType(), nullable=True),\n",
    "    StructField('year', FloatType(), nullable=True),\n",
    "    StructField('genres', StringType(), nullable=True),\n",
    "    StructField('region_id', FloatType(), nullable=True),\n",
    "])\n",
    "\n",
    "df_items = (spark.read.format(\"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"sep\", \"\\t\")\n",
    "            .schema(read_items_schema)\n",
    "            .load(\"/labs/slaba03/laba03_items.csv\")\n",
    "           )\n",
    "\n",
    "df_items = (df_items\n",
    "            .withColumn(\"year\", \n",
    "                        when(df_items.item_id == 103377, 2008.0)\n",
    "                        .when(df_items.item_id == 95141, 2014.0)\n",
    "                        .when(df_items.item_id == 72544, 2009.0)\n",
    "                        .when(df_items.item_id == 8544, 1994.0)\n",
    "                        .otherwise(df_items.year))\n",
    "            .withColumn(\"genres\", \n",
    "                        when(df_items.item_id == 103377, 'Анимация,Короткометражные')\n",
    "                        .otherwise(df_items.genres))\n",
    "           )\n",
    "    \n",
    "df_items = (df_items.repartition(16).cache())\n",
    "\n",
    "print(df_items.filter(df_items.item_id.isNull()).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>datetime_availability_start</th>\n",
       "      <th>datetime_availability_stop</th>\n",
       "      <th>datetime_show_start</th>\n",
       "      <th>datetime_show_stop</th>\n",
       "      <th>content_type</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>region_id</th>\n",
       "      <th>year_cat</th>\n",
       "      <th>year_cat_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01T00:00:00Z</td>\n",
       "      <td>2099-12-31T21:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>тарбозавр 3d</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Полнометражные,Западные мультфильмы,Для детей,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970-01-01T00:00:00Z</td>\n",
       "      <td>2099-12-31T21:00:00Z</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>марин и его друзья. подводные истории</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Западные мультфильмы,Сериалы,Для детей,Зарубежные</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  channel_id datetime_availability_start datetime_availability_stop  \\\n",
       "0    74429         NaN        1970-01-01T00:00:00Z       2099-12-31T21:00:00Z   \n",
       "1    72413         NaN        1970-01-01T00:00:00Z       2099-12-31T21:00:00Z   \n",
       "\n",
       "  datetime_show_start datetime_show_stop  content_type  \\\n",
       "0                None               None             1   \n",
       "1                None               None             1   \n",
       "\n",
       "                                   title    year  \\\n",
       "0                           тарбозавр 3d  2011.0   \n",
       "1  марин и его друзья. подводные истории  2015.0   \n",
       "\n",
       "                                              genres  region_id year_cat  \\\n",
       "0  Полнометражные,Западные мультфильмы,Для детей,...        NaN     [11]   \n",
       "1  Западные мультфильмы,Сериалы,Для детей,Зарубежные        NaN     [11]   \n",
       "\n",
       "  year_cat_str  \n",
       "0           11  \n",
       "1           11  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items = (\n",
    "    df_items\n",
    "    .withColumn(\"year_cat\", array((((df_items.year - 1910.0)/10) + 1).cast(IntegerType()).cast(StringType())))\n",
    "    .withColumn(\"year_cat_str\", (((df_items.year - 1910.0)/10) + 1).cast(IntegerType()).cast(StringType()))\n",
    ")\n",
    "\n",
    "df_items.filter(df_items.year.isNotNull()).limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|item_id| year_cat_norm|\n",
      "+-------+--------------+\n",
      "|6310504|(12,[0],[1.0])|\n",
      "|6235208|(12,[0],[1.0])|\n",
      "|6200617|(12,[0],[1.0])|\n",
      "|6234759|(12,[0],[1.0])|\n",
      "|6326768|(12,[0],[1.0])|\n",
      "+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items = df_items.drop('year_cat_vector')\n",
    "count_vectorizer_year = CountVectorizer(inputCol='year_cat', outputCol=\"year_cat_vector\", binary=False)\n",
    "count_vectorizer_year_model = count_vectorizer_year.fit(df_items)\n",
    "df_items = count_vectorizer_year_model.transform(df_items)\n",
    "\n",
    "\n",
    "normalizer_year = Normalizer(inputCol='year_cat_vector', outputCol=\"year_cat_norm\")\n",
    "df_items_year = normalizer_year.transform(df_items).select('item_id', 'year_cat_norm')\n",
    "df_items = df_items.drop(\"year_cat_vector\")\n",
    "\n",
    "df_items_year.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_year = (df_user\n",
    "                .filter(df_user.purchase == 1)\n",
    "                .join(df_items, df_user.item_id == df_items.item_id, 'left')\n",
    "                .select(df_user.user_id, df_items.year_cat_str.alias(\"year_cat_str\")))\n",
    "           \n",
    "df_user_uniq = df_user.select('user_id').distinct()\n",
    "df_user_year = (df_user_uniq\n",
    "                .join(df_user_year, df_user_uniq.user_id == df_user_year.user_id, 'left')\n",
    "                .select(df_user_uniq.user_id, df_user_year.year_cat_str))\n",
    "    \n",
    "df_user_year = df_user_year.groupBy('user_id').agg(collect_set('year_cat_str').alias('year_cat'))\n",
    "df_user_year = count_vectorizer_year_model.transform(df_user_year)\n",
    "df_user_year = normalizer_year.transform(df_user_year)\n",
    "df_user_year = df_user_year.drop(\"year_cat\", \"year_cat_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|item_id|  item_purchase_rate|\n",
      "+-------+--------------------+\n",
      "|  94851|7.288629737609329E-4|\n",
      "|  90019|0.002281368821292...|\n",
      "|  78113|0.001468428781204...|\n",
      "|  95080|                 0.0|\n",
      "|   8638|0.001450326323422...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_item_stat = df_user.groupby(\"item_id\").agg(sum(\"purchase\").alias(\"sum_purchase\"), count(\"purchase\").alias(\"count_purchase\"))\n",
    "df_user_item_stat = df_user_item_stat.withColumn(\"item_purchase_rate\", df_user_item_stat.sum_purchase / df_user_item_stat.count_purchase)\n",
    "df_user_item_stat = df_user_item_stat.select(\"item_id\", \"item_purchase_rate\")\n",
    "\n",
    "df_user_item_stat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|  user_purchase_rate|\n",
      "+-------+--------------------+\n",
      "| 780033|7.757951900698216E-4|\n",
      "| 761341|3.875968992248062E-4|\n",
      "| 776188|0.001152516327314637|\n",
      "| 754230|0.027575641516660282|\n",
      "| 833685|0.007500986971969996|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_user_stat = df_user.groupby(\"user_id\").agg(sum(\"purchase\").alias(\"sum_purchase\"), count(\"purchase\").alias(\"count_purchase\"))\n",
    "df_user_user_stat = df_user_user_stat.withColumn(\"user_purchase_rate\", df_user_user_stat.sum_purchase / df_user_user_stat.count_purchase)\n",
    "df_user_user_stat = df_user_user_stat.select(\"user_id\", \"user_purchase_rate\")\n",
    "\n",
    "df_user_user_stat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_genres(s):\n",
    "    replace_map = {\n",
    "        'Арт-хаус': 'Артхаус',\n",
    "        'Боевики': 'Боевик',\n",
    "        'Военные': 'Военный',\n",
    "        'Военные': 'Военный',\n",
    "        'Детские': 'Детский',\n",
    "        'Для детей': 'Детский',\n",
    "        'Для самых маленьких': 'Детский',\n",
    "        'Для всей семьи': 'Семейные',\n",
    "        'Для взрослых': 'Эротика',\n",
    "        'Документальные': 'Документальный',\n",
    "        'Драмы': 'Драма',\n",
    "        'Западные мультфильмы': 'Зарубежные,Анимация',\n",
    "        'Исторические': 'Исторический',\n",
    "        'Короткометражки': 'Короткометражные',\n",
    "        'Детский песни': 'Детский,Музыкальные',\n",
    "        'Мультфильмы в 3D': 'Анимация',\n",
    "        'Мультфильмы': 'Анимация',\n",
    "        'Мультсериалы': 'Анимация,Сериалы',\n",
    "        'Мюзиклы': 'Музыкальные',\n",
    "        'Русские мультфильмы': 'Анимация,Русские',\n",
    "        'Аниме': 'Анимация',\n",
    "        'Спорт': 'Спортивные',\n",
    "        'Спортивныеивные': 'Спортивные',\n",
    "        'Наши': 'Русские',\n",
    "        'Фильмы в 3D': 'Фильмы',\n",
    "        'Юмористические': 'Юмористические,Передачи',\n",
    "        'Кулинария': 'Передачи',\n",
    "        'Игры': 'Передачи',\n",
    "        'О здоровье': 'Передачи',\n",
    "        'Охота и рыбалка': 'Передачи',\n",
    "        'Реалити-шоу': 'Передачи',\n",
    "        'Видеоигры': 'Видеоигры,Передачи',\n",
    "        'Фильмы-спектакли': 'Музыкальные,Фильмы',\n",
    "        'Познавательные': 'Развивающие,Передачи',\n",
    "        'Хочу всё знать': 'Развивающие,Передачи',\n",
    "        'Фантастические': 'Фантастика',\n",
    "        'Фэнтези': 'Фантастика',\n",
    "        'Союзмультфильм': 'Союзмультфильм,Анимация',\n",
    "        'Юмористические': 'Комедии',\n",
    "        'Развлекательные': 'Комедии',\n",
    "        'Комедия': 'Комедии',\n",
    "        'Вестерн': 'Фильмы,Зарубежные,Боевик',\n",
    "        'Советское кино': 'Советские,Фильмы',\n",
    "        'Прочие': 'General',\n",
    "        'Мультфильм': 'Анимация',\n",
    "        'Музыкальный': 'Музыкальные',\n",
    "        'Семейный': 'Семейные',\n",
    "        'Приключение': 'Приключения',\n",
    "        'Научная фантастика': 'Фантастика',\n",
    "        'сказка': 'Сказки',\n",
    "        'Триллер': 'Триллеры',\n",
    "    }\n",
    "    if s is None:\n",
    "        return ['General']\n",
    "    \n",
    "    for key in replace_map:\n",
    "        s = str(s).replace(key, replace_map[key])\n",
    "        \n",
    "    return s.split(',')\n",
    "\n",
    "replace_genres_udf = udf(replace_genres, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|item_id|   genres_norm|\n",
      "+-------+--------------+\n",
      "|6310504|(41,[0],[1.0])|\n",
      "|6235208|(41,[0],[1.0])|\n",
      "|6200617|(41,[0],[1.0])|\n",
      "|6234759|(41,[0],[1.0])|\n",
      "|6326768|(41,[0],[1.0])|\n",
      "+-------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_items_genres = df_items.withColumn(\"genres_arr\", replace_genres_udf(\"genres\"))\n",
    "\n",
    "count_vectorizer = CountVectorizer(inputCol='genres_arr', outputCol=\"genres_vector\", binary=False)\n",
    "count_vectorizer_model = count_vectorizer.fit(df_items_genres)\n",
    "df_items_genres = count_vectorizer_model.transform(df_items_genres)\n",
    "\n",
    "normalizer = Normalizer(inputCol='genres_vector', outputCol=\"genres_norm\")\n",
    "df_items_genres = normalizer.transform(df_items_genres)\n",
    "\n",
    "df_items_genres = df_items_genres.select('item_id', 'genres_norm')\n",
    "\n",
    "df_items_genres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------------+\n",
      "|user_id|   genres_vector_all|genres_vector_purchase|\n",
      "+-------+--------------------+----------------------+\n",
      "| 754230|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|\n",
      "| 761341|(41,[0,1,2,3,4,5,...|        (41,[0],[1.0])|\n",
      "| 776188|(41,[0,1,2,3,4,5,...|  (41,[1,3,4,6,8,9,...|\n",
      "| 780033|(41,[0,1,2,3,4,5,...|  (41,[1,4,6,8,15],...|\n",
      "| 798454|(41,[0,1,2,3,4,5,...|  (41,[6,11,12],[1....|\n",
      "+-------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_genres = (\n",
    "    df_user\n",
    "    .join(df_items, df_user.item_id == df_items.item_id, 'inner')\n",
    "    .select(\n",
    "        df_user.user_id, \n",
    "        replace_genres_udf(df_items.genres).alias(\"genres_arr\"), \n",
    "        df_user.purchase\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "df_user_genres = df_user_genres.select(\n",
    "    df_user_genres.user_id, \n",
    "    explode(df_user_genres.genres_arr).alias('genres'), \n",
    "    df_user.purchase\n",
    ")\n",
    "\n",
    "df_user_genres_all = df_user_genres.groupBy('user_id').agg(collect_list('genres').alias('genres_arr'))\n",
    "df_user_genres_all = count_vectorizer_model.transform(df_user_genres_all)\n",
    "\n",
    "\n",
    "df_user_genres_purchase = df_user_genres.filter(df_user.purchase == 1)\n",
    "df_user_uniq = df_user.select('user_id').distinct()\n",
    "df_user_genres_purchase = (df_user_uniq\n",
    "                .join(df_user_genres_purchase, df_user_uniq.user_id == df_user_genres_purchase.user_id, 'left')\n",
    "                .select(df_user_uniq.user_id, df_user_genres_purchase.genres))\n",
    "\n",
    "df_user_genres_purchase = (\n",
    "    df_user_genres_purchase\n",
    "    .groupBy('user_id')\n",
    "    .agg(collect_list('genres').alias('genres_arr')))\n",
    "df_user_genres_purchase = count_vectorizer_model.transform(df_user_genres_purchase)\n",
    "\n",
    "df_user_genres = df_user_genres_all.join(\n",
    "    df_user_genres_purchase,\n",
    "    df_user_genres_all.user_id == df_user_genres_purchase.user_id,\n",
    "    'inner'\n",
    ").select(\n",
    "    df_user_genres_all.user_id, \n",
    "    df_user_genres_all.genres_vector.alias('genres_vector_all'),\n",
    "    df_user_genres_purchase.genres_vector.alias('genres_vector_purchase') \n",
    ")\n",
    "\n",
    "df_user_genres.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+----------------------+\n",
      "|user_id|genres_vector_all|genres_vector_purchase|\n",
      "+-------+-----------------+----------------------+\n",
      "+-------+-----------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_genres.filter(df_user_genres.genres_vector_purchase.isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_user.select(df_user.user_id, df_user.item_id, df_user.purchase.alias('target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+----------------------+--------------------+\n",
      "|user_id|item_id|target|   genres_vector_all|genres_vector_purchase|         genres_norm|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+\n",
      "| 754230|  78087|     0|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[2,4,24,25,26...|\n",
      "| 754230|  77839|     0|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[3,16,17,18],...|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = (df_train\n",
    "            .join(df_user_genres, df_train.user_id == df_user_genres.user_id, 'inner')\n",
    "            .join(df_items_genres, df_train.item_id == df_items_genres.item_id, 'inner')\n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                \n",
    "                df_user_genres.genres_vector_all,\n",
    "                df_user_genres.genres_vector_purchase,\n",
    "                df_items_genres.genres_norm\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+----------------------+--------------------+------------------+--------------------+\n",
      "|user_id|item_id|target|   genres_vector_all|genres_vector_purchase|         genres_norm|user_purchase_rate|  item_purchase_rate|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+------------------+--------------------+\n",
      "| 816426|  91200|     0|(41,[0,1,2,3,4,5,...|            (41,[],[])|(41,[1,3,4,9],[0....|               0.0|7.358351729212656E-4|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+------------------+--------------------+\n",
      "\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "|user_id|item_id|target|   genres_vector_all|genres_vector_purchase|         genres_norm|  user_purchase_rate|  item_purchase_rate|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "| 754230|   8389|     0|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[2,5,7,23],[0...|0.027575641516660282|0.005979073243647235|\n",
      "| 780033|   8389|     0|(41,[0,1,2,3,4,5,...|  (41,[1,4,6,8,15],...|(41,[2,5,7,23],[0...|7.757951900698216E-4|0.005979073243647235|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = (df_train\n",
    "            .join(df_user_user_stat, df_user_user_stat.user_id == df_train.user_id, 'inner')\n",
    "            .join(df_user_item_stat, df_user_item_stat.item_id == df_train.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                df_train.genres_vector_all,\n",
    "                df_train.genres_vector_purchase,\n",
    "                df_train.genres_norm,\n",
    "                \n",
    "                df_user_user_stat.user_purchase_rate,\n",
    "                df_user_item_stat.item_purchase_rate,\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "df_train.filter((df_train.user_id == 816426) & (df_train.item_id == 91200)).show()\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "|user_id|item_id|target|   genres_vector_all|genres_vector_purchase|         genres_norm|  user_purchase_rate|  item_purchase_rate|      user_year_norm|item_year_norm|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "| 754230|   8389|     0|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[2,5,7,23],[0...|0.027575641516660282|0.005979073243647235|(12,[1,2,4,7],[0....|(12,[3],[1.0])|\n",
      "| 754230|   8638|     1|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[1,4,6,12,20]...|0.027575641516660282|0.001450326323422...|(12,[1,2,4,7],[0....|(12,[1],[1.0])|\n",
      "+-------+-------+------+--------------------+----------------------+--------------------+--------------------+--------------------+--------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = (df_train\n",
    "            .join(df_user_year, df_user_year.user_id == df_train.user_id, 'inner')\n",
    "            .join(df_items_year, df_items_year.item_id == df_train.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                df_train.genres_vector_all,\n",
    "                df_train.genres_vector_purchase,\n",
    "                df_train.genres_norm,\n",
    "                df_train.user_purchase_rate,\n",
    "                df_train.item_purchase_rate,\n",
    "                \n",
    "                df_user_year.year_cat_norm.alias('user_year_norm'),\n",
    "                df_items_year.year_cat_norm.alias('item_year_norm')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|(125,[0,1,2,3,4,5...|     0|\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "|(125,[0,1,2,3,4,5...|     0|\n",
      "|(125,[0,1,2,3,4,5...|     0|\n",
      "|(125,[0,1,2,3,4,5...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"genres_vector_all\", \"genres_vector_purchase\", \"genres_norm\", \n",
    "        \"user_purchase_rate\", \"item_purchase_rate\"\n",
    "    ], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_train = assembler.transform(df_train).select(\"features\", \"target\")\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5021720\n",
      "10904\n",
      "11073\n",
      "10904\n"
     ]
    }
   ],
   "source": [
    "print(df_train.filter(df_train.target == 0).count())\n",
    "print(df_train.filter(df_train.target == 1).count())\n",
    "\n",
    "samle_count = df_train.filter(df_train.target == 1).count() / df_train.filter(df_train.target == 0).count()\n",
    "\n",
    "df_train = df_train.filter(df_train.target == 1).union(df_train.filter(df_train.target == 0).sample(samle_count)).coalesce(10)\n",
    "\n",
    "print(df_train.filter(df_train.target == 0).count())\n",
    "print(df_train.filter(df_train.target == 1).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|target|\n",
      "+--------------------+------+\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "|(125,[0,1,2,3,4,5...|     1|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol=\"target\", maxIter=15)\n",
    "lr_model = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+----------------------+--------------------+\n",
      "|user_id|item_id|   genres_vector_all|genres_vector_purchase|         genres_norm|\n",
      "+-------+-------+--------------------+----------------------+--------------------+\n",
      "| 754230| 102033|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[2,9],[0.7071...|\n",
      "| 754230| 100303|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|      (41,[3],[1.0])|\n",
      "| 754230|  79874|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[4,10],[0.707...|\n",
      "| 754230| 101646|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[2,5,7,14,19,...|\n",
      "| 754230|  93488|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,5,6,...|(41,[6,12,15],[0....|\n",
      "+-------+-------+--------------------+----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = (df_test\n",
    "            .join(df_user_genres, df_test.user_id == df_user_genres.user_id, 'inner')\n",
    "            .join(df_items_genres, df_test.item_id == df_items_genres.item_id, 'inner')\n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                \n",
    "                df_user_genres.genres_vector_all,\n",
    "                df_user_genres.genres_vector_purchase,\n",
    "                df_items_genres.genres_norm\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "|user_id|item_id|   genres_vector_all|genres_vector_purchase|         genres_norm|  user_purchase_rate|  item_purchase_rate|\n",
      "+-------+-------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "| 761341|   8389|(41,[0,1,2,3,4,5,...|        (41,[0],[1.0])|(41,[2,5,7,23],[0...|3.875968992248062E-4|0.005979073243647235|\n",
      "| 776188|   8389|(41,[0,1,2,3,4,5,...|  (41,[1,3,4,6,8,9,...|(41,[2,5,7,23],[0...|0.001152516327314637|0.005979073243647235|\n",
      "| 846231|   8389|(41,[0,1,2,3,4,5,...|  (41,[1,2,3,4,6,8,...|(41,[2,5,7,23],[0...|0.001923816852635629|0.005979073243647235|\n",
      "| 822709|   8389|(41,[0,1,2,3,4,5,...|  (41,[4,9],[1.0,1.0])|(41,[2,5,7,23],[0...|3.789314134141720...|0.005979073243647235|\n",
      "| 824008|   8389|(41,[0,1,2,3,4,5,...|  (41,[1,4],[1.0,1.0])|(41,[2,5,7,23],[0...|3.821169277799006...|0.005979073243647235|\n",
      "+-------+-------+--------------------+----------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = (df_test\n",
    "            .join(df_user_user_stat, df_user_user_stat.user_id == df_test.user_id, 'inner')\n",
    "            .join(df_user_item_stat, df_user_item_stat.item_id == df_test.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                df_test.genres_vector_all,\n",
    "                df_test.genres_vector_purchase,\n",
    "                df_test.genres_norm,\n",
    "                \n",
    "                df_user_user_stat.user_purchase_rate,\n",
    "                df_user_item_stat.item_purchase_rate,\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = (df_test\n",
    "            .join(df_user_year, df_user_year.user_id == df_test.user_id, 'inner')\n",
    "            .join(df_items_year, df_items_year.item_id == df_test.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                df_test.genres_vector_all,\n",
    "                df_test.genres_vector_purchase,\n",
    "                df_test.genres_norm,\n",
    "                df_test.user_purchase_rate,\n",
    "                df_test.item_purchase_rate,\n",
    "                \n",
    "                df_user_year.year_cat_norm.alias('user_year_norm'),\n",
    "                df_items_year.year_cat_norm.alias('item_year_norm')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"genres_vector_all\", \"genres_vector_purchase\", \"genres_norm\", \n",
    "               \"user_purchase_rate\", \"item_purchase_rate\"\n",
    "              ], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_test = assembler.transform(df_test).select(\"user_id\", \"item_id\", \"features\")\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(df_test)\n",
    "# predictions = gbtc_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1851975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>304865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction    count\n",
       "0         0.0  1851975\n",
       "1         1.0   304865"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.groupby('prediction').count().limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156840\n",
      "2156840\n",
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "| 938008|  94183|     0.0|\n",
      "| 928787|  99730|     0.0|\n",
      "| 801678|  73229|     0.0|\n",
      "| 878233|  78285|     0.0|\n",
      "| 894258|  98731|     0.0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = (df_user_test\n",
    "                .join(predictions, \n",
    "                      (df_user_test.user_id == predictions.user_id) & (df_user_test.item_id == predictions.item_id), \n",
    "                      'left')\n",
    "                .select(df_user_test.user_id, df_user_test.item_id, predictions.prediction.alias(\"purchase\"))\n",
    "                .fillna(value=0.0, subset=[\"purchase\"])\n",
    "                .repartition(10)\n",
    "                .cache()\n",
    "               )\n",
    "\n",
    "print(df_user_test.count())\n",
    "print(predictions.count())\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (predictions\n",
    "      .sort(\"user_id\", \"item_id\")\n",
    "      .toPandas())\n",
    "\n",
    "df.to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
