{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"korneev\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4055\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>mshrm_lab4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2718161898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, HashingTF, IDF, IDFModel\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "from pyspark.sql.functions import struct, to_json\n",
    "from pyspark.sql.types import StructType, StringType, StructField, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs  655090069 2022-01-06 18:46 /labs/slaba04/gender_age_dataset.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fields = [StructField(\"gender\", StringType()),\n",
    "               StructField(\"age\", StringType()),\n",
    "               StructField(\"uid\", StringType()),\n",
    "               StructField(\"user_json\", StringType())]\n",
    "schema = StructType(list_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.load(\"/labs/slaba04/gender_age_dataset.txt\",\n",
    "                          format=\"csv\",\n",
    "                          sep=\"\\t\",\n",
    "                          header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+\n",
      "|gender|  age|                 uid|           user_json|\n",
      "+------+-----+--------------------+--------------------+\n",
      "|     F|18-24|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|\n",
      "|     M|25-34|d502331d-621e-472...|{\"visits\": [{\"url...|\n",
      "+------+-----+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " gender    | F                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      " age       | 18-24                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
      " uid       | d50192e5-c44e-4ae8-ae7a-7cfe67c8b777                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " user_json | {\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]} \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_json(x):\n",
    "    string = str(x)\n",
    "    string = \" \".join([urls.get(\"url\") for urls in eval(string)['visits']])\n",
    "    string = re.split('\\W', string)\n",
    "    #stop_words\n",
    "#     stop_words = []\n",
    "#     string = [x if x not in stop_words else \"\" for x in string]\n",
    "    string = \" \".join(string)\n",
    "    return string\n",
    "\n",
    "udf_prepare_user_json = f.udf(lambda x: prepare_user_json(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.withColumn(\"prepare_user_json\",\n",
    "                             udf_prepare_user_json(dataset[\"user_json\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "что вообще есть? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  word|   count|\n",
      "+------+--------+\n",
      "|      |16233277|\n",
      "|  http| 5662188|\n",
      "|    ru| 4181093|\n",
      "|   www| 2252099|\n",
      "|   com| 1295527|\n",
      "|  html|  978352|\n",
      "| https|  688894|\n",
      "|   php|  511687|\n",
      "| avito|  473979|\n",
      "|     1|  430540|\n",
      "|     0|  393646|\n",
      "|  news|  273026|\n",
      "|     2|  255385|\n",
      "|   net|  228808|\n",
      "|smotri|  207966|\n",
      "| index|  205858|\n",
      "|  mail|  201938|\n",
      "|    d0|  194756|\n",
      "| forum|  193086|\n",
      "|  page|  175254|\n",
      "+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.withColumn('word', f.explode(f.split(f.col('prepare_user_json'), ' ')))\\\n",
    "       .groupBy('word')\\\n",
    "       .count()\\\n",
    "       .sort('count', ascending=False)\\\n",
    "       .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#добавляем стоп-слова\n",
    "def prepare_user_json_sw(x):\n",
    "    string = str(x)\n",
    "    try:\n",
    "        string = \" \".join([urls.get(\"url\") for urls in eval(string)['visits']])\n",
    "    except:\n",
    "        string = \" \".join([urls.get(\"url\") for urls in eval(string)])\n",
    "    string = re.split('\\W', string)\n",
    "    #stop_words\n",
    "    stop_words = [\"http\", \"https\", \"ru\", \"www\", \"com\", \"html\", \"php\"]\n",
    "    string = [x if x not in stop_words else \"\" for x in string]\n",
    "    string = \" \".join(string)\n",
    "    return re.sub(r\"\\s(\\s)?\", \"\\\\1\", string)\n",
    "\n",
    "udf_prepare_user_json_sw = f.udf(lambda x: prepare_user_json_sw(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.withColumn(\"prepare_user_json_sw\",\n",
    "                             udf_prepare_user_json_sw(dataset[\"user_json\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|         word|  count|\n",
      "+-------------+-------+\n",
      "|             |8181942|\n",
      "|        avito| 466710|\n",
      "|       smotri| 207802|\n",
      "|       24open|  97626|\n",
      "|   loveplanet|  91148|\n",
      "|        index|  86838|\n",
      "|  mailrambler|  84379|\n",
      "|      youtube|  80249|\n",
      "|       yandex|  79789|\n",
      "|           vk|  77332|\n",
      "|         ebay|  54484|\n",
      "|      flirchi|  51294|\n",
      "|      echomsk|  50616|\n",
      "|     yaplakal|  50343|\n",
      "|      topface|  48957|\n",
      "|         text|  48300|\n",
      "|       yabadu|  45694|\n",
      "|yandsearchweb|  44755|\n",
      "|     bkavanga|  38911|\n",
      "|           vz|  38086|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.withColumn('word', f.explode(f.split(f.col('prepare_user_json_sw'), ' ')))\\\n",
    "       .groupBy('word')\\\n",
    "       .count()\\\n",
    "       .sort('count', ascending=False)\\\n",
    "       .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|gender|  age|                 uid|           user_json|   prepare_user_json|prepare_user_json_sw|\n",
      "+------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "|     F|18-24|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|http   zebra zoya...| zebrazoya 200028...|\n",
      "|     M|25-34|d502331d-621e-472...|{\"visits\": [{\"url...|http   sweetradin...| sweetrading p900...|\n",
      "|     F|25-34|d50237ea-747e-48a...|{\"visits\": [{\"url...|http   ru oriflam...|  oriflame produc...|\n",
      "|     F|25-34|d502f29f-d57a-46b...|{\"visits\": [{\"url...|http   translate ...| translatetattoo ...|\n",
      "|     M| >=55|d503c3b2-a0c2-4f4...|{\"visits\": [{\"url...|https   mail ramb...| mailrambler  fol...|\n",
      "+------+-----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41138"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(f.col('uid'))\\\n",
    "       .distinct()\\\n",
    "       .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(gender='F'), Row(gender='M'), Row(gender='-')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(f.col('gender'))\\\n",
    "       .distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(age='>=55'),\n",
       " Row(age='45-54'),\n",
       " Row(age='-'),\n",
       " Row(age='35-44'),\n",
       " Row(age='25-34'),\n",
       " Row(age='18-24')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(f.col('age'))\\\n",
    "       .distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_gender(x):\n",
    "    mapping = {\n",
    "        '-': 0,\n",
    "        'F': 1,\n",
    "        'M': 2,\n",
    "    }\n",
    "    return mapping.get(x)\n",
    "\n",
    "def decode_gender(x):\n",
    "    mapping = {\n",
    "        0:'-',\n",
    "        1:'F',\n",
    "        2:'M',\n",
    "    }\n",
    "    return mapping.get(x)\n",
    "\n",
    "udf_encode_gender = f.udf(lambda x: encode_gender(x), IntegerType())\n",
    "udf_decode_gender = f.udf(lambda x: decode_gender(x), StringType())\n",
    "\n",
    "def encode_age(x):\n",
    "    mapping = {\n",
    "        '-': 0,\n",
    "        '45-54': 1,\n",
    "        '35-44': 2,\n",
    "        '25-34': 3,\n",
    "        '18-24': 4,\n",
    "        '>=55': 5,\n",
    "    }\n",
    "    return mapping.get(x)\n",
    "\n",
    "def decode_age(x):\n",
    "    mapping = {\n",
    "        0:'-',\n",
    "        1:'45-54',\n",
    "        2:'35-44',\n",
    "        3:'25-34',\n",
    "        4:'18-24',\n",
    "        5:'>=55',\n",
    "    }\n",
    "    return mapping.get(x)\n",
    "\n",
    "udf_encode_age = f.udf(lambda x: encode_age(x), IntegerType())\n",
    "udf_decode_age = f.udf(lambda x: decode_age(x), StringType())\n",
    "\n",
    "\n",
    "dataset = dataset.withColumn(\"gender\", udf_encode_gender(\"gender\"))\n",
    "dataset = dataset.withColumn(\"age\", udf_encode_age(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|gender|age|                 uid|           user_json|   prepare_user_json|prepare_user_json_sw|\n",
      "+------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|     1|  4|d50192e5-c44e-4ae...|{\"visits\": [{\"url...|http   zebra zoya...| zebrazoya 200028...|\n",
      "|     2|  3|d502331d-621e-472...|{\"visits\": [{\"url...|http   sweetradin...| sweetrading p900...|\n",
      "|     1|  3|d50237ea-747e-48a...|{\"visits\": [{\"url...|http   ru oriflam...|  oriflame produc...|\n",
      "+------+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_regexp_filter(string):\n",
    "    regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "    return \" \".join(regex.findall(string.lower()))\n",
    "udf_text_regexp_filter = f.udf(lambda x: text_regexp_filter(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.withColumn(\"prepare_user_json_sw_filter\", \n",
    "                             udf_text_regexp_filter(dataset[\"prepare_user_json_sw\"]))\n",
    "\n",
    "#tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"prepare_user_json_sw_filter\", outputCol=\"words\")\n",
    "dataset = tokenizer.transform(dataset)\n",
    "\n",
    "#считаем tf\n",
    "ht = HashingTF(inputCol=\"words\", outputCol=\"features_ht\", numFeatures=10000)\n",
    "dataset = ht.transform(dataset)\n",
    "\n",
    "#считаем tfidf\n",
    "tfidf = IDF(inputCol=\"features_ht\", outputCol=\"user_json_tfidf\").fit(dataset)\n",
    "dataset = tfidf.transform(dataset)\n",
    "\n",
    "tokenizer.write().overwrite().save(\"tokenizer_model\")\n",
    "ht.write().overwrite().save(\"ht_model\")\n",
    "tfidf.write().overwrite().save(\"tfidf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = dataset.limit(5) \n",
    "clf = RandomForestClassifier(labelCol=\"gender\", featuresCol=\"user_json_tfidf\") \n",
    "model = clf.fit(dataset.where('gender !=0'))\n",
    "model.write().overwrite().save(\"gender_model\")\n",
    "predictions = model.transform(pred_test)\n",
    "predictions = predictions.withColumn(\"pred_gender\", udf_decode_gender(\"prediction\"))\n",
    "columns_to_drop = ['rawPrediction', 'probability', 'prediction']\n",
    "predictions = predictions.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(labelCol=\"age\", featuresCol=\"user_json_tfidf\") \n",
    "model = clf.fit(dataset.where('age != 0'))\n",
    "model.write().overwrite().save(\"age_model\")\n",
    "predictions = model.transform(predictions)\n",
    "predictions = predictions.withColumn(\"pred_gender\", udf_decode_age(\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'age',\n",
       " 'uid',\n",
       " 'user_json',\n",
       " 'prepare_user_json',\n",
       " 'prepare_user_json_sw',\n",
       " 'prepare_user_json_sw_filter',\n",
       " 'words',\n",
       " 'features_ht',\n",
       " 'user_json_tfidf',\n",
       " 'pred_gender',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kafka\n",
    "# KAFKA_BOOTSTRAP_SERVER = 'spark-node-1.newprolab.com:6667'\n",
    "KAFKA_BOOTSTRAP_SERVER = 'spark-master-2.newprolab.com:6667'\n",
    "INPUT_KAFKA_TOPIC = 'input_andrey.korneev'\n",
    "OUTPUT_KAFKA_TOPIC = 'andrey.korneev'\n",
    "\n",
    "# read \n",
    "read_kafka_params = {\n",
    "    'kafka.bootstrap.servers': KAFKA_BOOTSTRAP_SERVER,\n",
    "    'subscribe': INPUT_KAFKA_TOPIC,\n",
    "    'startingOffsets': 'earliest',\n",
    "    'endingOffsets': 'latest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_sdf = (\n",
    "    spark\n",
    "    .read\n",
    "    .format('kafka')\n",
    "    .options(**read_kafka_params)\n",
    "    .option(\"failOnDataLoss\", 'False')\n",
    "    .load()\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 5000\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "| key|               value|               topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.korneev|        0|     0|2022-11-06 17:16:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.korneev|        0|     1|2022-11-06 17:16:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.korneev|        0|     2|2022-11-06 17:16:...|            0|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('count', kafka_sdf.count())\n",
    "kafka_sdf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url_visits_(x):\n",
    "    \n",
    "    x = json.loads(x)\n",
    "    x = json.loads(x['visits'])\n",
    "    return '{\"visits\":' + str(x) + '}'\n",
    "def parse_url_visits_series(x):\n",
    "    return x.apply(parse_url_visits_) \n",
    "parse_url_visits = f.pandas_udf(parse_url_visits_series,\"string\") \n",
    "\n",
    "kafka_sdf = kafka_sdf.withColumn(\"user_json\", parse_url_visits(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_uid_(x):\n",
    "    x = json.loads(x)\n",
    "    return x['uid']\n",
    "\n",
    "def parse_uid_series(x):\n",
    "    return x.apply(parse_uid_) \n",
    "parse_uid = f.pandas_udf(parse_uid_series,\"string\") \n",
    "\n",
    "kafka_sdf = kafka_sdf.withColumn(\"uid\", parse_uid(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+--------------------+--------------------+\n",
      "| key|               value|               topic|partition|offset|           timestamp|timestampType|           user_json|                 uid|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+--------------------+--------------------+\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.korneev|        0|     0|2022-11-06 17:16:...|            0|{\"visits\":[{'url'...|bd7a30e1-a25d-4cb...|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_sdf.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "deserialized = kafka_sdf.select(f.col(\"value\").cast(\"string\").alias(\"value\"))\n",
    "\n",
    "parsed_test = deserialized.select(f.get_json_object(f.col(\"value\"), \"$.uid\").alias(\"uid\"),\n",
    "                                  f.get_json_object(f.col(\"value\"), \"$.visits\").alias(\"visits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стрим\n",
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVER,\n",
    "    \"subscribe\": INPUT_KAFKA_TOPIC,\n",
    "    \"startingOffsets\": \"latest\",\n",
    "    \"failOnDataLoss\": \"False\"\n",
    "}\n",
    "write_kafka_params = {\n",
    "    'kafka.bootstrap.servers': KAFKA_BOOTSTRAP_SERVER,\n",
    "    'topic': OUTPUT_KAFKA_TOPIC\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.load(\"tokenizer_model\")\n",
    "hashingTF = HashingTF.load(\"ht_model\")\n",
    "idfModel = IDFModel.load(\"tfidf_model\")\n",
    "age_model = RandomForestClassificationModel.load(\"age_model\")\n",
    "gender_model = RandomForestClassificationModel.load(\"gender_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df, batch_id):  \n",
    "    deserialized = batch_df.select(f.col(\"value\").cast(\"string\").alias(\"value\"))\n",
    "    batch_df = deserialized.select(f.get_json_object(f.col(\"value\"), \"$.uid\").alias(\"uid\"),\n",
    "                                   f.get_json_object(f.col(\"value\"), \"$.visits\").alias(\"user_json\"))\n",
    "    #data prepare\n",
    "    batch_df = batch_df.withColumn(\"prepare_user_json_sw\",\n",
    "                                     udf_prepare_user_json_sw(batch_df[\"user_json\"]))\n",
    "    batch_df = batch_df.withColumn(\"prepare_user_json_sw_filter\", \n",
    "                                     udf_text_regexp_filter(batch_df[\"prepare_user_json_sw\"]))\n",
    "\n",
    "    tokens = tokenizer.transform(batch_df)\n",
    "    hashing = hashingTF.transform(tokens)\n",
    "    batch_df = idfModel.transform(hashing) \n",
    "    #gender predict\n",
    "    batch_df = gender_model.transform(batch_df)\n",
    "    batch_df = batch_df.withColumn(\"gender\", udf_decode_gender(\"prediction\"))\n",
    "    columns_to_drop = ['rawPrediction', 'probability', 'prediction']\n",
    "    batch_df = batch_df.drop(*columns_to_drop)\n",
    "\n",
    "    #age predict\n",
    "    batch_df = age_model.transform(batch_df)\n",
    "    batch_df = batch_df.withColumn(\"age\", udf_decode_age(\"prediction\"))\n",
    "\n",
    "    #submit\n",
    "    message = batch_df.select('uid', 'gender', 'age')       \n",
    "    message = message.select(to_json(struct(*message.columns)).alias(\"value\"))\n",
    "    message.write\\\n",
    "           .format('kafka')\\\n",
    "           .options(**write_kafka_params)\\\n",
    "           .mode('append')\\\n",
    "           .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_sdf = (spark\n",
    "    .readStream\n",
    "    .format('kafka')\n",
    "    .options(**read_kafka_params)\n",
    "    .option(\"failOnDataLoss\", 'False')\n",
    "    .load()\n",
    ")\n",
    "kafka_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_console_sink(df):\n",
    "    return df.writeStream\\\n",
    "            .foreachBatch(process_batch)\\\n",
    "            .option('checkpointLocation', 'streaming/chk/chk_kafka_nikita_gribov_lab04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink = create_console_sink(kafka_sdf)\n",
    "sq = sink.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Processing new data',\n",
       " 'isDataAvailable': True,\n",
       " 'isTriggerActive': True}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7f05257b-28dd-4309-94d2-ee9fa90a6bc3',\n",
       " 'runId': 'e8c94e08-9218-41a9-8df5-3d72b0c544ae',\n",
       " 'name': None,\n",
       " 'timestamp': '2022-11-06T14:20:22.655Z',\n",
       " 'batchId': 7,\n",
       " 'numInputRows': 0,\n",
       " 'inputRowsPerSecond': 0.0,\n",
       " 'processedRowsPerSecond': 0.0,\n",
       " 'durationMs': {'getEndOffset': 0, 'setOffsetRange': 2, 'triggerExecution': 2},\n",
       " 'stateOperators': [],\n",
       " 'sources': [{'description': 'KafkaV2[Subscribe[input_andrey.korneev]]',\n",
       "   'startOffset': {'input_andrey.korneev': {'0': 10000}},\n",
       "   'endOffset': {'input_andrey.korneev': {'0': 10000}},\n",
       "   'numInputRows': 0,\n",
       "   'inputRowsPerSecond': 0.0,\n",
       "   'processedRowsPerSecond': 0.0}],\n",
       " 'sink': {'description': 'ForeachBatchSink'}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq.lastProgress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
