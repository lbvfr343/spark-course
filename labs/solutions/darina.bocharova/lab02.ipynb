{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/darina.bocharova\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_info = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier'], [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'], [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'], [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'], [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'], [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23126, 'en', 'Compass - powerful SASS library that makes your life easier'],\n",
       " [21617, 'en', 'Preparing for the AP* Computer Science A Exam — Part 2'],\n",
       " [16627, 'es', 'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'],\n",
       " [11556,\n",
       "  'es',\n",
       "  'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'],\n",
       " [16704, 'ru', 'Программирование на Lazarus'],\n",
       " [13702, 'ru', 'Математическая экономика']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11556, 'es'],\n",
       " [13702, 'ru'],\n",
       " [16627, 'es'],\n",
       " [16704, 'ru'],\n",
       " [21617, 'en'],\n",
       " [23126, 'en']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_id_cours_list = sorted([personal_info[i][0:2] for i in range(len(personal_info))])\n",
    "my_id_cours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --driver-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Spark Dataframe app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Spark Dataframe app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark Dataframe app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f32510d6400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.read.json(\"/labs/slaba02/DO_record_per_line.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"/labs/slaba02/DO_record_per_line.json\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cat: string, desc: string, id: bigint, lang: string, name: string, provider: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "|                 cat|                desc|   id|lang|                name|provider|\n",
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "|3/business_manage...| Unique video ske...|10209|  en|Learn How To Writ...|   Udemy|\n",
      "|   1/arts_music_film|Explores such ind...|15686|  en|Photoshop CS5 One...|   Lynda|\n",
      "|  5/computer_science|Learn the basic c...|11858|  en|Human Anatomy and...|   ed2go|\n",
      "|   1/arts_music_film|How to streamline...|15821|  en|Premiere Pro CS4 ...|   Lynda|\n",
      "|                    |\n",
      "Hola a Todos!\n",
      "En...|10037|  es|Introduccion Visu...|   Udemy|\n",
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28153"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+\n",
      "|                desc|  id|lang|\n",
      "+--------------------+----+----+\n",
      "|In this class, co...|2930|  en|\n",
      "|This course will ...|2222|  en|\n",
      "| Learn Team effec...|9576|  en|\n",
      "|This course is de...|2530|  en|\n",
      "| Many commercial-...|5609|  en|\n",
      "+--------------------+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cut_df = df.select([\"desc\", \"id\", \"lang\"])\n",
    "cut_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|   id|                desc|\n",
      "+-----+--------------------+\n",
      "|10593| Learn Oracle SQL...|\n",
      "|14224|Find out about th...|\n",
      "|17423|Apple's new iAd f...|\n",
      "|17843| iOS App Developm...|\n",
      "|16174|Learn how to buil...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_en = cut_df.filter(cut_df.lang == \"en\").select([\"id\", \"desc\"])\n",
    "df_en.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24553"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   id|                desc|          words_list|\n",
      "+-----+--------------------+--------------------+\n",
      "|10593| Learn Oracle SQL...|[, learn, oracle,...|\n",
      "|14224|Find out about th...|[find, out, about...|\n",
      "|17423|Apple's new iAd f...|[apple's, new, ia...|\n",
      "|17843| iOS App Developm...|[, ios, app, deve...|\n",
      "|16174|Learn how to buil...|[learn, how, to, ...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_en = Tokenizer(inputCol=\"desc\", outputCol=\"words_list\")\n",
    "df_en = tokenizer_en.transform(df_en)\n",
    "df_en.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " id         | 8010                                                                                                                                                                                                                                                                                                                                                      \n",
      " desc       | NLP這套學問的假設，是我們以NLP視野體驗環境的前提。課程會將NLP的假設前提分為四方面：關於溝通策略的假設前提關於解讀行為的假設前提關於大腦認知的假設前提關於自我提昇的假設前提除此以外，課程亦會介紹「mind to muscle」技巧，學會將一些有啟發性的概念植根於神經系統。這是正式學習NLP的第一課，雖有很多新概念需時消化，但對認識、學習、溫習NLP都非常重要！     \n",
      " words_list | [nlp這套學問的假設，是我們以nlp視野體驗環境的前提。課程會將nlp的假設前提分為四方面：關於溝通策略的假設前提關於解讀行為的假設前提關於大腦認知的假設前提關於自我提昇的假設前提除此以外，課程亦會介紹「mind, to, muscle」技巧，學會將一些有啟發性的概念植根於神經系統。這是正式學習nlp的第一課，雖有很多新概念需時消化，但對認識、學習、溫習nlp都非常重要！] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 574, 583, 647, 8010\n",
    "df_en.filter(df_en.id == 8010).select([\"id\", \"desc\", \"words_list\"]).show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\", \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\", \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\", \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could', \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", 'would']\n"
     ]
    }
   ],
   "source": [
    "stop_words_en = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "print(stop_words_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|   id|                desc|          words_list|    filtr_words_list|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|10593| Learn Oracle SQL...|[, learn, oracle,...|[, learn, oracle,...|\n",
      "|14224|Find out about th...|[find, out, about...|[find, surprising...|\n",
      "|17423|Apple's new iAd f...|[apple's, new, ia...|[apple's, new, ia...|\n",
      "|17843| iOS App Developm...|[, ios, app, deve...|[, ios, app, deve...|\n",
      "|16174|Learn how to buil...|[learn, how, to, ...|[learn, build, we...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stw_en = StopWordsRemover(inputCol=\"words_list\", outputCol=\"filtr_words_list\", stopWords=stop_words_en)\n",
    "df_en = stw_en.transform(df_en)\n",
    "df_en.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  id|                desc|          words_list|    filtr_words_list|                  tf|            features|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|8133|The first MOOC to...|[the, first, mooc...|[first, mooc, tea...|(1000,[1,5,8,18,2...|(1000,[1,5,8,18,2...|\n",
      "|1629|11.941 and 11.942...|[11.941, and, 11....|[11.941, 11.942, ...|(1000,[19,25,26,3...|(1000,[19,25,26,3...|\n",
      "|8851| The Course This ...|[, the, course, t...|[, course, second...|(1000,[0,3,19,21,...|(1000,[0,3,19,21,...|\n",
      "|3937| Stuck in writing...|[, stuck, in, wri...|[, stuck, writing...|(1000,[3,4,6,16,2...|(1000,[3,4,6,16,2...|\n",
      "|6182| Why is it that s...|[, why, is, it, t...|[, servers, make,...|(1000,[1,6,7,10,1...|(1000,[1,6,7,10,1...|\n",
      "+----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF_en = HashingTF(inputCol=\"filtr_words_list\", outputCol=\"tf\", numFeatures=1000)\n",
    "tf_en = hashingTF_en.transform(df_en)\n",
    "df_en = IDF(inputCol=\"tf\", outputCol=\"features\").fit(tf_en).transform(tf_en)\n",
    "df_en.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_simailar_list_en(my_cours_id):\n",
    "  \n",
    "    target = df_en.filter(df_en.id == my_cours_id).select([\"features\"]).take(1)\n",
    "    target = target[0].__getitem__('features')\n",
    "  \n",
    "    cos_simailar_list = []\n",
    "    for id, features in df_en.select(\"id\", \"features\").take(df_en.count()):\n",
    "        cos_simailar = target.dot(features) / (target.norm(2) * features.norm(2))\n",
    "        # !\n",
    "        if str(cos_simailar) != 'nan':\n",
    "            cos_simailar_list.append([id, cos_simailar])\n",
    "        sorted_cos_simailar_list = sorted(cos_simailar_list, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_cos_simailar_list[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21617, 0.9999999999999998], [21609, 0.9879770695632255], [21608, 0.5121478668212629], [21616, 0.5099089184033334], [21492, 0.4150819256540292], [21624, 0.40131357525456773], [21630, 0.3958597768210409], [21628, 0.39558891364916526], [21623, 0.39467405336620726], [21474, 0.35134058978367644], [16162, 0.34287712829023914]]\n",
      "[21609, 21608, 21616, 21492, 21624, 21630, 21628, 21623, 21474, 16162]\n"
     ]
    }
   ],
   "source": [
    "total_list_en1 = cos_simailar_list_en(21617)\n",
    "print(total_list_en1)\n",
    "total_list_en1_id = []\n",
    "for i in range(10):\n",
    "    total_list_en1_id.append(total_list_en1[i+1][0])\n",
    "print(total_list_en1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/envs/bd9/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23126, 1.0], [10764, 0.5086536515468937], [13782, 0.4829889650994544], [13727, 0.4827985373316882], [5114, 0.4633097723776149], [24419, 0.45925418609589813], [9949, 0.44787706610113887], [13665, 0.42581447134167366], [20638, 0.4205004686919404], [2724, 0.4090014421469624], [23478, 0.39602540765777966]]\n",
      "[10764, 13782, 13727, 5114, 24419, 9949, 13665, 20638, 2724, 23478]\n"
     ]
    }
   ],
   "source": [
    "total_list_en2 = cos_simailar_list_en(23126)\n",
    "print(total_list_en2)\n",
    "total_list_en2_id = []\n",
    "for i in range(10):\n",
    "    total_list_en2_id.append(total_list_en2[i+1][0])\n",
    "print(total_list_en2_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+\n",
      "|                desc|   id|lang|\n",
      "+--------------------+-----+----+\n",
      "| Aprenderás nueva...|12801|  es|\n",
      "| En este curso va...|20070|  es|\n",
      "|\n",
      "Category:\n",
      "Business |10491|  es|\n",
      "| Aprende las técn...|10381|  es|\n",
      "|Este curso dotará...|18285|  es|\n",
      "+--------------------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_es = cut_df.filter(cut_df.lang == \"es\")\n",
    "df_es.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1374"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_es.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+--------------------+\n",
      "|                desc|  id|lang|          words_list|\n",
      "+--------------------+----+----+--------------------+\n",
      "| Aprende a realiz...|7121|  es|[, aprende, a, re...|\n",
      "| Curso de Técnica...|9421|  es|[, curso, de, téc...|\n",
      "| The Course Este ...|3660|  es|[, the, course, e...|\n",
      "| De la Identidad ...|5492|  es|[, de, la, identi...|\n",
      "| Aprende cómo ens...|9048|  es|[, aprende, cómo,...|\n",
      "+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_es = Tokenizer(inputCol=\"desc\", outputCol=\"words_list\")\n",
    "df_es = tokenizer_en.transform(df_es)\n",
    "df_es.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "|                desc|   id|lang|          words_list|                  tf|            features|\n",
      "+--------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "| Aprenderás nueva...|12801|  es|[, aprenderás, nu...|(1000,[3,14,21,34...|(1000,[3,14,21,34...|\n",
      "| En este curso va...|20070|  es|[, en, este, curs...|(1000,[3,7,17,18,...|(1000,[3,7,17,18,...|\n",
      "|\n",
      "Category:\n",
      "Business |10491|  es|[, category:, bus...|(1000,[372,374,52...|(1000,[372,374,52...|\n",
      "| Aprende las técn...|10381|  es|[, aprende, las, ...|(1000,[0,1,3,14,1...|(1000,[0,1,3,14,1...|\n",
      "|Este curso dotará...|18285|  es|[este, curso, dot...|(1000,[1,3,7,14,1...|(1000,[1,3,7,14,1...|\n",
      "+--------------------+-----+----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF_es = HashingTF(inputCol=\"words_list\", outputCol=\"tf\", numFeatures=1000)\n",
    "tf_es = hashingTF_es.transform(df_es)\n",
    "df_es = IDF(inputCol=\"tf\", outputCol=\"features\").fit(tf_es).transform(tf_es)\n",
    "df_es.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_simailar_list_es(my_cours_id):\n",
    "  \n",
    "  target = df_es.filter(df_es.id == my_cours_id).select([\"features\"]).take(1)\n",
    "  target = target[0].__getitem__('features')\n",
    "  \n",
    "  cos_simailar_list = []\n",
    "  for id, features in df_es.select(\"id\", \"features\").take(df_es.count()):\n",
    "    cos_simailar = target.dot(features) / (target.norm(2) * features.norm(2))\n",
    "    if str(cos_simailar) != 'nan':\n",
    "        cos_simailar_list.append([id, cos_simailar])\n",
    "    sorted_cos_simailar_list = sorted(cos_simailar_list, key=lambda x: x[1], reverse=True)\n",
    "  return sorted_cos_simailar_list[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11556, 1.0], [16488, 0.40925983599682725], [22710, 0.32061954484074584], [468, 0.3081773509475058], [10384, 0.30176738830370875], [19330, 0.2896889536301552], [11605, 0.2820844232758169], [13461, 0.2651682506782593], [10447, 0.2594332624681442], [11568, 0.24387608198892807], [11564, 0.21751557562489288]]\n",
      "[16488, 22710, 468, 10384, 19330, 11605, 13461, 10447, 11568, 11564]\n"
     ]
    }
   ],
   "source": [
    "total_list_es1 = cos_simailar_list_es(11556)\n",
    "print(total_list_es1)\n",
    "total_list_es1_id = []\n",
    "for i in range(10):\n",
    "  total_list_es1_id.append(total_list_es1[i+1][0])\n",
    "print(total_list_es1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16627, 1.0000000000000002], [11431, 0.4962725387738898], [12660, 0.3600395508529288], [12247, 0.35905200419482813], [17964, 0.33640299384420097], [5687, 0.3336725668346817], [9598, 0.3292829914868768], [25010, 0.32705885254453787], [16694, 0.31186150164549387], [17961, 0.3068127903204994], [11575, 0.29121485119152507]]\n",
      "[11431, 12660, 12247, 17964, 5687, 9598, 25010, 16694, 17961, 11575]\n"
     ]
    }
   ],
   "source": [
    "total_list_es2 = cos_simailar_list_es(16627)\n",
    "print(total_list_es2)\n",
    "total_list_es2_id = []\n",
    "for i in range(10):\n",
    "  total_list_es2_id.append(total_list_es2[i+1][0])\n",
    "print(total_list_es2_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+\n",
      "|                desc|   id|lang|\n",
      "+--------------------+-----+----+\n",
      "|Курс является вве...|13698|  ru|\n",
      "|Курс посвящен исп...|20357|  ru|\n",
      "|Онлайн-интенсив п...|17075|  ru|\n",
      "|Практический курс...|18279|  ru|\n",
      "|В курсе излагаютс...|13696|  ru|\n",
      "+--------------------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ru = cut_df.filter(cut_df.lang == \"ru\")\n",
    "df_ru.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1231"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ru.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+--------------------+\n",
      "|                desc|  id|lang|          words_list|\n",
      "+--------------------+----+----+--------------------+\n",
      "|Курс рассчитан на...|1063|  ru|[курс, рассчитан,...|\n",
      "|Курс посвящен изу...|1020|  ru|[курс, посвящен, ...|\n",
      "|В курсе изучаются...|1151|  ru|[в, курсе, изучаю...|\n",
      "|Технический трени...|1395|  ru|[технический, тре...|\n",
      "|В этом курсе пере...|1356|  ru|[в, этом, курсе, ...|\n",
      "+--------------------+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_ru = Tokenizer(inputCol=\"desc\", outputCol=\"words_list\")\n",
    "df_ru = tokenizer_ru.transform(df_ru)\n",
    "df_ru.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "stop_words_ru = StopWordsRemover.loadDefaultStopWords(\"russian\")\n",
    "print(stop_words_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+----+--------------------+--------------------+\n",
      "|                desc|  id|lang|          words_list|    filtr_words_list|\n",
      "+--------------------+----+----+--------------------+--------------------+\n",
      "|Курс рассчитан на...|1063|  ru|[курс, рассчитан,...|[курс, рассчитан,...|\n",
      "|Курс посвящен изу...|1020|  ru|[курс, посвящен, ...|[курс, посвящен, ...|\n",
      "|В курсе изучаются...|1151|  ru|[в, курсе, изучаю...|[курсе, изучаются...|\n",
      "|Технический трени...|1395|  ru|[технический, тре...|[технический, тре...|\n",
      "|В этом курсе пере...|1356|  ru|[в, этом, курсе, ...|[курсе, перемести...|\n",
      "+--------------------+----+----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stw_ru = StopWordsRemover(inputCol=\"words_list\", outputCol=\"filtr_words_list\", stopWords=stop_words_ru)\n",
    "df_ru = stw_ru.transform(df_ru)\n",
    "df_ru.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|                desc|   id|lang|          words_list|    filtr_words_list|                  tf|            features|\n",
      "+--------------------+-----+----+--------------------+--------------------+--------------------+--------------------+\n",
      "|Курс является вве...|13698|  ru|[курс, является, ...|[курс, является, ...|(1000,[0,34,181,2...|(1000,[0,34,181,2...|\n",
      "|Курс посвящен исп...|20357|  ru|[курс, посвящен, ...|[курс, посвящен, ...|(1000,[3,175,214,...|(1000,[3,175,214,...|\n",
      "|Онлайн-интенсив п...|17075|  ru|[онлайн-интенсив,...|[онлайн-интенсив,...|(1000,[18,27,34,5...|(1000,[18,27,34,5...|\n",
      "|Практический курс...|18279|  ru|[практический, ку...|[практический, ку...|(1000,[13,29,34,4...|(1000,[13,29,34,4...|\n",
      "|В курсе излагаютс...|13696|  ru|[в, курсе, излага...|[курсе, излагаютс...|(1000,[17,32,44,9...|(1000,[17,32,44,9...|\n",
      "+--------------------+-----+----+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF_ru = HashingTF(inputCol=\"filtr_words_list\", outputCol=\"tf\", numFeatures=1000)\n",
    "tf_ru = hashingTF_ru.transform(df_ru)\n",
    "df_ru = IDF(inputCol=\"tf\", outputCol=\"features\").fit(tf_ru).transform(tf_ru)\n",
    "df_ru.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_simailar_list_ru(my_cours_id):\n",
    "  \n",
    "  target = df_ru.filter(df_ru.id == my_cours_id).select([\"features\"]).take(1)\n",
    "  target = target[0].__getitem__('features')\n",
    "  \n",
    "  cos_simailar_list = []\n",
    "  for id, features in df_ru.select(\"id\", \"features\").take(df_ru.count()):\n",
    "    cos_simailar = target.dot(features) / (target.norm(2) * features.norm(2))\n",
    "    if str(cos_simailar) != 'nan':\n",
    "        cos_simailar_list.append([id, cos_simailar])\n",
    "    sorted_cos_simailar_list = sorted(cos_simailar_list, key=lambda x: x[1], reverse=True)\n",
    "  return sorted_cos_simailar_list[0:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13702, 1.0000000000000002], [864, 1.0000000000000002], [17075, 0.2734349522351883], [919, 0.1912376381558141], [28074, 0.1809981148998331], [13057, 0.17405058778615892], [895, 0.15587750767847933], [1383, 0.1557139972947489], [1052, 0.14260108365282806], [1125, 0.14242270380898678], [8300, 0.13982046314295313]]\n",
      "[864, 17075, 919, 28074, 13057, 895, 1383, 1052, 1125, 8300]\n"
     ]
    }
   ],
   "source": [
    "total_list_ru1 = cos_simailar_list_ru(13702)\n",
    "print(total_list_ru1)\n",
    "total_list_ru1_id = []\n",
    "for i in range(10):\n",
    "  total_list_ru1_id.append(total_list_ru1[i+1][0])\n",
    "print(total_list_ru1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16704, 1.0], [1250, 0.2613547630305457], [1131, 0.24244690401997568], [1164, 0.2392302084437246], [1228, 0.21866946329918455], [1011, 0.19977351331683688], [25916, 0.19138615349740062], [1257, 0.18929692993551903], [6928, 0.1875958859087456], [1151, 0.17534061921744115], [1361, 0.17336934061580564]]\n",
      "[1250, 1131, 1164, 1228, 1011, 25916, 1257, 6928, 1151, 1361]\n"
     ]
    }
   ],
   "source": [
    "total_list_ru2 = cos_simailar_list_ru(16704)\n",
    "print(total_list_ru2)\n",
    "total_list_ru2_id = []\n",
    "for i in range(10):\n",
    "  total_list_ru2_id.append(total_list_ru2[i+1][0])\n",
    "print(total_list_ru2_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = {}\n",
    "# es1\n",
    "data['11556'] = total_list_es1_id\n",
    "# ru1\n",
    "data['13702'] = total_list_ru1_id\n",
    "# es2\n",
    "data['16627'] = total_list_es2_id\n",
    "# ru2\n",
    "data['16704'] = total_list_ru2_id\n",
    "# en1\n",
    "data['21617'] = total_list_en1_id\n",
    "# en2\n",
    "data['23126'] = total_list_en2_id\n",
    "with open('lab02.json', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'sc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda/envs/bd9/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \"\"\".format(\n\u001b[1;32m    242\u001b[0m             \u001b[0mcatalogImplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.sql.catalogImplementation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0msc_HTML\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         )\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/context.py\u001b[0m in \u001b[0;36m_repr_html_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \"\"\".format(\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0msc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         )\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark2-client/python/pyspark/context.py\u001b[0m in \u001b[0;36muiWebUrl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0muiWebUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;34m\"\"\"Return the URL of the SparkUI instance started by this SparkContext\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muiWebUrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'sc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f32510d6400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
