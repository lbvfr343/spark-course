{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для получения спарк сессии достаточно исполнить\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_cources = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier'], \n",
    "[21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'], \n",
    "[16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'], \n",
    "[11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'], \n",
    "[16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'], \n",
    "[13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"lang\", StringType()),\n",
    "    StructField(\"desc\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data=given_cources, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+\n",
      "|   id|lang|                desc|\n",
      "+-----+----+--------------------+\n",
      "|23126|  en|Compass - powerfu...|\n",
      "|21617|  en|Preparing for the...|\n",
      "|16627|  es|Aprende Excel: Ni...|\n",
      "|11556|  es|Aprendizaje Colab...|\n",
      "|16704|  ru|Программирование ...|\n",
      "|13702|  ru|Математическая эк...|\n",
      "+-----+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show() #посмотрю примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import pandas_udf, udf, col, isnan, isnull, broadcast, desc, lower\n",
    "from pyspark.sql.types import FloatType, ArrayType, StringType, IntegerType\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(ArrayType(StringType()))\n",
    "# препроцессинг + токенизация \n",
    "def clear_string(series):\n",
    "    regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "    res = series.str.findall(regex)\n",
    "    res_low = res.apply(lambda x: [v.lower() for v in x], ArrayType(StringType()))\n",
    "    return res_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('tokens', clear_string('desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = spark.read.json(\"/labs/slaba02/DO_record_per_line.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.withColumn('tokens', clear_string('desc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"tokens\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(all_data)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    return float(a.dot(b) / (a.norm(2) * b.norm(2)))\n",
    "\n",
    "cos_sim_udf = udf(cos_sim, FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитываю косинусную близость и сохраняю в json по шагам: \n",
    "1. вывожу sparse-vector для каждого примера,\n",
    "2. добавляю столбцом в датафрейм,\n",
    "3. добавляю столбцом cos_sim для каждого примера,\n",
    "4. вывожу столбец с топ-10 рекомендаций,\n",
    "5. сохраняю json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывожу sparse-vector для каждого примера,\n",
    "c21617 = rescaledData.select(col(\"features\").alias(\"c21617\")).where(\"id = 21617\").limit(1)\n",
    "c23126 = rescaledData.select(col(\"features\").alias(\"c23126\")).where(\"id = 23126\").limit(1)\n",
    "c16627 = rescaledData.select(col(\"features\").alias(\"c16627\")).where(\"id = 16627\").limit(1)\n",
    "c11556 = rescaledData.select(col(\"features\").alias(\"c11556\")).where(\"id = 11556\").limit(1)\n",
    "c16704 = rescaledData.select(col(\"features\").alias(\"c16704\")).where(\"id = 16704\").limit(1)\n",
    "c13702 = rescaledData.select(col(\"features\").alias(\"c13702\")).where(\"id = 13702\").limit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляю столбцом в датафрейм,\n",
    "rescaledData = rescaledData.crossJoin(c21617)\n",
    "rescaledData = rescaledData.crossJoin(c23126)\n",
    "rescaledData = rescaledData.crossJoin(c16627)\n",
    "rescaledData = rescaledData.crossJoin(c11556)\n",
    "rescaledData = rescaledData.crossJoin(c16704)\n",
    "rescaledData = rescaledData.crossJoin(c13702)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляю столбцом cos_sim для каждого примера,\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c21617\", cos_sim_udf(col(\"features\"), col(\"c21617\")))\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c23126\", cos_sim_udf(col(\"features\"), col(\"c23126\")))\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c16627\", cos_sim_udf(col(\"features\"), col(\"c16627\")))\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c11556\", cos_sim_udf(col(\"features\"), col(\"c11556\")))\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c16704\", cos_sim_udf(col(\"features\"), col(\"c16704\")))\n",
    "rescaledData = rescaledData.withColumn(\"cos_sim_c13702\", cos_sim_udf(col(\"features\"), col(\"c13702\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21609, 21616, 21608, 22298, 21628, 21630, 21623, 21508, 21081, 19417]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вывожу столбец с топ-10 рекомендаций\n",
    "\n",
    "ans_21617 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'en'\")\n",
    "    .where(\"id != 21617\")\n",
    "    .where(\"cos_sim_c21617 is not null\")\n",
    "    .where(\"cos_sim_c21617 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c21617\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_21617 = [x for x in ans_21617.id]\n",
    "lst_21617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14760, 13665, 13782, 20638, 24419, 15909, 2724, 25782, 17499, 13348]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_23126 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'en'\")\n",
    "    .where(\"id != 23126\")\n",
    "    .where(\"cos_sim_c23126 is not null\")\n",
    "    .where(\"cos_sim_c23126 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c23126\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_23126 = [x for x in ans_23126.id]\n",
    "lst_23126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11431, 11575, 12247, 17964, 5687, 17961, 16694, 12660, 25010, 5558]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_16627 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'es'\")\n",
    "    .where(\"id != 16627\")\n",
    "    .where(\"cos_sim_c16627 is not null\")\n",
    "    .where(\"cos_sim_c16627 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c16627\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_16627 = [x for x in ans_16627.id]\n",
    "lst_16627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16488, 468, 13461, 23357, 19330, 7833, 9289, 10447, 22710, 11340]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_11556 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'es'\")\n",
    "    .where(\"id != 11556\")\n",
    "    .where(\"cos_sim_c11556 is not null\")\n",
    "    .where(\"cos_sim_c11556 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c11556\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_11556 = [x for x in ans_11556.id]\n",
    "lst_11556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1236, 1247, 1365, 20288, 1273, 1164, 8186, 1233, 8203, 875]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_16704 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'ru'\")\n",
    "    .where(\"id != 16704\")\n",
    "    .where(\"cos_sim_c16704 is not null\")\n",
    "    .where(\"cos_sim_c16704 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c16704\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_16704 = [x for x in ans_16704.id]\n",
    "lst_16704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_13702 = (\n",
    "rescaledData.select(col(\"id\"))\n",
    "    .where(\"lang = 'ru'\")\n",
    "    .where(\"id != 13702\")\n",
    "    .where(\"cos_sim_c13702 is not null\")\n",
    "    .where(\"cos_sim_c13702 != 'NaN'\")\n",
    "    .orderBy(\"cos_sim_c13702\", ascending=False)\n",
    "    .limit(10).toPandas()\n",
    ")\n",
    "lst_13702 = [x for x in ans_13702.id]\n",
    "lst_13702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняю json\n",
    "data = {\"21617\": lst_21617, \"23126\": lst_23126, \"11556\": lst_11556, \"16627\": lst_16627, \"13702\": lst_13702, \"16704\": lst_16704} #собираю словарь для оформления ответа\n",
    "\n",
    "import json\n",
    "with open('lab02.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
