{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n",
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  74107|       0|\n",
      "|   1654|  89249|       0|\n",
      "|   1654|  99982|       0|\n",
      "|   1654|  89901|       0|\n",
      "|   1654| 100504|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-------+\n",
      "|purchase|  count|\n",
      "+--------+-------+\n",
      "|       1|  10904|\n",
      "|       0|5021720|\n",
      "+--------+-------+\n",
      "\n",
      "+---------+--------+\n",
      "|item_type|   count|\n",
      "+---------+--------+\n",
      "|     live|17704201|\n",
      "|      pvr| 3141406|\n",
      "+---------+--------+\n",
      "\n",
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                   1941|\n",
      "+-----------------------+\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = true)\n",
      " |-- avail_stop_dt: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = false)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = false)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- ts_start: string (nullable = true)\n",
      " |-- ts_end: string (nullable = true)\n",
      " |-- item_type: string (nullable = true)\n",
      " |-- time: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_num_views: long (nullable = false)\n",
      " |-- user_total_view_time: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_type: string (nullable = true)\n",
      " |-- user_type_view_cnt: long (nullable = false)\n",
      " |-- user_type_view_time: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      " |-- user_num_views: long (nullable = true)\n",
      " |-- user_total_view_time: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      " |-- user_num_views: long (nullable = true)\n",
      " |-- user_total_view_time: double (nullable = true)\n",
      " |-- user_num_live_views: long (nullable = true)\n",
      " |-- user_time_live_views: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      " |-- user_num_views: long (nullable = true)\n",
      " |-- user_total_view_time: double (nullable = true)\n",
      " |-- user_num_live_views: long (nullable = true)\n",
      " |-- user_time_live_views: double (nullable = true)\n",
      " |-- user_num_pvr_views: long (nullable = true)\n",
      " |-- user_time_pvr_views: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      " |-- user_num_views: long (nullable = false)\n",
      " |-- user_total_view_time: double (nullable = false)\n",
      " |-- user_num_live_views: long (nullable = false)\n",
      " |-- user_time_live_views: double (nullable = false)\n",
      " |-- user_num_pvr_views: long (nullable = false)\n",
      " |-- user_time_pvr_views: double (nullable = false)\n",
      "\n",
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- item_id: long (nullable = true)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- year: string (nullable = false)\n",
      " |-- target: integer (nullable = true)\n",
      " |-- avail_start_dt: string (nullable = false)\n",
      " |-- avail_stop_dt: string (nullable = false)\n",
      " |-- user_pays: long (nullable = true)\n",
      " |-- user_cnt: long (nullable = true)\n",
      " |-- user_pay_to_all: double (nullable = true)\n",
      " |-- item_pays: long (nullable = true)\n",
      " |-- item_cnt: long (nullable = true)\n",
      " |-- item_pay_to_all: double (nullable = true)\n",
      " |-- user_num_views: long (nullable = false)\n",
      " |-- user_total_view_time: double (nullable = false)\n",
      " |-- user_num_live_views: long (nullable = false)\n",
      " |-- user_time_live_views: double (nullable = false)\n",
      " |-- user_num_pvr_views: long (nullable = false)\n",
      " |-- user_time_pvr_views: double (nullable = false)\n",
      "\n",
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            purchase|\n",
      "+-------+-------+--------------------+\n",
      "|   1654|    336|0.032905070014759286|\n",
      "|   1654|    678|0.032905070014759286|\n",
      "|   1654|    691|0.032905070014759286|\n",
      "|   1654|    696|  0.0329250952293082|\n",
      "|   1654|    763|0.032905070014759286|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 6 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())\n",
    "\n",
    "\n",
    "schema_t = StructType([StructField('user_id',LongType(),True)\n",
    "                       ,StructField('item_id',LongType(),True)\n",
    "                       ,StructField('purchase',IntegerType(),True)               \n",
    "                      ]) \n",
    "\n",
    "schema_i = StructType([StructField('item_id',LongType(),True)\n",
    "                       ,StructField('channel_id',StringType(),True)\n",
    "                       ,StructField('datetime_availability_start',StringType(),True)\n",
    "                       ,StructField('datetime_availability_stop',StringType(),True)\n",
    "                       ,StructField('datetime_show_start',StringType(),True) \n",
    "                       ,StructField('datetime_show_stop',StringType(),True) \n",
    "                       ,StructField('content_type',IntegerType(),True)\n",
    "                       ,StructField('title',StringType(),True) \n",
    "                       ,StructField('year',StringType(),True)\n",
    "                       ,StructField('genres',StringType(),True)\n",
    "                       ,StructField('region_id',StringType(),True)\n",
    "                      ]) \n",
    "\n",
    "schema_v = StructType([StructField('user_id',LongType(),True)\n",
    "                       ,StructField('item_id',LongType(),True)\n",
    "                       ,StructField('ts_start',StringType(),True)\n",
    "                       ,StructField('ts_end',StringType(),True) \n",
    "                       ,StructField('item_type',StringType(),True) \n",
    "                      ]) \n",
    "\n",
    "\n",
    "train_df = spark.read.csv(\"/labs/slaba03/laba03_train.csv\", header=True, schema=schema_t)#, sep = '\\t'\n",
    "test_df = spark.read.csv(\"/labs/slaba03/laba03_test.csv\", header=True, schema=schema_t)#, sep = '\\t'\n",
    "items_df = spark.read.csv(\"/labs/slaba03/laba03_items.csv\", header=True, sep = '\\t', schema=schema_i)\n",
    "views_df = spark.read.csv(\"/labs/slaba03/laba03_views_programmes.csv\", header=True, schema=schema_v)#, sep = '\\t')\n",
    "\n",
    "\n",
    "train_df.show(5)\n",
    "\n",
    "train_df.groupBy('purchase').count().show()\n",
    "views_df.groupby('item_type').count().show()\n",
    "test_df.select(F.countDistinct('user_id')).show()\n",
    "features_df = train_df.union(test_df)\n",
    "features_df.printSchema()\n",
    "features_df = (\n",
    "    features_df\n",
    "    .join(items_df,on='item_id',how='left')\n",
    "    .select(features_df['user_id']\n",
    "            ,features_df['item_id']\n",
    "            ,'genres'\n",
    "            ,'year'\n",
    "            ,F.col('purchase').alias('target')\n",
    "            ,F.col('datetime_availability_start').alias('avail_start_dt')\n",
    "            ,F.col('datetime_availability_stop').alias('avail_stop_dt'))\n",
    ")\n",
    "features_df.printSchema()\n",
    "features_df = features_df.fillna( { 'genres':'no_genre'} )\n",
    "features_df = features_df.fillna( { 'year':'no_year'} )\n",
    "features_df = features_df.fillna( { 'avail_start_dt':'no_avail_start_dt'} )\n",
    "features_df = features_df.fillna( { 'avail_stop_dt':'no_avail_stop_dt'} )\n",
    "\n",
    "\n",
    "features_df = features_df.withColumn('genres',F.lower(F.col('genres')))\n",
    "features_df.printSchema()\n",
    "\n",
    "user_purchases = (\n",
    "    features_df \n",
    "    .groupBy('user_id')\n",
    "    .agg(F.sum('target').alias('user_pays'),\n",
    "         F.count('*').alias('user_cnt')\n",
    "        )\n",
    "    .select('user_id','user_pays','user_cnt',(F.col('user_pays') / F.col('user_cnt')).alias('user_pay_to_all'))\n",
    ")\n",
    "user_purchases.printSchema()\n",
    "item_purchases = (\n",
    "    features_df \n",
    "    .groupBy('item_id')\n",
    "    .agg(F.sum('target').alias('item_pays'),\n",
    "         F.count('*').alias('item_cnt')\n",
    "        )\n",
    "    .select('item_id','item_pays','item_cnt',(F.col('item_pays') / F.col('item_cnt')).alias('item_pay_to_all'))\n",
    ")  \n",
    "item_purchases.printSchema()\n",
    "features_df = features_df.join(user_purchases,on='user_id',how='left')\n",
    "features_df = features_df.join(item_purchases,on='item_id',how='left')\n",
    "features_df.printSchema()\n",
    "views_df = views_df.withColumn('time',views_df.ts_end-views_df.ts_start)\n",
    "views_df.printSchema()\n",
    "user_views = (\n",
    "    views_df\n",
    "    .groupBy('user_id')\n",
    "    .agg(F.count('*').alias('user_num_views'),\n",
    "         F.sum('time').alias('user_total_view_time')\n",
    "        )\n",
    ")\n",
    "user_views.printSchema()\n",
    "\n",
    "user_type_views = (\n",
    "    views_df.groupBy('user_id','item_type')\n",
    "    .agg(F.count('*').alias('user_type_view_cnt'),\n",
    "         F.sum('time').alias('user_type_view_time')\n",
    "    )\n",
    ")\n",
    "user_type_views.printSchema()\n",
    "features_df = (\n",
    "    features_df\n",
    "    .join(user_views,on='user_id',how='left')\n",
    ")\n",
    "features_df.printSchema()\n",
    "features_df = (\n",
    "    features_df\n",
    "    .join(user_type_views.where(\"item_type=='live'\")\n",
    "          .select('user_id'\n",
    "                  ,col('user_type_view_cnt').alias('user_num_live_views')\n",
    "                  ,col('user_type_view_time').alias('user_time_live_views')),on='user_id',how='left')\n",
    ")\n",
    "features_df.printSchema()\n",
    "features_df = (\n",
    "    features_df\n",
    "    .join(user_type_views.where(\"item_type=='pvr'\")\n",
    "          .select('user_id'\n",
    "                  ,col('user_type_view_cnt').alias('user_num_pvr_views')\n",
    "                  ,col('user_type_view_time').alias('user_time_pvr_views')),on='user_id',how='left')\n",
    ")\n",
    "features_df.printSchema()\n",
    "features_df2 = features_df.fillna( { 'user_num_views':0,\n",
    "                                   'user_total_view_time':0,\n",
    "                                   'user_num_live_views':0,\n",
    "                                   'user_time_live_views':0,\n",
    "                                   'user_num_pvr_views':0,\n",
    "                                   'user_time_pvr_views':0} )\n",
    "features_df2.printSchema()\n",
    "features_df = features_df2.select('user_id', 'item_id', 'year', 'target', 'avail_start_dt', 'avail_stop_dt', 'user_pays', 'user_cnt', 'user_pay_to_all', 'item_pays', 'item_cnt', 'item_pay_to_all', 'user_num_views', 'user_total_view_time', 'user_num_live_views', 'user_time_live_views', 'user_num_pvr_views', 'user_time_pvr_views')\n",
    "features_df2.printSchema()\n",
    "year_indexer = StringIndexer(inputCol=\"year\", outputCol=\"yearIndex\")\n",
    "avail_start_indexer = StringIndexer(inputCol=\"avail_start_dt\", outputCol=\"avail_start_dtIndex\")\n",
    "avail_stop_indexer = StringIndexer(inputCol=\"avail_stop_dt\", outputCol=\"avail_stop_dtIndex\")\n",
    "\n",
    "\n",
    "OHE_year_vector = OneHotEncoder(inputCol=\"yearIndex\", outputCol=\"year_vec\")\n",
    "OHE_avail_start_dt_vector = OneHotEncoder(inputCol=\"avail_start_dtIndex\", outputCol=\"avail_start_dt_vec\")\n",
    "OHE_avail_stop_dt_vector = OneHotEncoder(inputCol=\"avail_stop_dtIndex\", outputCol=\"avail_stop_dt_vec\")\n",
    "\n",
    "\n",
    "features = [a for a in features_df.columns if a not in ['item_id', 'user_id', 'target','year','avail_start_dt','avail_stop_dt']]\n",
    "features = features + ['year_vec','avail_start_dt_vec','avail_stop_dt_vec']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "pipeline = Pipeline(stages=[year_indexer,\n",
    "                            avail_start_indexer,\n",
    "                            avail_stop_indexer,\n",
    "                            OHE_year_vector,\n",
    "                            OHE_avail_start_dt_vector,\n",
    "                            OHE_avail_stop_dt_vector,\n",
    "                            assembler\n",
    "                    ])\n",
    "transf_feats = pipeline.fit(features_df).transform(features_df)\n",
    "transf_feats.rdd.getNumPartitions()\n",
    "transf_feats = transf_feats.coalesce(50)\n",
    "transf_feats = transf_feats.select('user_id','item_id','features','target')\n",
    "train = transf_feats.where('target is not null')\n",
    "test = transf_feats.where('target is null')\n",
    "lr = GBTClassifier(featuresCol='features'\n",
    "                        , labelCol=\"target\"\n",
    "                        , maxIter=30)\n",
    "lr_model = lr.fit(train)\n",
    "sparse_values = udf(lambda v: v.values.tolist(), ArrayType(DoubleType()))\n",
    "\n",
    "predictions_prom_lr = lr_model.transform(test)\n",
    "predictions_fin_lr = predictions_prom_lr.select('user_id','item_id','probability').withColumn(\"proba\", sparse_values(\"probability\"))\n",
    "predictions_fin_lr.rdd.getNumPartitions()\n",
    "res = predictions_fin_lr.select('user_id','item_id',F.col('proba').getItem(1).alias('purchase')).orderBy(F.col('user_id').asc(),F.col('item_id').asc())\n",
    "res.count()\n",
    "res.show(5)\n",
    "res.toPandas().to_csv('lab03_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            purchase|\n",
      "+-------+-------+--------------------+\n",
      "|   1654|    336|0.032905070014759286|\n",
      "|   1654|    678|0.032905070014759286|\n",
      "|   1654|    691|0.032905070014759286|\n",
      "|   1654|    696|  0.0329250952293082|\n",
      "|   1654|    763|0.032905070014759286|\n",
      "|   1654|    795| 0.03489766832813934|\n",
      "|   1654|    861|0.032905070014759286|\n",
      "|   1654|   1137|0.033118672439478525|\n",
      "|   1654|   1159|  0.0329250952293082|\n",
      "|   1654|   1428|0.032905070014759286|\n",
      "|   1654|   1685|  0.0329250952293082|\n",
      "|   1654|   1686|0.032905070014759286|\n",
      "|   1654|   1704| 0.03299673230867528|\n",
      "|   1654|   2093|0.032905070014759286|\n",
      "|   1654|   2343|0.032905070014759286|\n",
      "|   1654|   2451|0.032905070014759286|\n",
      "|   1654|   2469| 0.03669501095494343|\n",
      "|   1654|   2603|0.032905070014759286|\n",
      "|   1654|   2609|0.032905070014759286|\n",
      "|   1654|   2621|  0.0329250952293082|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(col(\"purchase\") > 0.5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156813"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.filter(col(\"purchase\") <= 0.5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+------+--------------------+--------------------+----------+\n",
      "|user_id|item_id|            features|target|       rawPrediction|         probability|prediction|\n",
      "+-------+-------+--------------------+------+--------------------+--------------------+----------+\n",
      "| 728960|  79884|(96,[0,1,2,3,4,5,...|  null|[1.69485989093793...|[0.96738170375237...|       0.0|\n",
      "| 728960|  88979|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  98225|(96,[0,1,2,4,6,7,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|   6162|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  10176|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  66180|(96,[0,1,2,4,6,7,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  68160|(96,[0,1,2,4,6,7,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  74401|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  74827|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  11101|(96,[0,1,2,3,4,5,...|  null|[1.69341870183137...|[0.96729062957216...|       0.0|\n",
      "| 728960|  74526|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  77438|(96,[0,1,2,3,4,5,...|  null|[1.69458118785416...|[0.96736411058403...|       0.0|\n",
      "| 728960|  80901|(96,[0,1,2,3,4,5,...|  null|[1.69485989093793...|[0.96738170375237...|       0.0|\n",
      "| 728960|  93626|(96,[0,1,2,3,4,5,...|  null|[1.69157241966424...|[0.96717359699605...|       0.0|\n",
      "| 728960|  95007|(96,[0,1,2,3,4,5,...|  null|[1.69458118785416...|[0.96736411058403...|       0.0|\n",
      "| 728960|  11257|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  94712|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960| 100448|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  10290|(96,[0,1,2,3,4,5,...|  null|[1.69517443945017...|[0.96740154866004...|       0.0|\n",
      "| 728960|  88933|(96,[0,1,2,3,4,5,...|  null|[1.69306993944404...|[0.96726855306484...|       0.0|\n",
      "+-------+-------+--------------------+------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_prom_lr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_prom_lr_train = lr_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.936081370651349"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "tp_double = predictions_prom_lr_train.withColumn(\n",
    "    \"target\", col(\"target\").cast(\"double\"\n",
    ")).withColumn(\n",
    "    \"prediction\", col(\"prediction\").cast(\"double\"\n",
    "))\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "                                         labelCol=\"target\",\n",
    "                                         rawPredictionCol=\"rawPrediction\", \n",
    "                                         metricName=\"areaUnderROC\")\n",
    "evaluator.evaluate(tp_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
