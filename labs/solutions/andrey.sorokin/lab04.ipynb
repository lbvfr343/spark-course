{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 --executor-memory 1g --executor-cores 1 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Lab04_by_sand</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f70ec07bbe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[2]\") \\\n",
    "                    .appName(\"Lab04_by_sand\") \\\n",
    "                    .config(\"spark.driver.memory\", \"512m\") \\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, IDF, CountVectorizer\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import struct\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, RegexTokenizer, MinMaxScaler, Normalizer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rw-r--r--   3 hdfs hdfs  655090069 2022-01-06 18:46 /labs/slaba04/gender_age_dataset.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba04/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender\tage\tuid\tuser_json\r\n",
      "F\t18-24\td50192e5-c44e-4ae8-ae7a-7cfe67c8b777\t{\"visits\": [{\"url\": \"http://zebra-zoya.ru/200028-chehol-organayzer-dlja-macbook-11-grid-it.html?utm_campaign=397720794&utm_content=397729344&utm_medium=cpc&utm_source=begun\", \"timestamp\": 1419688144068}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426666298001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426666298000}, {\"url\": \"http://news.yandex.ru/yandsearch?cl4url=chezasite.com/htc/htc-one-m9-delay-86327.html&lr=213&rpt=story\", \"timestamp\": 1426661722001}, {\"url\": \"http://www.sotovik.ru/news/240283-htc-one-m9-zaderzhivaetsja.html\", \"timestamp\": 1426661722000}]}\r\n",
      "M\t25-34\td502331d-621e-4721-ada2-5d30b2c3801f\t{\"visits\": [{\"url\": \"http://sweetrading.ru/?p=900\", \"timestamp\": 1419717886224}, {\"url\": \"http://sweetrading.ru/?p=884\", \"timestamp\": 1419717884437}, {\"url\": \"http://sweetrading.ru/?p=1002\", \"timestamp\": 14"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -head /labs/slaba04/gender_age_dataset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERS_FILE = \"/labs/slaba04/gender_age_dataset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " gender    | F                    \n",
      " age       | 18-24                \n",
      " uid       | d50192e5-c44e-4ae... \n",
      " user_json | {\"visits\": [{\"url... \n",
      "-RECORD 1-------------------------\n",
      " gender    | M                    \n",
      " age       | 25-34                \n",
      " uid       | d502331d-621e-472... \n",
      " user_json | {\"visits\": [{\"url... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users = spark.read.csv(USERS_FILE, sep='\\t', header=True)\n",
    "users.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- uid: string (nullable = true)\n",
      " |-- user_json: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------------------------------------------------\n",
      " gender | F                                                                               \n",
      " age    | 18-24                                                                           \n",
      " uid    | d50192e5-c44e-4ae8-ae7a-7cfe67c8b777                                            \n",
      " hosts  | [zebra-zoya.ru, news.yandex.ru, www.sotovik.ru, news.yandex.ru, www.sotovik.ru] \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@f.pandas_udf(ArrayType(StringType()))\n",
    "def extract_hosts(pdf):\n",
    "    def __parse_url(url):\n",
    "        regexp = '(\\w+)://([\\w\\d\\-\\.]*)/*([\\w\\-/\\.]*)[\\?]*(.*)'\n",
    "        found = re.findall(regexp, str(url))\n",
    "        if len(found) > 0:\n",
    "            return re.findall(regexp, url)[0]\n",
    "        else:\n",
    "            return ('', '', '', '')\n",
    "    def __parse_json(x):\n",
    "        d = json.loads(x)\n",
    "        hosts = [__parse_url(x['url'])[1] for x in d]\n",
    "        return hosts\n",
    "    return pdf.apply(lambda x: __parse_json(x))\n",
    "\n",
    "visits = users.withColumn(\"hosts\", extract_hosts(f.get_json_object(f.col(\"user_json\"), \"$.visits\"))).drop('user_json')\n",
    "visits.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------\n",
      " gender      | F                                                                               \n",
      " age         | 18-24                                                                           \n",
      " uid         | d50192e5-c44e-4ae8-ae7a-7cfe67c8b777                                            \n",
      " hosts       | [zebra-zoya.ru, news.yandex.ru, www.sotovik.ru, news.yandex.ru, www.sotovik.ru] \n",
      " host_counts | 5                                                                               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visits = visits.withColumn(\"host_counts\", f.size(f.col(\"hosts\")))\n",
    "visits.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = visits.groupBy(\"gender\").count().collect()\n",
    "ages = visits.groupBy(\"age\").count().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: ('F', '>=55'),\n",
       "  1: ('F', '45-54'),\n",
       "  2: ('F', '-'),\n",
       "  3: ('F', '35-44'),\n",
       "  4: ('F', '25-34'),\n",
       "  5: ('F', '18-24'),\n",
       "  6: ('M', '>=55'),\n",
       "  7: ('M', '45-54'),\n",
       "  8: ('M', '-'),\n",
       "  9: ('M', '35-44'),\n",
       "  10: ('M', '25-34'),\n",
       "  11: ('M', '18-24'),\n",
       "  12: ('-', '>=55'),\n",
       "  13: ('-', '45-54'),\n",
       "  14: ('-', '-'),\n",
       "  15: ('-', '35-44'),\n",
       "  16: ('-', '25-34'),\n",
       "  17: ('-', '18-24')},\n",
       " {('F', '>=55'): 0,\n",
       "  ('F', '45-54'): 1,\n",
       "  ('F', '-'): 2,\n",
       "  ('F', '35-44'): 3,\n",
       "  ('F', '25-34'): 4,\n",
       "  ('F', '18-24'): 5,\n",
       "  ('M', '>=55'): 6,\n",
       "  ('M', '45-54'): 7,\n",
       "  ('M', '-'): 8,\n",
       "  ('M', '35-44'): 9,\n",
       "  ('M', '25-34'): 10,\n",
       "  ('M', '18-24'): 11,\n",
       "  ('-', '>=55'): 12,\n",
       "  ('-', '45-54'): 13,\n",
       "  ('-', '-'): 14,\n",
       "  ('-', '35-44'): 15,\n",
       "  ('-', '25-34'): 16,\n",
       "  ('-', '18-24'): 17})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_targets = [(row1.gender, row2.age) for row1 in genders for row2 in ages]\n",
    "target_map = {i: t for i, t in zip(range(len(genders) * len(ages)), all_targets)}\n",
    "target_map_rev = {t: i for i, t in zip(range(len(genders) * len(ages)), all_targets)}\n",
    "target_map, target_map_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcasted_target_map = spark.sparkContext.broadcast(target_map)\n",
    "broadcasted_target_map_rev = spark.sparkContext.broadcast(target_map_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------\n",
      " gender      | F                                                                               \n",
      " age         | 18-24                                                                           \n",
      " uid         | d50192e5-c44e-4ae8-ae7a-7cfe67c8b777                                            \n",
      " hosts       | [zebra-zoya.ru, news.yandex.ru, www.sotovik.ru, news.yandex.ru, www.sotovik.ru] \n",
      " host_counts | 5                                                                               \n",
      " target      | 5                                                                               \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@f.udf(IntegerType())\n",
    "def map_targets(gender, age):\n",
    "    target_map_rev = broadcasted_target_map_rev.value\n",
    "    return target_map_rev[(gender, age)]\n",
    "visits = visits.withColumn(\"target\", map_targets(f.col('gender'), f.col('age')))\n",
    "visits.show(1, vertical=True, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = [\n",
    "    'host_counts'\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=num_features, outputCol=\"num_features\")\n",
    "scaler = StandardScaler(inputCol=assembler.getOutputCol(), outputCol=\"num_features_scaled\")\n",
    "num_pipeline = Pipeline(stages=[assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_encoder = HashingTF(inputCol=\"hosts\", outputCol=\"features\")\n",
    "host_pipeline = Pipeline(stages=[host_encoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assemble = VectorAssembler(inputCols=[host_pipeline.getStages()[-1].getOutputCol()], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Pipeline(stages=[num_pipeline, host_pipeline, all_assemble])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = visits.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=transformer.getStages()[-1].getOutputCol(), labelCol=\"target\", maxIter=15)\n",
    "estimator = Pipeline(stages=[host_encoder, lr])\n",
    "model = estimator.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1425"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = prediction.select(\"target\", f.col(\"prediction\").cast(\"int\")) \\\n",
    "    .filter(\"target == prediction\").count()\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8118"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = prediction.count()\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.17553584626755359\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format(correct_predictions / all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=transformer.getStages()[-1].getOutputCol(), labelCol=\"target\", \n",
    "                  numTrees=10, maxDepth=10, seed=42)\n",
    "estimator = Pipeline(stages=[host_encoder, rf])\n",
    "model = estimator.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1716"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = prediction.select(\"target\", f.col(\"prediction\").cast(\"int\")) \\\n",
    "    .filter(\"target == prediction\").count()\n",
    "correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8118"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions = prediction.count()\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.21138211382113822\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is {}\".format(correct_predictions / all_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVERS = 'spark-master-1.newprolab.com:6667'\n",
    "INPUT_TOPIC = \"input_andrey.sorokin\"\n",
    "OUTPUT_TOPIC = \"andrey.sorokin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "    \"subscribe\": INPUT_TOPIC,\n",
    "    \"startingOffsets\": \"earliest\"\n",
    "}\n",
    "kafka_sdf = spark.read.format(\"kafka\").options(**read_kafka_params).option(\"failOnDataLoss\", 'False').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "| key|               value|               topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     0|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     1|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     2|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     3|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     4|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     5|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     6|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     7|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     8|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|     9|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    10|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    11|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    12|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    13|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    14|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    15|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    16|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    17|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    18|2022-10-29 18:22:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|input_andrey.sorokin|        0|    19|2022-10-29 18:22:...|            0|\n",
      "+----+--------------------+--------------------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 uid|               hosts|\n",
      "+--------------------+--------------------+\n",
      "|bd7a30e1-a25d-4cb...|[www.interfax.ru,...|\n",
      "|bd7a6f52-45db-49b...|[www.packagetrack...|\n",
      "|bd7a7fd9-ab06-42f...|[www.mk.ru, www.m...|\n",
      "|bd7c5d7a-0def-41d...|[www.24open.ru, w...|\n",
      "|bd7e54a2-0215-45c...|[www.dns-shop.ru,...|\n",
      "|bd7e9797-4cdb-46e...|      [news.meta.ua]|\n",
      "|bd7e9ec7-fb67-45e...|[dynamobryansk.fo...|\n",
      "|bd8056df-cc25-4b6...|[www.2mm.ru, www....|\n",
      "|bd818690-73d2-445...|[www.lacywear.ru,...|\n",
      "|bd81e006-f059-4cd...|       [nn.domru.ru]|\n",
      "|bd81e64a-bfa3-414...|[cache.betweendig...|\n",
      "|bd82fee4-afb3-408...|[apostrophe.com.u...|\n",
      "|bd83400b-abe2-42f...|[index.ru, com.ad...|\n",
      "|bd843c8c-dbba-4ec...|[katushka.net, ka...|\n",
      "|bd86d250-a6ee-41f...|[www.sq.com.ua, n...|\n",
      "|bd889738-93b2-402...|[www.proforientat...|\n",
      "|bd88fac5-3211-439...|[yourlust.com, tu...|\n",
      "|bd89a20f-a7af-462...|[yandex.ru, prime...|\n",
      "|bd8c2ee4-9c45-46d...|[video-dom2.ru, v...|\n",
      "|bd8f08a1-d845-4cb...|[live.russia.tv, ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = kafka_sdf.select(f.get_json_object(f.col(\"value\").cast(\"string\"), \"$.uid\").alias(\"uid\"),\n",
    "                 extract_hosts(f.get_json_object(f.col(\"value\").cast(\"string\"), \"$.visits\")).alias(\"hosts\"))\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 uid|               hosts|            features|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|bd7a30e1-a25d-4cb...|[www.interfax.ru,...|(262144,[1386,156...|[0.29451470104907...|[0.02945147010490...|      14.0|\n",
      "|bd7a6f52-45db-49b...|[www.packagetrack...|(262144,[1386,774...|[0.19073160619967...|[0.01907316061996...|      10.0|\n",
      "|bd7a7fd9-ab06-42f...|[www.mk.ru, www.m...|(262144,[179661,2...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd7c5d7a-0def-41d...|[www.24open.ru, w...|(262144,[9670,135...|[0.20703404009113...|[0.02070340400911...|      10.0|\n",
      "|bd7e54a2-0215-45c...|[www.dns-shop.ru,...|(262144,[4368,372...|[0.19284246114706...|[0.01928424611470...|      10.0|\n",
      "|bd7e9797-4cdb-46e...|      [news.meta.ua]|(262144,[142399],...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd7e9ec7-fb67-45e...|[dynamobryansk.fo...|(262144,[155739],...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd8056df-cc25-4b6...|[www.2mm.ru, www....|(262144,[191897,2...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd818690-73d2-445...|[www.lacywear.ru,...|(262144,[117590,1...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd81e006-f059-4cd...|       [nn.domru.ru]|(262144,[165011],...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd81e64a-bfa3-414...|[cache.betweendig...|(262144,[137314,1...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd82fee4-afb3-408...|[apostrophe.com.u...|(262144,[12826,17...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd83400b-abe2-42f...|[index.ru, com.ad...|(262144,[3282,177...|[0.20703404009113...|[0.02070340400911...|      10.0|\n",
      "|bd843c8c-dbba-4ec...|[katushka.net, ka...|(262144,[12004,23...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd86d250-a6ee-41f...|[www.sq.com.ua, n...|(262144,[4588,540...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "|bd889738-93b2-402...|[www.proforientat...|(262144,[3357,212...|[0.23598217137107...|[0.02359821713710...|      10.0|\n",
      "|bd88fac5-3211-439...|[yourlust.com, tu...|(262144,[2157,832...|[0.17571973363880...|[0.01757197336388...|      10.0|\n",
      "|bd89a20f-a7af-462...|[yandex.ru, prime...|(262144,[36876,37...|[0.20703404009113...|[0.02070340400911...|      10.0|\n",
      "|bd8c2ee4-9c45-46d...|[video-dom2.ru, v...|(262144,[36876,42...|[0.20703404009113...|[0.02070340400911...|      10.0|\n",
      "|bd8f08a1-d845-4cb...|[live.russia.tv, ...|(262144,[70311,14...|[0.21016184237876...|[0.02101618423787...|      10.0|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.transform(test)\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.udf(StringType())\n",
    "def unmap_gender(target):\n",
    "    target_map = broadcasted_target_map.value\n",
    "    return target_map[target][0]\n",
    "\n",
    "@f.udf(StringType())\n",
    "def unmap_age(target):\n",
    "    target_map = broadcasted_target_map.value\n",
    "    return target_map[target][1]\n",
    "\n",
    "out_df = pred.select(f.to_json(f.struct(\"uid\", \n",
    "        unmap_gender(f.col(\"prediction\")).alias(\"gender\"), \n",
    "        unmap_age(f.col(\"prediction\")).alias(\"age\"))).alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|value                                                                    |\n",
      "+-------------------------------------------------------------------------+\n",
      "|{\"uid\":\"bd7a30e1-a25d-4cbf-a03f-61748cbe540e\",\"gender\":\"-\",\"age\":\"-\"}    |\n",
      "|{\"uid\":\"bd7a6f52-45db-49bf-90f2-a3b07a9b7bcd\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd7a7fd9-ab06-42f5-bf0f-1cbb0463004c\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd7c5d7a-0def-41d1-895f-fdb96c56c2d4\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd7e54a2-0215-45cb-a869-9efebf250e38\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd7e9797-4cdb-46e1-a540-f3ea010605ad\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd7e9ec7-fb67-45eb-8ad3-209d01d15ae6\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd8056df-cc25-4b63-bc12-a46f888baa49\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd818690-73d2-445d-be5d-5c8f748dbb19\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "|{\"uid\":\"bd81e006-f059-4cdd-b716-3467c78d1312\",\"gender\":\"M\",\"age\":\"25-34\"}|\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_kafka_params = {\n",
    "   \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "   \"topic\": OUTPUT_TOPIC\n",
    "}\n",
    "out_df.write.format(\"kafka\").options(**write_kafka_params).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------+---------+------+--------------------+-------------+\n",
      "| key|               value|         topic|partition|offset|           timestamp|timestampType|\n",
      "+----+--------------------+--------------+---------+------+--------------------+-------------+\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     0|2022-10-29 21:41:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     1|2022-10-29 21:41:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     2|2022-10-29 21:41:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     3|2022-10-29 21:41:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     4|2022-10-29 21:41:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     5|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     6|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     7|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     8|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|     9|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    10|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    11|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    12|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    13|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    14|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    15|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    16|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    17|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    18|2022-10-29 21:54:...|            0|\n",
      "|null|[7B 22 75 69 64 2...|andrey.sorokin|        0|    19|2022-10-29 21:54:...|            0|\n",
      "+----+--------------------+--------------+---------+------+--------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "    \"subscribe\": OUTPUT_TOPIC,\n",
    "    \"startingOffsets\": \"earliest\"\n",
    "}\n",
    "test_test  = spark.read.format(\"kafka\").options(**test_kafka_params) \\\n",
    "    .option(\"failOnDataLoss\", 'False').load()\n",
    "test_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": KAFKA_BOOTSTRAP_SERVERS,\n",
    "    \"subscribe\": INPUT_TOPIC,\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "kafka_sdf = spark.readStream.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_df = kafka_sdf.select(f.get_json_object(f.col(\"value\").cast(\"string\"), \"$.uid\").alias(\"uid\"),\n",
    "                 extract_hosts(f.get_json_object(f.col(\"value\").cast(\"string\"), \"$.visits\")).alias(\"hosts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = model.transform(parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pred_df.select(f.to_json(f.struct(\"uid\", \n",
    "                                           unmap_gender(f.col(\"prediction\")).alias(\"gender\"), \n",
    "                                           unmap_age(f.col(\"prediction\")).alias(\"age\"))).alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f70bc0c8a58>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.writeStream.format(\"kafka\").options(**write_kafka_params)\\\n",
    "    .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\")\\\n",
    "    .outputMode(\"append\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pyspark.sql.streaming.StreamingQuery at 0x7f70bc0b3668>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streams = SparkSession.builder.getOrCreate().streams.active\n",
    "streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped KafkaV2[Subscribe[input_andrey.sorokin]]\n"
     ]
    }
   ],
   "source": [
    "if streams:\n",
    "    for s in streams:\n",
    "        if s.lastProgress[\"sources\"][0] is not None: \n",
    "            desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "        else:\n",
    "            desc = \"Unknown\"\n",
    "        s.stop()\n",
    "        print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
