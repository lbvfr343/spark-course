{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()\n",
    "#sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 1 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"PGG-try4\") \n",
    "#conf.set(\"spark.driver.allowMultipleContexts\", True) \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, CountVectorizer,StringIndexer,OneHotEncoder\n",
    "import pyspark.sql.functions as f_\n",
    "from pyspark.sql.types import FloatType, StructType, StructField, IntegerType, StringType, ArrayType,TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml import Pipeline\n",
    "import json\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@f_.udf(StringType())\n",
    "def url_cyr(url):\n",
    "    return str(unquote(url))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.csv('/labs/slaba04/gender_age_dataset.txt',sep='\\t',header=True)\n",
    "json_schema = \"map<string, array<struct<url:string,timestamp:string>>>\"\n",
    "\n",
    "tabular_data = data.withColumn('json', f_.from_json(f_.col('user_json'), json_schema))\\\n",
    "    .select('gender', 'age', 'uid', f_.explode('json'))\\\n",
    "    .select('gender', 'age', 'uid',f_.explode('value'))\\\n",
    "    .select('gender', 'age', 'uid',f_.col('col').url.alias('url'), f_.col('col').timestamp.alias('timestamp'))\\\n",
    "    .select('gender', 'age', 'uid',f_.col('timestamp').alias('ts_original'),f_.to_timestamp(f_.from_unixtime(f_.col('timestamp')/1000)).alias('timestamp'), url_cyr(f_.col('url')).alias('url'))\\\n",
    "    .select('*'\n",
    "                ,f_.concat(f_.col('gender'),f_.lit('_'),f_.col('age')).alias('label')\n",
    "                ,f_.regexp_replace(f_.lower(f_.split(f_.col('url'),'/').getItem(2)),'www.','').alias('domain')\n",
    "                ,f_.when((f_.length(f_.split(f_.col('url'),'\\\\?').getItem(0))  >  f_.coalesce(f_.length(f_.split(f_.col('url'),'\\\\?').getItem(1)),f_.lit(0))), f_.split(f_.col('url'),'\\\\?').getItem(0) ).otherwise(f_.col('url')).alias('url2'))\\\n",
    "    .select('*',f_.trim(f_.lower(f_.regexp_replace(f_.regexp_replace('url2',r'[^\\pL\\p{Space}]',' ' ),'[ ]+',' '))).alias('url_words'))\\\n",
    "            .withColumn(\"lag_ts\",f_.lag('timestamp').over(Window.partitionBy(\"uid\").orderBy(f_.col('timestamp'))))\\\n",
    "            .withColumn(\"lag_domain\",f_.lag('domain').over(Window.partitionBy(\"uid\").orderBy(f_.col('timestamp'))))\\\n",
    "    .select('*'\n",
    "                ,(f_.col('timestamp').cast('long') - f_.col('lag_ts').cast('long')).alias('timediff')\n",
    "            ,f_.when(((f_.col('lag_domain').isNotNull()) & (f_.col('lag_domain') != f_.col('domain'))),f_.lit(1)).otherwise(f_.lit(0)).alias('change_site_flg')\n",
    "           )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tabular_data=tabular_data.groupBy('gender', 'age', 'label','uid').agg(\n",
    "     f_.concat_ws( ' ',f_.collect_list(f_.col('url_words'))).alias('urls_w')\n",
    "    ,f_.concat_ws( ' ',f_.collect_list(f_.col('domain'))).alias('domains')\n",
    "    ,f_.max('timestamp').cast('long').alias('max_ts')\n",
    "    ,f_.min('timestamp').cast('long').alias('min_ts')\n",
    "    ,f_.avg('timestamp').cast('long').alias('avg_ts')\n",
    "    ,f_.max('timediff').alias('max_tdiff')\n",
    "    ,f_.min('timediff').alias('min_tdiff')\n",
    "    ,f_.avg('timediff').alias('avg_tdiff')\n",
    "    ,f_.countDistinct('domain').alias('domain_cnt')\n",
    "    ,f_.sum('change_site_flg').alias('change_site_cnt')\n",
    "    ,f_.count('*').alias('visit_cnt')\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 81.3 ms, sys: 21.7 ms, total: 103 ms\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "si = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "stop_words_url=['www','http','html','htm','utm','php']\n",
    "tokenizer = Tokenizer(inputCol=\"urls_w\", outputCol=\"words\")\n",
    "tokenizer2 = Tokenizer(inputCol=\"domains\", outputCol=\"domains_w\")\n",
    "swr=StopWordsRemover(inputCol=\"words\", outputCol=\"words_censored\", stopWords=stop_words_url)\n",
    "tf = HashingTF(numFeatures =75,inputCol=\"words_censored\", outputCol=\"tf\")\n",
    "tf2 = HashingTF(numFeatures =100,inputCol=\"domains_w\", outputCol=\"domain_tf\")\n",
    "\n",
    "tfidf = IDF(inputCol=\"tf\", outputCol=\"idf\")\n",
    "tfidf2 = IDF(inputCol=\"domain_tf\", outputCol=\"domain_idf\")\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenizer,\n",
    "    tokenizer2,\n",
    "    swr,\n",
    "    tf,\n",
    "    tf2,\n",
    "    tfidf,\n",
    "    tfidf2\n",
    "])\n",
    "\n",
    "calc=pipeline.fit(grouped_tabular_data)\n",
    "tabular_tfidf_data=calc.transform(grouped_tabular_data)\n",
    "si_label=si.fit(tabular_tfidf_data)\n",
    "tabular_labled_tfidf_data=si_label.transform(tabular_tfidf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " gender          | -                                                                                                                                                                                                                                                                                                                                                \n",
      " age             | -                                                                                                                                                                                                                                                                                                                                                \n",
      " label           | -_-                                                                                                                                                                                                                                                                                                                                              \n",
      " uid             | 0108d217-e476-493d-8c81-a9744f12451a                                                                                                                                                                                                                                                                                                             \n",
      " urls_w          | http kvartblog ru blog cherno belyj novyj god http kvartblog ru blog elka iz fotografij master klass http kvartblog ru blog prazdnichnaja kvartira s kaminom v tsentre madrida                                                                                                                                                                   \n",
      " domains         | kvartblog.ru kvartblog.ru kvartblog.ru                                                                                                                                                                                                                                                                                                           \n",
      " max_ts          | 1419843739                                                                                                                                                                                                                                                                                                                                       \n",
      " min_ts          | 1419843601                                                                                                                                                                                                                                                                                                                                       \n",
      " avg_ts          | 1419843669                                                                                                                                                                                                                                                                                                                                       \n",
      " max_tdiff       | 70                                                                                                                                                                                                                                                                                                                                               \n",
      " min_tdiff       | 68                                                                                                                                                                                                                                                                                                                                               \n",
      " avg_tdiff       | 69.0                                                                                                                                                                                                                                                                                                                                             \n",
      " domain_cnt      | 1                                                                                                                                                                                                                                                                                                                                                \n",
      " change_site_cnt | 0                                                                                                                                                                                                                                                                                                                                                \n",
      " visit_cnt       | 3                                                                                                                                                                                                                                                                                                                                                \n",
      " words           | [http, kvartblog, ru, blog, cherno, belyj, novyj, god, http, kvartblog, ru, blog, elka, iz, fotografij, master, klass, http, kvartblog, ru, blog, prazdnichnaja, kvartira, s, kaminom, v, tsentre, madrida]                                                                                                                                      \n",
      " domains_w       | [kvartblog.ru, kvartblog.ru, kvartblog.ru]                                                                                                                                                                                                                                                                                                       \n",
      " words_censored  | [kvartblog, ru, blog, cherno, belyj, novyj, god, kvartblog, ru, blog, elka, iz, fotografij, master, klass, kvartblog, ru, blog, prazdnichnaja, kvartira, s, kaminom, v, tsentre, madrida]                                                                                                                                                        \n",
      " tf              | (75,[2,10,24,34,36,38,40,42,45,48,51,52,61,70,72],[1.0,2.0,1.0,1.0,1.0,1.0,2.0,1.0,7.0,1.0,1.0,1.0,1.0,3.0,1.0])                                                                                                                                                                                                                                 \n",
      " domain_tf       | (100,[57],[3.0])                                                                                                                                                                                                                                                                                                                                 \n",
      " idf             | (75,[2,10,24,34,36,38,40,42,45,48,51,52,61,70,72],[0.4881304209644578,1.1995183317013194,0.4608620413350178,0.622510830195803,0.7032861580008227,0.598652750743655,1.3454397881444415,0.5681170246012941,0.46881721741285987,0.6117871084334605,0.6939983168782443,0.6594709068563536,0.6450506089089934,1.1595107986482873,0.5613187856222133]) \n",
      " domain_idf      | (100,[57],[5.972942544011325])                                                                                                                                                                                                                                                                                                                   \n",
      " indexedLabel    | 3.0                                                                                                                                                                                                                                                                                                                                              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabular_labled_tfidf_data.show(1,truncate=False,vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'age', 'label', 'uid', 'urls_w', 'domains', 'max_ts', 'min_ts', 'avg_ts', 'max_tdiff', 'min_tdiff', 'avg_tdiff', 'domain_cnt', 'change_site_cnt', 'visit_cnt', 'words', 'domains_w', 'words_censored', 'tf', 'domain_tf', 'idf', 'domain_idf', 'indexedLabel']\n"
     ]
    }
   ],
   "source": [
    "print(tabular_labled_tfidf_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list=[ 'max_ts', 'min_ts', 'avg_ts', 'max_tdiff', 'min_tdiff', 'avg_tdiff', 'visit_cnt', 'idf', 'domain_idf','domain_cnt','change_site_cnt']\n",
    "assembler = VectorAssembler(inputCols=feature_list, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=assembler.transform(tabular_labled_tfidf_data.fillna( {'min_tdiff':0,'max_tdiff':0,'avg_tdiff':0} )).select('uid','indexedLabel','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/igor.gorchakov/train_data_lab04.parquet': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r /user/igor.gorchakov/train_data_lab04.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.write.parquet('train_data_lab04.parquet',mode='overwrite')\n",
    "train_data=spark.read.parquet('/user/igor.gorchakov/train_data_lab04.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = train_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "trainingData = train_data.sampleBy(\"indexedLabel\", \n",
    "        fractions={0: 0.7, 1: 0.7, 2: 0.7, 3: 0.7, 4: 0.7, 5: 0.7, 6: 0.7, 7: 0.7, 8: 0.7,9: 0.7, 10: 0.7}, seed=713)\n",
    "testData = train_data.join(trainingData, on=['uid'], how=\"leftanti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+\n",
      "|                 uid|indexedLabel|            features|\n",
      "+--------------------+------------+--------------------+\n",
      "|00c5207a-1bea-453...|         3.0|(184,[0,1,2,6,11,...|\n",
      "+--------------------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 ms, sys: 1.04 ms, total: 28.7 ms\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=100,maxDepth=10)\n",
    "model_rf=rf.fit(trainingData)\n",
    "predictions_train_=model_rf.transform(trainingData)\n",
    "predictions_=model_rf.transform(testData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.6 ms, sys: 275 µs, total: 1.87 ms\n",
      "Wall time: 8.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.97 ms, sys: 513 µs, total: 7.48 ms\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_ = evaluator.evaluate(predictions_)\n",
    "accuracy_train_ = evaluator.evaluate(predictions_train_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3495542991918421 0.21946859510847486\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_train_, accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21946859510847486\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "drwxr-xr-x   - igor.gorchakov igor.gorchakov          0 2022-11-09 11:55 .sparkStaging\r\n",
      "drwxr-xr-x   - igor.gorchakov igor.gorchakov          0 2022-11-07 21:02 lab05.csv\r\n",
      "drwxr-xr-x   - igor.gorchakov igor.gorchakov          0 2022-10-11 18:08 test_save.txt\r\n",
      "drwxr-xr-x   - igor.gorchakov igor.gorchakov          0 2022-11-09 11:57 train_data_lab04.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.save('rf_1g.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = RandomForestClassificationModel.load('rf_1g.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is : 11:59:54\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time is :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_igor.gorchakov\",\n",
    "    \"checkpointLocation\":\"/tmp/chk_gr/{n}\".format(n='igor.gorchakov'),\n",
    "    \"startingOffsets\": \"earliest\"\n",
    "}\n",
    "kafka_sdf = spark.read.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = \"map<string, array<struct<url:string,timestamp:string>>>\"\n",
    "kafka_in_tabular_data=kafka_sdf.select(f_.get_json_object(f_.col(\"value\").cast(\"string\"), \"$.uid\").alias(\"uid\"),\n",
    "                f_.concat(f_.lit('''{\"visits\": '''),f_.get_json_object(f_.col(\"value\").cast(\"string\"), \"$.visits\"),f_.lit('''}''')).alias(\"user_json\")\n",
    "                ).withColumn('json', f_.from_json(f_.col('user_json'), json_schema))\\\n",
    "    .select('uid', f_.explode('json'))\\\n",
    "    .select('uid',f_.explode('value'))\\\n",
    "    .select('uid',f_.col('col').url.alias('url'), f_.col('col').timestamp.alias('timestamp'))\\\n",
    "    .select( 'uid',f_.col('timestamp').alias('ts_original'),f_.to_timestamp(f_.from_unixtime(f_.col('timestamp')/1000)).alias('timestamp'), url_cyr(f_.col('url')).alias('url'))\\\n",
    "    .select('*'\n",
    "                ,f_.regexp_replace(f_.lower(f_.split(f_.col('url'),'/').getItem(2)),'www.','').alias('domain')\n",
    "                ,f_.when((f_.length(f_.split(f_.col('url'),'\\\\?').getItem(0))  >  f_.coalesce(f_.length(f_.split(f_.col('url'),'\\\\?').getItem(1)),f_.lit(0))), f_.split(f_.col('url'),'\\\\?').getItem(0) ).otherwise(f_.col('url')).alias('url2'))\\\n",
    "    .select('*',f_.trim(f_.lower(f_.regexp_replace(f_.regexp_replace('url2',r'[^\\pL\\p{Space}]',' ' ),'[ ]+',' '))).alias('url_words'))\\\n",
    "            .withColumn(\"lag_ts\",f_.lag('timestamp').over(Window.partitionBy(\"uid\").orderBy(f_.col('timestamp'))))\\\n",
    "            .withColumn(\"lag_domain\",f_.lag('domain').over(Window.partitionBy(\"uid\").orderBy(f_.col('timestamp'))))\\\n",
    "    .select('*'\n",
    "                ,(f_.col('timestamp').cast('long') - f_.col('lag_ts').cast('long')).alias('timediff')\n",
    "            ,f_.when(((f_.col('lag_domain').isNotNull()) & (f_.col('lag_domain') != f_.col('domain'))),f_.lit(1)).otherwise(f_.lit(0)).alias('change_site_flg')\n",
    "           )\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_in_grouped_tabular_data=kafka_in_tabular_data.groupBy('uid').agg(\n",
    "     f_.concat_ws( ' ',f_.collect_list(f_.col('url_words'))).alias('urls_w')\n",
    "    ,f_.concat_ws( ' ',f_.collect_list(f_.col('domain'))).alias('domains')\n",
    "    ,f_.max('timestamp').cast('long').alias('max_ts')\n",
    "    ,f_.min('timestamp').cast('long').alias('min_ts')\n",
    "    ,f_.avg('timestamp').cast('long').alias('avg_ts')\n",
    "    ,f_.max('timediff').alias('max_tdiff')\n",
    "    ,f_.min('timediff').alias('min_tdiff')\n",
    "    ,f_.avg('timediff').alias('avg_tdiff')\n",
    "    ,f_.countDistinct('domain').alias('domain_cnt')\n",
    "    ,f_.sum('change_site_flg').alias('change_site_cnt')\n",
    "    ,f_.count('*').alias('visit_cnt')\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_in_grouped_tabular_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 ms, sys: 23.3 ms, total: 49 ms\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kafka_tabular_tfidf_data=calc.transform(kafka_in_grouped_tabular_data)\n",
    "test_data=assembler.transform(kafka_tabular_tfidf_data).select('uid','features')\n",
    "model_load=RandomForestClassificationModel.load('rf_1g.sav')\n",
    "test_predictions=model_load.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decode=spark.createDataFrame([[float(i),v.split('_')[0],v.split('_')[1]] for i,v in enumerate(si_label.labels)],schema='prediction:float, gender:string,age:string')\n",
    "result=test_predictions.join(label_decode,['prediction'],'left').select('uid','gender','age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_kafka(topic, data):\n",
    "    kafka_params = {\"kafka.bootstrap.servers\": \"spark-master-1.newprolab.com:6667\"}\n",
    "    kafka_doc = f_.to_json(f_.struct(f_.col(\"*\")))\n",
    "    raw = data \\\n",
    "        .select(kafka_doc.alias(\"value\")) \\\n",
    "        .withColumn(\"topic\", f_.lit(topic))\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18 ms, sys: 15.2 ms, total: 33.2 ms\n",
      "Wall time: 58.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_kafka_params = {\n",
    "   \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "   \"topic\": \"igor.gorchakov\",\n",
    "\"checkpointLocation\":\"/tmp/chk_gr/{n}\".format(n='igor.gorchakov')\n",
    "}\n",
    "write_kafka('igor.gorchakov',result).write.format(\"kafka\").options(**write_kafka_params)\\\n",
    "    .option(\"checkpointLocation\", \"/tmp/chk_gr/{n}\".format(n='igor.gorchakov')).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time is : 12:01:25\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time is :\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()\n",
    "#sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
