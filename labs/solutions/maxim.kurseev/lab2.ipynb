{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лаба 2. Content-based рекомендательная система образовательных курсов – Spark Dataframes\n",
    "По имеющимся данным портала eclass.cc построить content-based рекомендации по образовательным курсам. \n",
    "Запрещено использовать библиотеки pandas, sklearn и аналогичные.\n",
    "\n",
    "**Для подбора рекомендаций следует использовать меру TFIDF, а в качестве метрики для ранжирования — косинус угла между TFIDF-векторами для разных курсов. TFIDF нужно считать для описаний курсов `desc`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --driver-memory 2g pyspark-shell'\n",
    "\n",
    "regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, ArrayType, DoubleType\n",
    "import json\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Kurseev Maxim Spark Dataframe lab\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Kurseev Maxim Spark Dataframe lab\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Kurseev Maxim Spark Dataframe lab</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f84722080f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "**Сourses to make recommendations:** `23126, 21617, 16627, 11556, 16704, 13702`\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_list = [23126, 21617, 16627, 11556, 16704, 13702]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## почему-то land становится Null если схему использовать - забью на нее пока\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField('cat', StringType()),\n",
    "    StructField('desc', StringType()),\n",
    "    StructField('id', IntegerType()),\n",
    "    StructField('land', StringType()),\n",
    "    StructField('name', StringType()),\n",
    "    StructField('provider', StringType()),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "data = data.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " cat      | 3/business_manage... \n",
      " desc     |  Unique video ske... \n",
      " id       | 10209                \n",
      " lang     | en                   \n",
      " name     | Learn How To Writ... \n",
      " provider | Udemy                \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(1, vertical=True, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(lang='en'), Row(lang='es'), Row(lang='ru')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter(F.col('id').isin(film_list)).select('lang').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(ArrayType(StringType()))\n",
    "def tokenizer_udf(series):\n",
    "    regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "    words = regex.findall(series)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " id       | 16189                \n",
      " features | (10000,[842,1341,... \n",
      " lang     | en                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_tokenized = (data\n",
    "                  .filter(\n",
    "                      (F.col('desc') != ' ') & \n",
    "                      (F.col('lang').isin(['en','es','ru']))\n",
    "                         )\n",
    "                  .withColumn('desc', F.lower(F.col('desc')))\n",
    "                  .select('id', 'desc', 'lang')\n",
    "                  .withColumn('word_tok', tokenizer_udf('desc'))\n",
    "                 )\n",
    "\n",
    "## removing stop_words\n",
    "\n",
    "stopwordListRus = StopWordsRemover.loadDefaultStopWords(\"russian\")\n",
    "stopwordListEng = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stopwordListEsp = StopWordsRemover.loadDefaultStopWords(\"spanish\")\n",
    "\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"word_tok\", \n",
    "                           outputCol=\"word_list\" ,\n",
    "                           stopWords=stopwordListRus + stopwordListEng + stopwordListEsp)\n",
    "\n",
    "data_tokenized_no_stop_words = remover.transform(data_tokenized).select('id','word_list','lang')\n",
    "\n",
    "## hashing\n",
    "\n",
    "hasher = HashingTF(numFeatures=10000, binary=False, inputCol='word_list', outputCol=\"word_vector\")\n",
    "hashed_data = hasher.transform(data_tokenized_no_stop_words)\n",
    "\n",
    "## tf-idf\n",
    "\n",
    "idf = IDF(inputCol=\"word_vector\", outputCol=\"features\")\n",
    "idfModel = idf.fit(hashed_data)\n",
    "\n",
    "allData = idfModel.transform(hashed_data).select('id', 'features','lang')\n",
    "\n",
    "allData.show(1, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## func \n",
    "cosine_similarity = F.udf(lambda v, u: float(v.dot(u) / (v.norm(2) * u.norm(2))), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23126\n",
      "21617\n",
      "16627\n",
      "11556\n",
      "16704\n",
      "13702\n"
     ]
    }
   ],
   "source": [
    "for id_ in film_list:\n",
    "\n",
    "    temp_id = (allData.filter(F.col('id') == id_)\n",
    "               .withColumnRenamed('id','matched_id')\n",
    "               .withColumnRenamed('features','features_single')\n",
    "               .join(\n",
    "                   allData.withColumn('matched_id', F.lit(id_)), \n",
    "                   how='left',\n",
    "                   on=['matched_id','lang']\n",
    "               )\n",
    "               .withColumn('cosine_similarity', cosine_similarity('features_single', 'features'))\n",
    "               .filter(~F.isnan(F.col('cosine_similarity')))\n",
    "               .sort(F.col('cosine_similarity').desc())\n",
    "               .filter(F.col('matched_id') != F.col('id'))\n",
    "               .select('id')\n",
    "              )\n",
    "    ids = temp_id.take(10)\n",
    "\n",
    "    answers[str(id_)] = [ids[i][0] for i in range(10)]\n",
    "    print(id_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------------------+-----+--------------------+-----------------+\n",
      "|matched_id|lang|     features_single|   id|            features|cosine_similarity|\n",
      "+----------+----+--------------------+-----+--------------------+-----------------+\n",
      "|     21617|  en|(10000,[17,161,36...|21609|(10000,[17,161,36...|              1.0|\n",
      "|     21617|  en|(10000,[17,161,36...|21616|(10000,[161,173,3...|        0.5303736|\n",
      "|     21617|  en|(10000,[17,161,36...|22298|(10000,[32,157,16...|        0.5222076|\n",
      "|     21617|  en|(10000,[17,161,36...|21608|(10000,[161,173,3...|         0.507748|\n",
      "|     21617|  en|(10000,[17,161,36...|21628|(10000,[9,20,32,1...|       0.49559322|\n",
      "+----------+----+--------------------+-----+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21609, 21616, 22298, 21608, 21628, 21630, 21081, 19417, 21623, 21508]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['21617']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lab02.json\", \"w\") as f:\n",
    "    json.dump(answers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
