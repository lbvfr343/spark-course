{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f574968d630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По имеющимся данным о рейтингах фильмов (MovieLens: 100 000 рейтингов) посчитать агрегированную статистику по ним.\n",
    "\n",
    "Задание необходимо сделать, используя RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются следующие входные данные:\n",
    "\n",
    "Таблица users x movies с рейтингами. Архив с датасетом нужно скачать с сайта GroupLens. Также он загружен на HDFS в /labs/laba01/ml-100k. Файл u.data содержит все оценки, а файл u.item — список всех фильмов.\n",
    "Информация о структуре датасета расположена здесь.\n",
    "!hdfs dfs -ls /labs/laba01/ml-100k\n",
    "\n",
    "id фильма для расчета индивидуальных характеристик — в Личном кабинете на странице Лабы 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 items\r\n",
      "-rw-r--r--   3 hdfs hdfs       6750 2022-01-06 18:46 /labs/laba01/ml-100k/README\r\n",
      "-rw-r--r--   3 hdfs hdfs        716 2022-01-06 18:46 /labs/laba01/ml-100k/allbut.pl\r\n",
      "-rw-r--r--   3 hdfs hdfs        643 2022-01-06 18:46 /labs/laba01/ml-100k/mku.sh\r\n",
      "-rw-r--r--   3 hdfs hdfs    1979173 2022-01-06 18:46 /labs/laba01/ml-100k/u.data\r\n",
      "-rw-r--r--   3 hdfs hdfs        202 2022-01-06 18:46 /labs/laba01/ml-100k/u.genre\r\n",
      "-rw-r--r--   3 hdfs hdfs         36 2022-01-06 18:46 /labs/laba01/ml-100k/u.info\r\n",
      "-rw-r--r--   3 hdfs hdfs     236344 2022-01-06 18:46 /labs/laba01/ml-100k/u.item\r\n",
      "-rw-r--r--   3 hdfs hdfs        193 2022-01-06 18:46 /labs/laba01/ml-100k/u.occupation\r\n",
      "-rw-r--r--   3 hdfs hdfs      22628 2022-01-06 18:46 /labs/laba01/ml-100k/u.user\r\n",
      "-rw-r--r--   3 hdfs hdfs    1586544 2022-01-06 18:46 /labs/laba01/ml-100k/u1.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     392629 2022-01-06 18:46 /labs/laba01/ml-100k/u1.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1583948 2022-01-06 18:46 /labs/laba01/ml-100k/u2.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     395225 2022-01-06 18:46 /labs/laba01/ml-100k/u2.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1582546 2022-01-06 18:46 /labs/laba01/ml-100k/u3.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     396627 2022-01-06 18:46 /labs/laba01/ml-100k/u3.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581878 2022-01-06 18:46 /labs/laba01/ml-100k/u4.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397295 2022-01-06 18:46 /labs/laba01/ml-100k/u4.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1581776 2022-01-06 18:46 /labs/laba01/ml-100k/u5.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     397397 2022-01-06 18:46 /labs/laba01/ml-100k/u5.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792501 2022-01-06 18:46 /labs/laba01/ml-100k/ua.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186672 2022-01-06 18:46 /labs/laba01/ml-100k/ua.test\r\n",
      "-rw-r--r--   3 hdfs hdfs    1792476 2022-01-06 18:46 /labs/laba01/ml-100k/ub.base\r\n",
      "-rw-r--r--   3 hdfs hdfs     186697 2022-01-06 18:46 /labs/laba01/ml-100k/ub.test\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/laba01/ml-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sparkContext.textFile('/labs/laba01/ml-100k/u.data')\n",
    "item = spark.sparkContext.textFile('/labs/laba01/ml-100k/u.item')\n",
    "readme = spark.sparkContext.textFile('/labs/laba01/ml-100k/README')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SUMMARY & USAGE LICENSE',\n",
       " '=============================================',\n",
       " '',\n",
       " 'MovieLens data sets were collected by the GroupLens Research Project',\n",
       " 'at the University of Minnesota.',\n",
       " ' ',\n",
       " 'This data set consists of:',\n",
       " '\\t* 100,000 ratings (1-5) from 943 users on 1682 movies. ',\n",
       " '\\t* Each user has rated at least 20 movies. ',\n",
       " '        * Simple demographic info for the users (age, gender, occupation, zip)',\n",
       " '',\n",
       " 'The data was collected through the MovieLens web site',\n",
       " '(movielens.umn.edu) during the seven-month period from September 19th, ',\n",
       " '1997 through April 22nd, 1998. This data has been cleaned up - users',\n",
       " 'who had less than 20 ratings or did not have complete demographic',\n",
       " 'information were removed from this data set. Detailed descriptions of',\n",
       " 'the data file can be found at the end of this file.',\n",
       " '',\n",
       " 'Neither the University of Minnesota nor any of the researchers',\n",
       " 'involved can guarantee the correctness of the data, its suitability',\n",
       " 'for any particular purpose, or the validity of results based on the',\n",
       " 'use of the data set.  The data set may be used for any research',\n",
       " 'purposes under the following conditions:',\n",
       " '',\n",
       " '     * The user may not state or imply any endorsement from the',\n",
       " '       University of Minnesota or the GroupLens Research Group.',\n",
       " '',\n",
       " '     * The user must acknowledge the use of the data set in',\n",
       " '       publications resulting from the use of the data set',\n",
       " '       (see below for citation information).',\n",
       " '',\n",
       " '     * The user may not redistribute the data without separate',\n",
       " '       permission.',\n",
       " '',\n",
       " '     * The user may not use this information for any commercial or',\n",
       " '       revenue-bearing purposes without first obtaining permission',\n",
       " '       from a faculty member of the GroupLens Research Project at the',\n",
       " '       University of Minnesota.',\n",
       " '',\n",
       " 'If you have any further questions or comments, please contact GroupLens',\n",
       " '<grouplens-info@cs.umn.edu>. ',\n",
       " '',\n",
       " 'CITATION',\n",
       " '==============================================',\n",
       " '',\n",
       " 'To acknowledge use of the dataset in publications, please cite the ',\n",
       " 'following paper:',\n",
       " '',\n",
       " 'F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets:',\n",
       " 'History and Context. ACM Transactions on Interactive Intelligent',\n",
       " 'Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.',\n",
       " 'DOI=http://dx.doi.org/10.1145/2827872',\n",
       " '',\n",
       " '',\n",
       " 'ACKNOWLEDGEMENTS',\n",
       " '==============================================',\n",
       " '',\n",
       " 'Thanks to Al Borchers for cleaning up this data and writing the',\n",
       " 'accompanying scripts.',\n",
       " '',\n",
       " 'PUBLISHED WORK THAT HAS USED THIS DATASET',\n",
       " '==============================================',\n",
       " '',\n",
       " 'Herlocker, J., Konstan, J., Borchers, A., Riedl, J.. An Algorithmic',\n",
       " 'Framework for Performing Collaborative Filtering. Proceedings of the',\n",
       " '1999 Conference on Research and Development in Information',\n",
       " 'Retrieval. Aug. 1999.',\n",
       " '',\n",
       " 'FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT',\n",
       " '==============================================',\n",
       " '',\n",
       " 'The GroupLens Research Project is a research group in the Department',\n",
       " 'of Computer Science and Engineering at the University of Minnesota.',\n",
       " 'Members of the GroupLens Research Project are involved in many',\n",
       " 'research projects related to the fields of information filtering,',\n",
       " 'collaborative filtering, and recommender systems. The project is lead',\n",
       " 'by professors John Riedl and Joseph Konstan. The project began to',\n",
       " 'explore automated collaborative filtering in 1992, but is most well',\n",
       " 'known for its world wide trial of an automated collaborative filtering',\n",
       " 'system for Usenet news in 1996.  The technology developed in the',\n",
       " 'Usenet trial formed the base for the formation of Net Perceptions,',\n",
       " 'Inc., which was founded by members of GroupLens Research. Since then',\n",
       " 'the project has expanded its scope to research overall information',\n",
       " 'filtering solutions, integrating in content-based methods as well as',\n",
       " 'improving current collaborative filtering technology.',\n",
       " '',\n",
       " 'Further information on the GroupLens Research project, including',\n",
       " 'research publications, can be found at the following web site:',\n",
       " '        ',\n",
       " '        http://www.grouplens.org/',\n",
       " '',\n",
       " 'GroupLens Research currently operates a movie recommender based on',\n",
       " 'collaborative filtering:',\n",
       " '',\n",
       " '        http://www.movielens.org/',\n",
       " '',\n",
       " 'DETAILED DESCRIPTIONS OF DATA FILES',\n",
       " '==============================================',\n",
       " '',\n",
       " 'Here are brief descriptions of the data.',\n",
       " '',\n",
       " 'ml-data.tar.gz   -- Compressed tar file.  To rebuild the u data files do this:',\n",
       " '                gunzip ml-data.tar.gz',\n",
       " '                tar xvf ml-data.tar',\n",
       " '                mku.sh',\n",
       " '',\n",
       " 'u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.',\n",
       " '              Each user has rated at least 20 movies.  Users and items are',\n",
       " '              numbered consecutively from 1.  The data is randomly',\n",
       " '              ordered. This is a tab separated list of ',\n",
       " '\\t         user id | item id | rating | timestamp. ',\n",
       " '              The time stamps are unix seconds since 1/1/1970 UTC   ',\n",
       " '',\n",
       " 'u.info     -- The number of users, items, and ratings in the u data set.',\n",
       " '',\n",
       " 'u.item     -- Information about the items (movies); this is a tab separated',\n",
       " '              list of',\n",
       " '              movie id | movie title | release date | video release date |',\n",
       " '              IMDb URL | unknown | Action | Adventure | Animation |',\n",
       " \"              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\",\n",
       " '              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |',\n",
       " '              Thriller | War | Western |',\n",
       " '              The last 19 fields are the genres, a 1 indicates the movie',\n",
       " '              is of that genre, a 0 indicates it is not; movies can be in',\n",
       " '              several genres at once.',\n",
       " '              The movie ids are the ones used in the u.data data set.',\n",
       " '',\n",
       " 'u.genre    -- A list of the genres.',\n",
       " '',\n",
       " 'u.user     -- Demographic information about the users; this is a tab',\n",
       " '              separated list of',\n",
       " '              user id | age | gender | occupation | zip code',\n",
       " '              The user ids are the ones used in the u.data data set.',\n",
       " '',\n",
       " 'u.occupation -- A list of the occupations.',\n",
       " '',\n",
       " 'u1.base    -- The data sets u1.base and u1.test through u5.base and u5.test',\n",
       " 'u1.test       are 80%/20% splits of the u data into training and test data.',\n",
       " 'u2.base       Each of u1, ..., u5 have disjoint test sets; this if for',\n",
       " 'u2.test       5 fold cross validation (where you repeat your experiment',\n",
       " 'u3.base       with each training and test set and average the results).',\n",
       " 'u3.test       These data sets can be generated from u.data by mku.sh.',\n",
       " 'u4.base',\n",
       " 'u4.test',\n",
       " 'u5.base',\n",
       " 'u5.test',\n",
       " '',\n",
       " 'ua.base    -- The data sets ua.base, ua.test, ub.base, and ub.test',\n",
       " 'ua.test       split the u data into a training set and a test set with',\n",
       " 'ub.base       exactly 10 ratings per user in the test set.  The sets',\n",
       " 'ub.test       ua.test and ub.test are disjoint.  These data sets can',\n",
       " '              be generated from u.data by mku.sh.',\n",
       " '',\n",
       " 'allbut.pl  -- The script that generates training and test sets where',\n",
       " '              all but n of a users ratings are in the training data.',\n",
       " '',\n",
       " 'mku.sh     -- A shell script to generate all the u data sets from u.data.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme.take(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'u.data     -- The full u data set, 100000 ratings by 943 users on 1682 items.',\n",
    " '              Each user has rated at least 20 movies.  Users and items are',\n",
    " '              numbered consecutively from 1.  The data is randomly',\n",
    " '              ordered. This is a tab separated list of ',\n",
    " '\\t         user id | item id | rating | timestamp. ',\n",
    " '              The time stamps are unix seconds since 1/1/1970 UTC   ',\n",
    " \n",
    " 'u.item     -- Information about the items (movies); this is a tab separated',\n",
    " '              list of',\n",
    " '              movie id | movie title | release date | video release date |',\n",
    " '              IMDb URL | unknown | Action | Adventure | Animation |',\n",
    " \"              Children's | Comedy | Crime | Documentary | Drama | Fantasy |\",\n",
    " '              Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi |',\n",
    " '              Thriller | War | Western |',\n",
    " '              The last 19 fields are the genres, a 1 indicates the movie',\n",
    " '              is of that genre, a 0 indicates it is not; movies can be in',\n",
    " '              several genres at once.',\n",
    " '              The movie ids are the ones used in the u.data data set.',\n",
    " '',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['196\\t242\\t3\\t881250949',\n",
       " '186\\t302\\t3\\t891717742',\n",
       " '22\\t377\\t1\\t878887116',\n",
       " '244\\t51\\t2\\t880606923',\n",
       " '166\\t346\\t1\\t886397596',\n",
       " '298\\t474\\t4\\t884182806',\n",
       " '115\\t265\\t2\\t881171488',\n",
       " '253\\t465\\t5\\t891628467',\n",
       " '305\\t451\\t3\\t886324817',\n",
       " '6\\t86\\t3\\t883603013']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(line):\n",
    "    split = line.split('\\t')\n",
    "    return split[1], split[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = data.map(split_data).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('242', '3'),\n",
       " ('302', '3'),\n",
       " ('377', '1'),\n",
       " ('51', '2'),\n",
       " ('346', '1'),\n",
       " ('474', '4'),\n",
       " ('265', '2'),\n",
       " ('465', '5'),\n",
       " ('451', '3'),\n",
       " ('86', '3')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_film_splitted_data = splitted_data.filter(lambda x: x[0]=='302').map(lambda x: (x[1], 1))\\\n",
    "                                       .sortByKey(True)\\\n",
    "                                       .countByKey().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 10, 46, 119, 120]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for k, v in my_film_splitted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_films_splitted_data = splitted_data.map(lambda x: (x[1], 1))\\\n",
    "                                       .sortByKey(True)\\\n",
    "                                       .countByKey().items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6110, 11370, 27145, 34174, 21201]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for k, v in all_films_splitted_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_json = {\n",
    "                \"hist_film\": [v for k, v in my_film_splitted_data],\n",
    "                \"hist_all\": [v for k, v in all_films_splitted_data]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('lab01.json', 'w') as f:\n",
    "    json.dump(result_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
