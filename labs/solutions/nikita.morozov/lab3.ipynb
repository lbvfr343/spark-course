{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 2 --driver-memory 2g pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"Morozov_Nikita\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2022-01-06 18:46 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2022-01-06 18:46 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2022-01-06 18:46 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2022-01-06 18:46 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, DateType\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, CountVectorizerModel, CountVectorizer, HashingTF, VectorAssembler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание схемы для каждого датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_train_and_test = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"purchase\", FloatType())\n",
    "])\n",
    "\n",
    "schema_views_programmes = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"ts_start\", IntegerType()),\n",
    "    StructField(\"ts_end\", IntegerType()),\n",
    "    StructField(\"item_type\", StringType())\n",
    "])\n",
    "\n",
    "schema_items = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"channel_id\", IntegerType()),\n",
    "    StructField(\"datetime_availability_start\", StringType()),\n",
    "    StructField(\"datetime_availability_stop\", StringType()),\n",
    "    StructField(\"datetime_show_start\", StringType()),\n",
    "    StructField(\"datetime_show_stop\", StringType()),\n",
    "    StructField(\"content_type\", IntegerType()),\n",
    "    StructField(\"title\", StringType()),\n",
    "    StructField(\"year\", FloatType()),\n",
    "    StructField(\"genres\", StringType()),\n",
    "   StructField(\"region_id\", FloatType())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  spark.read.options(header = True).csv(\"/labs/slaba03/laba03_train.csv\", schema_train_and_test)\n",
    "test =  spark.read.options(header = True).csv(\"/labs/slaba03/laba03_test.csv\", schema_train_and_test)\n",
    "items =  spark.read.options(delimiter = '\\t', header = True).csv(\"/labs/slaba03/laba03_items.csv\")\n",
    "views_programmes = spark.read.options(header = True).csv(\"/labs/slaba03/laba03_views_programmes.csv\", schema_views_programmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn(\"content_type\", \n",
    "                                  items[\"content_type\"]\n",
    "                                  .cast('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 FILLNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.fillna(0, subset=['channel_id'])\n",
    "items = items.fillna(\"None\", subset=['genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Объединим train и test для удобства создания признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = train.union(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Найдем пустые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_feach = items.select([c for c in items.columns if c in ['item_id','channel_id', 'datetime_show_start', 'datetime_show_stop',\n",
    "                                                             'content_type', 'title', 'year', 'genres', 'region_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+------------------+------------+-----+------+------+---------+\n",
      "|item_id|channel_id|datetime_show_start|datetime_show_stop|content_type|title|  year|genres|region_id|\n",
      "+-------+----------+-------------------+------------------+------------+-----+------+------+---------+\n",
      "|      0|      3704|               3704|              3704|           0|    0|631868|     0|   362264|\n",
      "+-------+----------+-------------------+------------------+------------+-----+------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_feach.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in items_feach.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+------+---------+\n",
      "|user_id|item_id|ts_start|ts_end|item_type|\n",
      "+-------+-------+--------+------+---------+\n",
      "|      0|      0|       0|     0|        0|\n",
      "+-------+-------+--------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "views_programmes.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in views_programmes.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engeneering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Агрегации по пользователю и фильмам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_purchase_user = full_data.groupBy(\"user_id\").sum().\\\n",
    "                             select('user_id', col('sum(purchase)').alias('sum_purchase_user'))\n",
    "\n",
    "#Среднее количество фильмов у пользователя\n",
    "mean_purchase_user = full_data.groupBy(\"user_id\").mean().\\\n",
    "                             select('user_id', col('avg(purchase)').alias('mean_purchased_user'))\n",
    "\n",
    "# Количество пользователей, купившых данный фильм\n",
    "sum_purchase_item = full_data.\\\n",
    "                             groupBy(\"item_id\").sum().\\\n",
    "                             select('item_id', col('sum(purchase)').alias('sum_purchase_item'))\n",
    "\n",
    "#Среднее количество купленных фильмов\n",
    "mean_purchased_item = full_data.groupBy(\"item_id\").mean().\\\n",
    "                             select('item_id', col('avg(purchase)').alias('mean_purchased_item'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_purchase_user.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Фичи, связанные со временем начала и окончания программы(не взлетело)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items_duration = items_feach.withColumn('start_timestamp',to_timestamp(col('datetime_show_start')))\\\n",
    "#   .withColumn('end_timestamp',\n",
    "#               to_timestamp(col(\"datetime_show_stop\")))\\\n",
    "#   .withColumn('diff_in_seconds',          #Длительность программы\n",
    "#               col(\"end_timestamp\").cast(\"long\") - col('start_timestamp').cast(\"long\"))\\\n",
    "#   .withColumn('hour_begin',               #Час\n",
    "#               f.hour('start_timestamp'))\\\n",
    "#   .withColumn('day_of_week',              #День недели\n",
    "#               ((f.dayofweek('start_timestamp')+5)%7)+1)\\\n",
    "#   .withColumn('day_of_month',             #День месяца\n",
    "#               f.dayofmonth('start_timestamp'))\\\n",
    "#   .withColumn('day_of_year',              #День года\n",
    "#               f.dayofyear('start_timestamp'))\\\n",
    "#   .withColumn('week_of_year',              #Неделя года\n",
    "#               f.weekofyear('start_timestamp'))\\\n",
    "#   .withColumn('month',                     #Месяц\n",
    "#               f.month('start_timestamp'))\\\n",
    "#   .withColumn(\"is_weekend\",\n",
    "#               col(\"day_of_week\").isin([6,7]).cast(\"int\")).select(col(\"item_id\")\n",
    "#                                                 ,col(\"diff_in_seconds\")\n",
    "#                                                 ,col(\"hour_begin\")\n",
    "#                                                 ,col(\"day_of_week\")\n",
    "#                                                 ,col(\"day_of_month\")\n",
    "#                                                 ,col(\"day_of_year\")\n",
    "#                                                 ,col(\"week_of_year\")\n",
    "#                                                 ,col(\"month\")\n",
    "#                                                 ,col(\"is_weekend\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Жанры через TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_genres = items_feach.select(col(\"item_id\"), col(\"genres\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_the_comma(data, column):\n",
    "    data=data.withColumn(column, lower(col('genres')))\n",
    "    data = data.withColumn(column, F.regexp_replace('desc', ',', ' '))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_genres = removing_the_comma(items_genres, 'desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    }
   ],
   "source": [
    "list_text = items_genres.select('desc').collect()\n",
    "set_lang = set()\n",
    "for i in list_text:\n",
    "    for j in i[0].split():\n",
    "        set_lang.add(j)\n",
    "print(len(set_lang))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_ru = StopWordsRemover.loadDefaultStopWords(\"russian\")\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"words\")\n",
    "\n",
    "swr_en = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"words_filtered_en\", stopWords=stop_words_ru)\n",
    "\n",
    "hasher = HashingTF(numFeatures=94, binary=False, inputCol=swr_en.getOutputCol(), outputCol=\"word_vector\")\n",
    "\n",
    "idf = IDF(inputCol=\"word_vector\", outputCol=\"tf_idf_genre\")\n",
    "\n",
    "pipeline_genre = Pipeline(stages=[\n",
    "    tokenizer,\n",
    "    swr_en,\n",
    "    hasher,\n",
    "    idf\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline_genre.fit(items_genres)\n",
    "tf_idf_genre = pipeline_model.transform(items_genres)\n",
    "tf_idf_genre = tf_idf_genre.select(col(\"item_id\"), col(\"tf_idf_genre\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_genres = items_genres.withColumn('wordCount', f.size(f.split(f.col('desc'), ' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Купленные жанры пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f.pandas_udf(StringType(), f.PandasUDFType.GROUPED_AGG)\n",
    "def collect_list(name):    \n",
    "    s = ','.join(name)\n",
    "    lst = s.split(\",\")\n",
    "    lst = set(lst)\n",
    "    return ' '.join(lst)\n",
    "\n",
    "user_purchased_genres = train\\\n",
    "     .filter(col('purchase') == 1)\\\n",
    "     .join(items, on='item_id', how='inner')\\\n",
    "     .select(['user_id', 'item_id', 'genres'])\\\n",
    "     .groupBy('user_id')\\\n",
    "     .agg(collect_list(col('genres')).alias('purchased_genres'))\\\n",
    "     .fillna('', subset=['purchased_genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchased_genres = user_purchased_genres.withColumn('purchased_genres_count',\n",
    "                                                         f.size(f.split(f.col('purchased_genres'), ' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Объединим все признаки, связанные с items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_items = items_genres.join(tf_idf_genre,\n",
    "                items_genres.item_id == tf_idf_genre.item_id,\n",
    "                'inner').drop(items_genres.item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Создание признаков о просмотре "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_programmes = views_programmes.withColumn('diff_time', col(\"ts_end\") - col(\"ts_start\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Статистики по Users\n",
    "\n",
    "count_live_program = views_programmes.filter(col(\"item_type\") == \"live\")\\\n",
    "                                     .select(col('user_id'), col(\"item_type\"))\\\n",
    "                                     .groupBy(\"user_id\").count().select(\"user_id\", col(\"count\").alias(\"count_live_program\"))\n",
    "\n",
    "count_prv_program = views_programmes.filter(col(\"item_type\") == \"pvr\")\\\n",
    "                                     .select(col('user_id'), col(\"item_type\"))\\\n",
    "                                     .groupBy(\"user_id\").count().select(\"user_id\", col(\"count\").alias(\"count_prv_program\"))\n",
    "\n",
    "sum_total_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .groupBy(\"user_id\").sum(\"diff_time\").select(\"user_id\", col(\"sum(diff_time)\").alias(\"sum_total_viewed_user\"))\n",
    "\n",
    "mean_total_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .groupBy(\"user_id\").mean(\"diff_time\").select(\"user_id\", col(\"avg(diff_time)\").alias(\"mean_total_viewed_user\"))\n",
    "\n",
    "sum_live_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"live\")\\\n",
    "                .groupBy(\"user_id\").sum(\"diff_time\").select(\"user_id\", col(\"sum(diff_time)\").alias(\"sum_live_viewed_user\"))\n",
    "\n",
    "sum_pvr_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"pvr\")\\\n",
    "                .groupBy(\"user_id\").sum(\"diff_time\").select(\"user_id\", col(\"sum(diff_time)\").alias(\"sum_pvr_viewed_user\"))\n",
    "\n",
    "mean_live_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"live\")\\\n",
    "                .groupBy(\"user_id\").mean(\"diff_time\").select(\"user_id\", col(\"avg(diff_time)\").alias(\"mean_live_viewed_user\"))\n",
    "\n",
    "mean_pvr_viewed_user = views_programmes.select(col(\"user_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"pvr\")\\\n",
    "                .groupBy(\"user_id\").mean(\"diff_time\").select(\"user_id\", col(\"avg(diff_time)\").alias(\"mean_pvr_viewed_user\"))\n",
    "\n",
    "### Статистики по Items\n",
    "sum_total_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .groupBy(\"item_id\").sum(\"diff_time\").select(\"item_id\", col(\"sum(diff_time)\").alias(\"sum_total_viewed_item\"))\n",
    "\n",
    "mean_total_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .groupBy(\"item_id\").mean(\"diff_time\").select(\"item_id\", col(\"avg(diff_time)\").alias(\"mean_total_viewed_item\"))\n",
    "\n",
    "sum_live_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"live\")\\\n",
    "                .groupBy(\"item_id\").sum(\"diff_time\").select(\"item_id\", col(\"sum(diff_time)\").alias(\"sum_live_viewed_item\"))\n",
    "\n",
    "sum_pvr_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"pvr\")\\\n",
    "                .groupBy(\"item_id\").sum(\"diff_time\").select(\"item_id\", col(\"sum(diff_time)\").alias(\"sum_pvr_viewed_item\"))\n",
    "\n",
    "mean_live_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"live\")\\\n",
    "                .groupBy(\"item_id\").mean(\"diff_time\").select(\"item_id\", col(\"avg(diff_time)\").alias(\"mean_live_viewed_item\"))\n",
    "\n",
    "mean_pvr_viewed_item = views_programmes.select(col(\"item_id\"), col(\"diff_time\"), col(\"item_type\"))\\\n",
    "                .filter(col(\"item_type\") == \"pvr\")\\\n",
    "                .groupBy(\"item_id\").mean(\"diff_time\").select(\"item_id\", col(\"avg(diff_time)\").alias(\"mean_pvr_viewed_item\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Объединим все признаки в full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = full_data.join(sum_purchase_user,\n",
    "               full_data.user_id == sum_purchase_user.user_id,\n",
    "               'left').\\\n",
    "            select(full_data.user_id, full_data.item_id, sum_purchase_user.sum_purchase_user)\n",
    "\n",
    "feature_data = feature_data.join(feature_items,\n",
    "               feature_data.item_id == feature_items.item_id,\n",
    "               'left').drop(feature_items.item_id)\n",
    "\n",
    "feature_data = feature_data.join(mean_purchase_user,\n",
    "               feature_data.user_id == mean_purchase_user.user_id,\n",
    "                'left').drop(feature_data.user_id)\n",
    "\n",
    "feature_data = feature_data.join(sum_purchase_item,\n",
    "               feature_data.item_id == sum_purchase_item.item_id,\n",
    "               'left').drop(feature_data.item_id)\n",
    "\n",
    "feature_data = feature_data.join(mean_purchased_item,\n",
    "               feature_data.item_id == mean_purchased_item.item_id,\n",
    "               'left').drop(feature_data.item_id)\n",
    "\n",
    "feature_data = feature_data.join(count_live_program,\n",
    "               feature_data.user_id == count_live_program.user_id,\n",
    "               'left').drop(count_live_program.user_id)\n",
    "\n",
    "feature_data = feature_data.join(count_prv_program,\n",
    "               feature_data.user_id == count_prv_program.user_id,\n",
    "               'left').drop(count_prv_program.user_id)\n",
    "\n",
    "feature_data = feature_data.join(sum_total_viewed_user,\n",
    "               feature_data.user_id == sum_total_viewed_user.user_id,\n",
    "               'left').drop(sum_total_viewed_user.user_id)\n",
    "\n",
    "feature_data = feature_data.join(mean_total_viewed_user,\n",
    "               feature_data.user_id == mean_total_viewed_user.user_id,\n",
    "               'left').drop(mean_total_viewed_user.user_id)\n",
    "\n",
    "feature_data = feature_data.join(sum_live_viewed_user,\n",
    "               feature_data.user_id == sum_live_viewed_user.user_id,\n",
    "               'left').drop(sum_live_viewed_user.user_id)\n",
    "\n",
    "feature_data = feature_data.join(sum_pvr_viewed_user,\n",
    "               feature_data.user_id == sum_pvr_viewed_user.user_id,\n",
    "               'left').drop(sum_pvr_viewed_user.user_id)\n",
    "\n",
    "feature_data = feature_data.join(mean_live_viewed_user,\n",
    "               feature_data.user_id == mean_live_viewed_user.user_id,\n",
    "               'left').drop(mean_live_viewed_user.user_id)\n",
    "\n",
    "feature_data = feature_data.join(mean_pvr_viewed_user,\n",
    "               feature_data.user_id == mean_pvr_viewed_user.user_id,\n",
    "               'left').drop(mean_pvr_viewed_user.user_id)\n",
    "\n",
    "\n",
    "feature_data = feature_data.join(items.select(col(\"item_id\"), col(\"content_type\")),\n",
    "               feature_data.item_id == items.item_id,\n",
    "               'left').drop(items.item_id)\n",
    "\n",
    "feature_data = feature_data.join(user_purchased_genres,\n",
    "               feature_data.user_id == user_purchased_genres.user_id,\n",
    "               'left').drop(user_purchased_genres.user_id)\n",
    "\n",
    "feature_data = feature_data.join(items.select(col(\"item_id\"), col(\"year\")),\n",
    "               feature_data.item_id == items.item_id,\n",
    "               'left').drop(items.item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = feature_data.fillna(0, subset=[\"wordCount\", \"sum_purchase_user\", \"mean_purchased_user\",\n",
    "                                               \"sum_purchase_item\", \"mean_purchased_item\", \"count_live_program\",\n",
    "                                              \"count_prv_program\", \"sum_total_viewed_user\", \"mean_total_viewed_user\",\n",
    "                                              \"sum_live_viewed_user\", \"sum_pvr_viewed_user\", \"mean_live_viewed_user\",\n",
    "                                              \"mean_pvr_viewed_user\", \"content_type\", \"purchased_genres_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[sum_purchase_user: double, genres: string, desc: string, wordCount: int, tf_idf_genre: vector, user_id: int, mean_purchased_user: double, sum_purchase_item: double, item_id: int, mean_purchased_item: double, count_live_program: bigint, count_prv_program: bigint, sum_total_viewed_user: bigint, mean_total_viewed_user: double, sum_live_viewed_user: bigint, sum_pvr_viewed_user: bigint, mean_live_viewed_user: double, mean_pvr_viewed_user: double, content_type: int, purchased_genres: string, purchased_genres_count: int, year: string]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7189464"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Удаление пустых значенний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+----+---------+-------+-------------------+-----------------+-------+-------------------+------------------+-----------------+---------------------+----------------------+--------------------+-------------------+---------------------+--------------------+------------+----------------+----------------------+----+\n",
      "|sum_purchase_user|genres|desc|wordCount|user_id|mean_purchased_user|sum_purchase_item|item_id|mean_purchased_item|count_live_program|count_prv_program|sum_total_viewed_user|mean_total_viewed_user|sum_live_viewed_user|sum_pvr_viewed_user|mean_live_viewed_user|mean_pvr_viewed_user|content_type|purchased_genres|purchased_genres_count|year|\n",
      "+-----------------+------+----+---------+-------+-------------------+-----------------+-------+-------------------+------------------+-----------------+---------------------+----------------------+--------------------+-------------------+---------------------+--------------------+------------+----------------+----------------------+----+\n",
      "|                0|     0|   0|        0|      0|                  0|                0|      0|                  0|                 0|                0|                    0|                     0|                   0|                  0|                    0|                   0|           0|          985264|                     0|7764|\n",
      "+-----------------+------+----+---------+-------+-------------------+-----------------+-------+-------------------+------------------+-----------------+---------------------+----------------------+--------------------+-------------------+---------------------+--------------------+------------+----------------+----------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = feature_data.drop(feature_data.tf_idf_genre)\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Разделим на train и test, как было изначально"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_data = train.join(feature_data, on=['user_id', 'item_id'], how='left')\n",
    "test_feature_data = test.join(feature_data, on=['user_id', 'item_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Явно укажем, какие столбцы являются признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ass = VectorAssembler(inputCols=['sum_purchase_user', \"mean_purchased_user\",\n",
    "                                 \"sum_purchase_item\", \"mean_purchased_item\", \n",
    "                                 \"wordCount\", \"tf_idf_genre\",\n",
    "                                 \"count_live_program\", \"count_prv_program\",\n",
    "                                 \"sum_live_viewed_user\", \"mean_live_viewed_user\",\n",
    "                                 \"sum_pvr_viewed_user\", \"mean_pvr_viewed_user\",\n",
    "                                 \"content_type\", \"purchased_genres_count\"],\n",
    "                      outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_feature_train = ass.transform(train_feature_data)\n",
    "vector_feature_test = ass.transform(test_feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bdt = GBTClassifier(featuresCol='features', labelCol='purchase', maxDepth = 3, maxIter = 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"probability\",\n",
    "                                          labelCol=\"purchase\",\n",
    "                                          metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramGrid = ParamGridBuilder().addGrid(model_bdt.maxDepth, [3])\\\n",
    "#                                .build()\n",
    "\n",
    "# crossval = CrossValidator(estimator=model_lg,\n",
    "#                            evaluator=evaluator,\n",
    "#                            numFolds=3,\n",
    "#                            parallelism=3,\n",
    "#                            estimatorParamMaps=paramGrid\n",
    "#                           )\n",
    "\n",
    "# cv = crossval.fit(vector_feature_train)\n",
    "\n",
    "# cv.avgMetrics\n",
    "\n",
    "# cv.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = model_bdt.fit(vector_feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbt.transform(vector_feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183934307325691"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = gbt.transform(vector_feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 s, sys: 1.21 s, total: 41.3 s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ress = predictions_test.select('user_id', 'item_id', col('probability').alias('purchase')).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress_pd = ress.sort_values(['user_id', 'item_id']).reset_index(drop=True)\n",
    "ress_pd['purchase'] = ress_pd['purchase'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress_pd.to_csv('~/lab03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
