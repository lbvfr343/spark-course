{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", True) # for cartesian product usage\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cat: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "df = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "|                 cat|                desc|   id|lang|                name|provider|\n",
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "|                    | La transformació...|11556|  es|Aprendizaje Colab...|   Udemy|\n",
      "|6/economics_finan...|Математическая эк...|13702|  ru|Математическая эк...|  Intuit|\n",
      "|                    | Hazte más emplea...|16627|  es|Aprende Excel: Ni...|   Udemy|\n",
      "|5/computer_scienc...|В курсе рассматри...|16704|  ru|Программирование ...|  Intuit|\n",
      "|  5/computer_science|An introduction t...|21617|  en|Preparing for the...|     edX|\n",
      "|                    | Improve your SAS...|23126|  en|Compass - powerfu...|   Udemy|\n",
      "+--------------------+--------------------+-----+----+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# id курсов в моём варианте задачи\n",
    "ids = [23126, 21617, 16627, 11556, 16704, 13702]\n",
    "df2 = df.filter(df.id.isin(ids))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# мой вариант задачи\n",
    "# насколько я понимаю, это поля id, lang и desc соответственно\n",
    "courses_to_make_recommendations = \\\n",
    "[[23126, u'en', u'Compass - powerful SASS library that makes your life easier'], \\\n",
    " [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2'], \\\n",
    " [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche'], \\\n",
    " [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo'], \\\n",
    " [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus'], \\\n",
    " [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# токенизация\n",
    "def tokenization(string):\n",
    "    regex = re.compile(u'[\\w\\d]{2,}', re.U)\n",
    "    return regex.findall(string.lower())\n",
    "tokenization = F.udf(tokenization, ArrayType(StringType()))\n",
    "\n",
    "tokenized_df = df.withColumn('tokens', tokenization(df.desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency\n",
    "hashingTF = HashingTF(inputCol = 'tokens', outputCol = 'features').setNumFeatures(10000)\n",
    "featurized_df = hashingTF.transform(tokenized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse document frequency\n",
    "idf = IDF(inputCol = 'features', outputCol = 'i_features')\n",
    "idfModel = idf.fit(featurized_df)\n",
    "rescaled_df = idfModel.transform(featurized_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "@F.udf(returnType=DoubleType())\n",
    "def cosine_similarity(v1, v2):\n",
    "    try:\n",
    "        p = 2\n",
    "        return float(v1.dot(v2)) / float(v1.norm(p) * v2.norm(p))\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{23126: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111], 21617: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111], 16627: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111], 11556: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111], 16704: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111], 13702: [864, 21079, 8313, 1041, 28074, 8300, 1033, 13057, 21025, 1111]}\n"
     ]
    }
   ],
   "source": [
    "lab_02_result = {}\n",
    "for course in courses_to_make_recommendations:\n",
    "    courses_sl = rescaled_df[(rescaled_df.lang == course[1]) & (rescaled_df.id != course[0])] # courses in the same language\n",
    "    course_features = rescaled_df[rescaled_df.id == course[0]][['i_features']] # matching features\n",
    "    resulting_set = courses_sl.join(course_features.withColumnRenamed('i_features', 'i_features_2')) # cartesian product\n",
    "    resulting_set = resulting_set.withColumn('cosine_smlr', cosine_similarity(resulting_set.i_features, resulting_set.i_features_2)) # computing cosine similarity\n",
    "    resulting_set = resulting_set.orderBy(resulting_set.cosine_smlr.desc(), resulting_set.name, resulting_set.id).limit(10)[['id']].toPandas() # descending order by cosine similarity\n",
    "    lab_02_result[course[0]] = list(tfidf_final['id'])\n",
    "print (lab_02_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab01.json', 'w', encoding = 'utf8') as output:\n",
    "    json.dump(lab_02_result, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
