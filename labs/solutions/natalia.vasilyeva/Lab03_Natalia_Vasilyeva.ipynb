{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf, col, isnan, isnull, broadcast, desc, lower\n",
    "import re\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import FloatType, ArrayType, StringType\n",
    "from pyspark.sql.functions import udf \n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"NV Spark Dataframe app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"NV Spark Dataframe app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number\n",
    "from pyspark.sql.functions import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2022-01-06 18:46 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2022-01-06 18:46 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2022-01-06 18:46 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2022-01-06 18:46 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"purchase\", IntegerType()),\n",
    "])\n",
    "\n",
    "\n",
    "user = spark.read\\\n",
    "          .schema(schema)\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .load(\"/labs/slaba03/laba03_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"channel_id\", IntegerType()),\n",
    "    StructField(\"datetime_availability_start\", StringType()),\n",
    "    StructField(\"datetime_availability_stop\", StringType()),\n",
    "    StructField(\"datetime_show_start\", StringType()),\n",
    "    StructField(\"datetime_show_stop\", StringType()),\n",
    "    StructField(\"content_type\", IntegerType()),\n",
    "    StructField(\"title\", StringType(), nullable = True),\n",
    "    StructField(\"year\", FloatType(), nullable = True),\n",
    "    StructField(\"genres\", StringType()),\n",
    "    StructField(\"region_id \", IntegerType())\n",
    "])\n",
    "\n",
    "\n",
    "items = spark.read\\\n",
    "          .schema(schema)\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\", True)\\\n",
    "          .option(\"sep\", \"\\t\")\\\n",
    "          .load(\"/labs/slaba03/laba03_items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"/labs/slaba03/laba03_test.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\"/labs/slaba03/laba03_train.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(items, on = 'item_id', how = 'left')\n",
    "train = train.withColumn(\"first_genre\", split(f.col(\"genres\"), \",\").getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.join(items, on = 'item_id', how = 'left')\n",
    "test = test.withColumn(\"first_genre\", split(f.col(\"genres\"), \",\").getItem(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target = train.groupby('user_id').agg(f.mean('purchase').alias('purchase')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = test.select('user_id', 'item_id').join(mean_target, on='user_id', how='left').orderBy('user_id', 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|            purchase|\n",
      "+-------+-------+--------------------+\n",
      "|   1654| 100026|0.001947040498442...|\n",
      "|   1654| 100029|0.001947040498442...|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_target.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156840"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.coalesce(1).write.mode('overwrite').csv('vn_lab3', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ALS (2).ipynb'\t\t\t Lab02_s.ipynb\r\n",
      "'Clustering (1).ipynb'\t\t Lab03_best_solution-Copy1.ipynb\r\n",
      " dataframes.ipynb\t\t Lab03_best_solution.ipynb\r\n",
      " experiments_vasilyeva.ipynb\t Lab03.ipynb\r\n",
      " Graphless\t\t\t Lab_2-Copy1.ipynb\r\n",
      "'HDFS CLI Examples.ipynb'\t mp_analysis.ipynb\r\n",
      " lab01.json\t\t\t'spark intro.ipynb'\r\n",
      " Lab01_Natalia_Vasilyeva.ipynb\t'Spark ML Pipelines.ipynb'\r\n",
      " Lab02.ipynb\t\t\t spark_scala_api.ipynb\r\n",
      " lab02.json\t\t\t'vectors (1).ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwx------   - natalia.vasilyeva natalia.vasilyeva          0 2022-10-13 21:00 .Trash\r\n",
      "drwxr-xr-x   - natalia.vasilyeva natalia.vasilyeva          0 2022-11-01 18:24 .sparkStaging\r\n",
      "drwxr-xr-x   - natalia.vasilyeva natalia.vasilyeva          0 2022-11-01 19:59 vn_lab3\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 natalia.vasilyeva natalia.vasilyeva          0 2022-11-01 19:59 vn_lab3/_SUCCESS\r\n",
      "-rw-r--r--   3 natalia.vasilyeva natalia.vasilyeva   68506595 2022-11-01 19:59 vn_lab3/part-00000-e8632981-d786-4a8c-8c17-f283a30aae82-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls vn_lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyToLocal vn_lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
