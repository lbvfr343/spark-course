{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:52.488587Z",
     "start_time": "2022-10-30T14:42:58.353558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:52.500164Z",
     "start_time": "2022-10-30T15:08:52.490540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4048\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:52.520730Z",
     "start_time": "2022-10-30T15:08:52.501611Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType \n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, FloatType\n",
    "from pyspark.sql.functions import col,array_contains\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "from pyspark.sql.functions import count\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:52.621854Z",
     "start_time": "2022-10-30T15:08:52.522310Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import allclose\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:54.777976Z",
     "start_time": "2022-10-30T15:08:52.623463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 items\r\n",
      "-rw-r--r--   3 hdfs hdfs   91066524 2022-01-06 18:46 /labs/slaba03/laba03_items.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   29965581 2022-01-06 18:46 /labs/slaba03/laba03_test.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs   74949368 2022-01-06 18:46 /labs/slaba03/laba03_train.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs  871302535 2022-01-06 18:46 /labs/slaba03/laba03_views_programmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:55.226598Z",
     "start_time": "2022-10-30T15:08:54.780591Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"user_id\", IntegerType(), True) \\\n",
    "      .add(\"item_id\", IntegerType(), True) \\\n",
    "      .add(\"purchase\", IntegerType(), True)\n",
    "      \n",
    "df_user = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(schema) \\\n",
    "      .load(\"/labs/slaba03/laba03_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:08:55.277604Z",
     "start_time": "2022-10-30T15:08:55.228814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, item_id: int, purchase: int]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"purchase\", IntegerType())\n",
    "])\n",
    "\n",
    "train = spark.read.csv('/labs/slaba03/laba03_train.csv', sep=',', header=True, schema=schema)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.474340Z",
     "start_time": "2022-10-30T15:08:55.279682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- channel_id: double (nullable = true)\n",
      " |-- datetime_availability_start: timestamp (nullable = true)\n",
      " |-- datetime_availability_stop: timestamp (nullable = true)\n",
      " |-- datetime_show_start: timestamp (nullable = true)\n",
      " |-- datetime_show_stop: timestamp (nullable = true)\n",
      " |-- content_type: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- region_id: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', sep='\\t', header=True, inferSchema=True)\n",
    "items.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.536318Z",
     "start_time": "2022-10-30T15:13:26.476320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[item_id: int, title: string, year: double, genres: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items[['item_id', 'title', 'year', 'genres']].na.fill({'year': -9999, 'genres': 'General'})\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.563118Z",
     "start_time": "2022-10-30T15:13:26.538193Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, item_id: int, ts_start: int, ts_end: int, item_type: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"ts_start\", IntegerType()),\n",
    "    StructField(\"ts_end\", IntegerType()),\n",
    "    StructField(\"item_type\", StringType())\n",
    "])\n",
    "\n",
    "programs = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', header=True, schema=schema)\n",
    "programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.586376Z",
     "start_time": "2022-10-30T15:13:26.564774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, item_id: int, purchase: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"purchase\", IntegerType())\n",
    "])\n",
    "\n",
    "test = spark.read.csv('/labs/slaba03/laba03_test.csv', sep=',', header=True, schema=schema)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feats from train: UserPurchase, ItemPurchase, RateFilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.594949Z",
     "start_time": "2022-10-30T15:13:26.588147Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, HashingTF\n",
    "from pyspark.ml import Transformer, Estimator, Pipeline\n",
    "import pyspark\n",
    "\n",
    "##-- сколько покупок совершил пользователь\n",
    "class UserPurchase(Estimator):\n",
    "    def __init__(self):\n",
    "        Transformer.__init__(self)\n",
    "        self.userPurchase = None\n",
    "        \n",
    "    def fit(self, df: pyspark.sql.dataframe.DataFrame):\n",
    "        self.userPurchase = df.groupBy(\"user_id\").agg(f.sum('purchase').alias('SumUserPurchases'))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        return df.join(self.userPurchase, on='user_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.601203Z",
     "start_time": "2022-10-30T15:13:26.596655Z"
    }
   },
   "outputs": [],
   "source": [
    "##-- сколько раз купили фильм\n",
    "class ItemPurchase(Estimator):\n",
    "    def __init__(self):\n",
    "        Transformer.__init__(self)\n",
    "        self.itemPurchase = None\n",
    "        \n",
    "    def fit(self, df: pyspark.sql.dataframe.DataFrame):\n",
    "        self.itemPurchase = df.groupBy(\"item_id\").agg(f.sum('purchase').alias('SumFilmPurchases'))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        return df.join(self.itemPurchase, on='item_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.607259Z",
     "start_time": "2022-10-30T15:13:26.602701Z"
    }
   },
   "outputs": [],
   "source": [
    "##-- доля покупок фильма на пользователя\n",
    "class RateFilmBuys(Transformer):\n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame):\n",
    "        return df.withColumn(\"rateFilmBuys\", df.SumUserPurchases / df.SumFilmPurchases).na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.718952Z",
     "start_time": "2022-10-30T15:13:26.608753Z"
    }
   },
   "outputs": [],
   "source": [
    "pipelineTrain = Pipeline(stages=[\n",
    "    UserPurchase(),\n",
    "    ItemPurchase()\n",
    "])\n",
    "\n",
    "trainFeats = pipelineTrain.fit(train)\n",
    "train = trainFeats.transform(train)\n",
    "test = trainFeats.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:13:26.725404Z",
     "start_time": "2022-10-30T15:13:26.720822Z"
    }
   },
   "outputs": [],
   "source": [
    "class JoinItems(Transformer):\n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        return df.join(items, on='item_id', how='inner')\n",
    "    \n",
    "class AddGenresSplit(Transformer):\n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        df = df.withColumn(\"genresSplit\", f.split(f.col('genres'), ','))\n",
    "        cv = CountVectorizer(inputCol='genresSplit', outputCol='genresCV')\n",
    "        model = cv.fit(df)\n",
    "        return model.transform(df)\n",
    "    \n",
    "class AddTitle(Transformer):\n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        tk = Tokenizer(inputCol='title', outputCol='TkTitle')\n",
    "        df = tk.transform(df)\n",
    "        cv = CountVectorizer(inputCol='TkTitle', outputCol='TitleCV')\n",
    "        model = cv.fit(df)\n",
    "        return model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:20.794718Z",
     "start_time": "2022-10-30T15:13:26.726816Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_items = Pipeline(stages=[\n",
    "    RateFilmBuys(),\n",
    "    JoinItems(),\n",
    "    AddGenresSplit(),\n",
    "    AddTitle()\n",
    "])\n",
    "\n",
    "itemsFeats = pipeline_items.fit(train)\n",
    "train = itemsFeats.transform(train)\n",
    "test = itemsFeats.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:20.800012Z",
     "start_time": "2022-10-30T15:17:20.796812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      " |-- SumUserPurchases: long (nullable = true)\n",
      " |-- SumFilmPurchases: long (nullable = true)\n",
      " |-- rateFilmBuys: double (nullable = false)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: double (nullable = false)\n",
      " |-- genres: string (nullable = false)\n",
      " |-- genresSplit: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- genresCV: vector (nullable = true)\n",
      " |-- TkTitle: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- TitleCV: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:20.807072Z",
     "start_time": "2022-10-30T15:17:20.801470Z"
    }
   },
   "outputs": [],
   "source": [
    "class JoinPrograms(Estimator):\n",
    "    def __init__(self):\n",
    "        Transformer.__init__(self)\n",
    "        self.userWatch = None\n",
    "        \n",
    "    def fit(self, df: pyspark.sql.dataframe.DataFrame):\n",
    "        df = df.withColumn('timeWatch', df.ts_end - df.ts_start)\n",
    "        self.userWatch = df.groupBy('user_id')\\\n",
    "                                .pivot('item_type')\\\n",
    "                                .agg(f.sum('timeWatch').alias('timeWatchSumByUser'),\n",
    "                                     f.mean('timeWatch').alias('timeWatchAvgByUser')).na.fill(0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df: pyspark.sql.dataframe.DataFrame) -> pyspark.sql.dataframe.DataFrame:\n",
    "        df = df.join(self.userWatch, on='user_id', how='left').na.fill(0)\n",
    "        df = df.withColumn('UserSumWatch', df.live_timeWatchSumByUser + df.pvr_timeWatchSumByUser)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:31.408981Z",
     "start_time": "2022-10-30T15:17:20.808791Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_programs = Pipeline(stages=[JoinPrograms()])\n",
    "timeWatch = pipeline_programs.fit(programs)\n",
    "train = timeWatch.transform(train).cache()\n",
    "test = timeWatch.transform(test).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T15:17:31.415207Z",
     "start_time": "2022-10-30T15:17:31.410724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SumFilmPurchases',\n",
       " 'pvr_timeWatchAvgByUser',\n",
       " 'UserSumWatch',\n",
       " 'genresCV',\n",
       " 'user_id',\n",
       " 'pvr_timeWatchSumByUser',\n",
       " 'TitleCV',\n",
       " 'live_timeWatchAvgByUser',\n",
       " 'rateFilmBuys',\n",
       " 'live_timeWatchSumByUser',\n",
       " 'item_id',\n",
       " 'SumUserPurchases',\n",
       " 'year']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropFeats = ['purchase', \n",
    "              'genres', \n",
    "              'genresSplit', \n",
    "              'title', \n",
    "              'TkTitle']\n",
    "trainColumns = list(set(train.columns) - set(dropFeats))\n",
    "trainColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:40:26.449344Z",
     "start_time": "2022-10-30T15:17:31.416564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-30 18:17:31.420322\n",
      "Start fitting...\n",
      "CPU times: user 1.29 s, sys: 365 ms, total: 1.65 s\n",
      "Wall time: 2h 22min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "inputCols = trainColumns\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol='features')\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='purchase', maxDepth=3, maxIter=20, seed=42)\n",
    " \n",
    "pipeline_model = Pipeline(stages=[\n",
    "    assembler,\n",
    "    gbt\n",
    "])\n",
    "\n",
    "print(\"Start fitting...\")\n",
    "model = pipeline_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:40:26.549516Z",
     "start_time": "2022-10-30T17:40:26.451776Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:40:26.620169Z",
     "start_time": "2022-10-30T17:40:26.551885Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = predictions.select(['user_id','item_id','probability'])\\\n",
    "                        .orderBy(['user_id','item_id']).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:40:26.677690Z",
     "start_time": "2022-10-30T17:40:26.622383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: int, item_id: int, purchase: float]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "firstelement=udf(lambda v:float(v[1]),FloatType())\n",
    "pred = pred.select(pred.user_id, pred.item_id, firstelement('probability').alias(\"purchase\")).cache()\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:43:40.573079Z",
     "start_time": "2022-10-30T17:40:26.679615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.6 s, sys: 962 ms, total: 19.6 s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "answer = pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:43:40.589169Z",
     "start_time": "2022-10-30T17:43:40.575210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1654</td>\n",
       "      <td>336</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1654</td>\n",
       "      <td>678</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1654</td>\n",
       "      <td>691</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1654</td>\n",
       "      <td>696</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1654</td>\n",
       "      <td>763</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  purchase\n",
       "0     1654      336  0.043932\n",
       "1     1654      678  0.043932\n",
       "2     1654      691  0.043932\n",
       "3     1654      696  0.043932\n",
       "4     1654      763  0.043932"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T17:43:40.624378Z",
     "start_time": "2022-10-30T17:43:40.590900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043811    1384450\n",
       "0.044534      97606\n",
       "0.044333      74167\n",
       "0.043932      73074\n",
       "0.044036      49667\n",
       "0.044063      48793\n",
       "0.047735      25868\n",
       "0.045057      24137\n",
       "0.045650      22992\n",
       "0.045318      21408\n",
       "0.044922      20861\n",
       "0.044701      20567\n",
       "0.045882      16436\n",
       "0.045237      15023\n",
       "0.046660      13715\n",
       "0.047386      11997\n",
       "0.045567      11543\n",
       "0.044926      10684\n",
       "0.044843      10178\n",
       "0.047251       9752\n",
       "0.049255       9743\n",
       "0.050780       7936\n",
       "0.045833       7791\n",
       "0.045317       7597\n",
       "0.046171       7046\n",
       "0.045197       5737\n",
       "0.046922       4851\n",
       "0.046497       4759\n",
       "0.045222       4051\n",
       "0.044762       3548\n",
       "             ...   \n",
       "0.071845          4\n",
       "0.105894          4\n",
       "0.102315          4\n",
       "0.162129          4\n",
       "0.219778          4\n",
       "0.154455          3\n",
       "0.134805          3\n",
       "0.099057          3\n",
       "0.220537          3\n",
       "0.311462          3\n",
       "0.124793          3\n",
       "0.091620          3\n",
       "0.118027          3\n",
       "0.404339          2\n",
       "0.218353          2\n",
       "0.102988          2\n",
       "0.091879          2\n",
       "0.077475          2\n",
       "0.208500          1\n",
       "0.131031          1\n",
       "0.226205          1\n",
       "0.293070          1\n",
       "0.127177          1\n",
       "0.125670          1\n",
       "0.117381          1\n",
       "0.510989          1\n",
       "0.087332          1\n",
       "0.082780          1\n",
       "0.569858          1\n",
       "0.584393          1\n",
       "Name: purchase, Length: 347, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.purchase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:42:42.577925Z",
     "start_time": "2022-10-30T19:42:35.368118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.12 s, sys: 84.4 ms, total: 7.2 s\n",
      "Wall time: 7.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "answer.to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:42:50.203792Z",
     "start_time": "2022-10-30T19:42:49.400120Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_answer = pd.read_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:42:52.241451Z",
     "start_time": "2022-10-30T19:42:52.232585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1654</td>\n",
       "      <td>336</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1654</td>\n",
       "      <td>678</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1654</td>\n",
       "      <td>691</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1654</td>\n",
       "      <td>696</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1654</td>\n",
       "      <td>763</td>\n",
       "      <td>0.043932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id  item_id  purchase\n",
       "0           0     1654      336  0.043932\n",
       "1           1     1654      678  0.043932\n",
       "2           2     1654      691  0.043932\n",
       "3           3     1654      696  0.043932\n",
       "4           4     1654      763  0.043932"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-30T19:42:56.253802Z",
     "start_time": "2022-10-30T19:42:55.127141Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
