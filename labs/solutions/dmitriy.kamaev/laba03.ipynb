{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f23e00c7438>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Смотрим что там в файлах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/ | awk '{print $8}' | xargs -I {} bash -c 'echo {}; hdfs dfs -head {} | sed -n \"1,5p\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Определяем разделитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -head /labs/slaba03/laba03_items.csv | xxd | sed -n '1,5p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, TimestampType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 635568\n",
      "-RECORD 0-------------------------------------------\n",
      " item_id                     | 65667                \n",
      " channel_id                  | null                 \n",
      " datetime_availability_start | 1970-01-01 03:00:00  \n",
      " datetime_availability_stop  | 2018-01-01 03:00:00  \n",
      " datetime_show_start         | null                 \n",
      " datetime_show_stop          | null                 \n",
      " content_type                | 1                    \n",
      " title                       | на пробах только ... \n",
      " year                        | 2013.0               \n",
      " genres                      | Эротика              \n",
      " region_id                   | null                 \n",
      "-RECORD 1-------------------------------------------\n",
      " item_id                     | 65669                \n",
      " channel_id                  | null                 \n",
      " datetime_availability_start | 1970-01-01 03:00:00  \n",
      " datetime_availability_stop  | 2018-01-01 03:00:00  \n",
      " datetime_show_start         | null                 \n",
      " datetime_show_stop          | null                 \n",
      " content_type                | 1                    \n",
      " title                       | скуби ду: эротиче... \n",
      " year                        | 2011.0               \n",
      " genres                      | Эротика              \n",
      " region_id                   | null                 \n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- channel_id: double (nullable = true)\n",
      " |-- datetime_availability_start: timestamp (nullable = true)\n",
      " |-- datetime_availability_stop: timestamp (nullable = true)\n",
      " |-- datetime_show_start: timestamp (nullable = true)\n",
      " |-- datetime_show_stop: timestamp (nullable = true)\n",
      " |-- content_type: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: double (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- region_id: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_item = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"delimiter\", \"\\t\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load('/labs/slaba03/laba03_items.csv')\n",
    "print('Count ' + str(df_item.count()))\n",
    "df_item.show(2, True, True)\n",
    "df_item.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = df_item.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 5032624\n",
      "-RECORD 0---------\n",
      " user_id  | 1654  \n",
      " item_id  | 74107 \n",
      " purchase | 0     \n",
      "-RECORD 1---------\n",
      " user_id  | 1654  \n",
      " item_id  | 89249 \n",
      " purchase | 0     \n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load('/labs/slaba03/laba03_train.csv')\n",
    "print('Count ' + str(df_train.count()))\n",
    "df_train.show(2, True, True)\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 2156840\n",
      "-RECORD 0----------\n",
      " user_id  | 903040 \n",
      " item_id  | 94901  \n",
      " purchase | 0      \n",
      "-RECORD 1----------\n",
      " user_id  | 938142 \n",
      " item_id  | 88705  \n",
      " purchase | 0      \n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load('/labs/slaba03/laba03_test.csv')\n",
    "print('Count ' + str(df_test.count()))\n",
    "df_train.show(2, True, True)\n",
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.repartition(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Платно/Бесплатно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Платно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df_item.filter(df_item.content_type == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов item_id нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.select(dfp.item_id).count(), dfp.select(dfp.item_id).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids = [row.item_id for row in dfp.select(dfp.item_id).collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = [row.item_id for row in df_train.select(df_train.item_id).distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teids = [row.item_id for row in df_test.select(df_test.item_id).distinct().collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(teids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for p1, t, te in zip(sorted(pids), sorted(tids), sorted(teids)):\n",
    "    i = i + 1\n",
    "    if p1 != t or t != te:\n",
    "        print(\"Лажа\")\n",
    "        break\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод из всего этого? Можно дропнуть в датасете все бесплатные итемы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = df_item.filter(df_item.content_type == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дропаем все итемы без жанров ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item[F.isnull(df_item.genres)].select(df_item.item_id, df_item.year, df_item.title).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слишком популярные сериалы без жанров, нужно проставить им вручную жанры, но сначала нужно обработать дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.select(df_item.title).count(), df_item.select(df_item.title).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item\\\n",
    "    .filter(df_item.content_type == 1)\\\n",
    "    .groupBy(df_item.title, df_item.year)\\\n",
    "    .count()\\\n",
    "    .filter(F.col('count') > 1)\\\n",
    "    .orderBy('count', ascending=False)\\\n",
    "    .show(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item\\\n",
    "    .filter(df_item.content_type == 1)\\\n",
    "    .groupBy(df_item.title, df_item.year)\\\n",
    "    .agg(F.collect_list(\"item_id\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как обработать дубликаты? Новая колонка item_id в которой указывать на один избранный дубликат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{73127: 74553,\n",
       " 81780: 88771,\n",
       " 89028: 93990,\n",
       " 95092: 87546,\n",
       " 99871: 77371,\n",
       " 2136: 80900,\n",
       " 78010: 96254,\n",
       " 92932: 82802,\n",
       " 10959: 88986,\n",
       " 10664: 66595,\n",
       " 66187: 83484,\n",
       " 74294: 2632,\n",
       " 87900: 9941,\n",
       " 93683: 100203,\n",
       " 88648: 89253,\n",
       " 87890: 5103,\n",
       " 94041: 1599,\n",
       " 73309: 74646,\n",
       " 82784: 7607,\n",
       " 82289: 10339,\n",
       " 78269: 67828,\n",
       " 77835: 90775,\n",
       " 72699: 88559,\n",
       " 8636: 74620,\n",
       " 88547: 94651,\n",
       " 82306: 3083,\n",
       " 99849: 77934,\n",
       " 101602: 77934,\n",
       " 98101: 102640,\n",
       " 8586: 99122,\n",
       " 99329: 8679,\n",
       " 78082: 8679,\n",
       " 101615: 8679,\n",
       " 103931: 97271,\n",
       " 93748: 100029,\n",
       " 10320: 66442,\n",
       " 89993: 74342,\n",
       " 89022: 79862,\n",
       " 74322: 9866,\n",
       " 72858: 86729,\n",
       " 10079: 77409,\n",
       " 9861: 94192,\n",
       " 101471: 9130,\n",
       " 100217: 83568,\n",
       " 8252: 67007,\n",
       " 72845: 99785,\n",
       " 77825: 98704,\n",
       " 7393: 94846,\n",
       " 10128: 74443,\n",
       " 79844: 67397,\n",
       " 88989: 88773,\n",
       " 85991: 86876,\n",
       " 74605: 540,\n",
       " 78976: 98737,\n",
       " 66399: 83512,\n",
       " 73310: 74379,\n",
       " 74805: 74115,\n",
       " 3755: 73739,\n",
       " 88886: 85740,\n",
       " 99962: 85740,\n",
       " 10031: 74523,\n",
       " 9855: 95051,\n",
       " 74380: 3408,\n",
       " 95015: 89014,\n",
       " 80895: 8634,\n",
       " 79412: 92393,\n",
       " 92357: 4603,\n",
       " 66585: 8224,\n",
       " 98670: 2343,\n",
       " 77802: 2343,\n",
       " 94742: 73378,\n",
       " 74407: 9971,\n",
       " 93064: 94781,\n",
       " 74333: 11471,\n",
       " 77716: 9706,\n",
       " 66997: 65908,\n",
       " 9462: 92081,\n",
       " 87903: 8643,\n",
       " 72073: 101842,\n",
       " 100229: 101842,\n",
       " 5576: 101842,\n",
       " 103589: 101842,\n",
       " 83732: 93061,\n",
       " 92657: 94773,\n",
       " 87889: 5530,\n",
       " 67052: 79831,\n",
       " 89633: 77438,\n",
       " 95012: 74472,\n",
       " 74359: 11023,\n",
       " 66555: 72718,\n",
       " 9139: 95187,\n",
       " 77867: 100226,\n",
       " 102141: 10927,\n",
       " 74272: 10130,\n",
       " 82357: 93564,\n",
       " 79409: 92352,\n",
       " 98228: 92352,\n",
       " 78160: 89044,\n",
       " 73190: 92862,\n",
       " 11478: 74647,\n",
       " 89049: 10517,\n",
       " 103812: 99509,\n",
       " 77583: 99509,\n",
       " 92937: 75704,\n",
       " 84449: 95953,\n",
       " 79891: 95953,\n",
       " 89064: 3895,\n",
       " 71600: 1685,\n",
       " 9555: 73516,\n",
       " 78113: 88803,\n",
       " 74678: 10002,\n",
       " 89109: 3188,\n",
       " 103371: 93719,\n",
       " 99790: 71570,\n",
       " 78686: 83529,\n",
       " 72225: 98684,\n",
       " 5859: 84289,\n",
       " 90009: 9832,\n",
       " 98975: 88982,\n",
       " 77684: 88982,\n",
       " 102441: 88982,\n",
       " 10521: 74292,\n",
       " 102444: 74249,\n",
       " 83487: 93463,\n",
       " 11494: 81844,\n",
       " 99483: 102447,\n",
       " 9129: 74402,\n",
       " 99840: 101992,\n",
       " 77924: 101992,\n",
       " 9737: 101992,\n",
       " 88651: 11025,\n",
       " 99558: 3703,\n",
       " 85990: 86860,\n",
       " 74779: 10327,\n",
       " 66175: 95188,\n",
       " 78268: 74512,\n",
       " 77931: 99845,\n",
       " 94689: 92533,\n",
       " 71653: 103762,\n",
       " 72902: 103762,\n",
       " 92858: 72732,\n",
       " 94098: 66405,\n",
       " 103235: 102431,\n",
       " 89678: 10531,\n",
       " 7648: 76701,\n",
       " 74597: 4995,\n",
       " 430: 94648,\n",
       " 71588: 99806,\n",
       " 79415: 92540,\n",
       " 101038: 72551,\n",
       " 3724: 74435,\n",
       " 74363: 102296,\n",
       " 100443: 74457,\n",
       " 78559: 92800,\n",
       " 73344: 89667,\n",
       " 101487: 99305,\n",
       " 72625: 99305,\n",
       " 102002: 99305,\n",
       " 73731: 763,\n",
       " 78281: 74532,\n",
       " 10091: 88999,\n",
       " 95940: 92361,\n",
       " 102588: 99980,\n",
       " 78116: 99980,\n",
       " 74495: 8379,\n",
       " 97127: 73389,\n",
       " 5767: 74412,\n",
       " 95020: 95151,\n",
       " 66822: 72900,\n",
       " 78272: 94046,\n",
       " 74431: 5583,\n",
       " 7577: 86404,\n",
       " 67746: 10845,\n",
       " 86846: 80891,\n",
       " 5299: 89258,\n",
       " 74377: 89258,\n",
       " 10419: 74341,\n",
       " 86052: 100504,\n",
       " 88797: 99971,\n",
       " 78114: 99971,\n",
       " 71942: 97979,\n",
       " 9705: 97979,\n",
       " 2696: 91231,\n",
       " 77789: 98592,\n",
       " 3305: 98592,\n",
       " 88973: 98592,\n",
       " 101509: 11068,\n",
       " 102641: 98213,\n",
       " 89104: 98213,\n",
       " 11484: 95009,\n",
       " 87311: 95009,\n",
       " 84402: 93999,\n",
       " 9073: 74306,\n",
       " 94764: 79407,\n",
       " 74579: 9589,\n",
       " 100212: 93709,\n",
       " 93667: 88807,\n",
       " 93563: 88807,\n",
       " 683: 94016,\n",
       " 802: 66684,\n",
       " 84497: 92923,\n",
       " 79461: 92425,\n",
       " 88994: 83207,\n",
       " 4975: 74510,\n",
       " 88940: 88546,\n",
       " 86402: 10574,\n",
       " 95470: 92916,\n",
       " 10844: 92890,\n",
       " 90010: 10298,\n",
       " 10526: 74542,\n",
       " 98511: 104152,\n",
       " 102616: 104152,\n",
       " 90762: 88794,\n",
       " 88898: 88794,\n",
       " 93039: 79450,\n",
       " 89660: 9847,\n",
       " 3159: 66680,\n",
       " 86547: 99986,\n",
       " 1867: 74960,\n",
       " 74271: 95010,\n",
       " 11026: 74555,\n",
       " 2990: 89000,\n",
       " 100419: 82811,\n",
       " 88990: 2967,\n",
       " 7194: 84238,\n",
       " 11516: 87886,\n",
       " 89008: 79851,\n",
       " 7098: 94134,\n",
       " 73599: 3692,\n",
       " 101587: 86214,\n",
       " 91262: 93493,\n",
       " 75469: 93558,\n",
       " 98736: 66852,\n",
       " 9738: 66852,\n",
       " 94666: 91251,\n",
       " 75094: 10382,\n",
       " 4033: 66827,\n",
       " 91286: 88706,\n",
       " 88596: 88706,\n",
       " 89263: 400,\n",
       " 101870: 71974,\n",
       " 8664: 71974,\n",
       " 102753: 99946,\n",
       " 336: 67864,\n",
       " 93484: 74827,\n",
       " 92649: 79400,\n",
       " 102089: 102651,\n",
       " 8496: 88960,\n",
       " 94686: 79893,\n",
       " 93576: 88538,\n",
       " 74278: 10662,\n",
       " 74677: 79857,\n",
       " 86001: 93621,\n",
       " 98178: 72090,\n",
       " 7444: 91498,\n",
       " 3176: 74316,\n",
       " 93583: 74527,\n",
       " 77747: 99925,\n",
       " 98274: 99471,\n",
       " 3751: 67515,\n",
       " 66870: 100382,\n",
       " 357: 66915,\n",
       " 9634: 74668,\n",
       " 9389: 74668,\n",
       " 89638: 74225,\n",
       " 72325: 98563,\n",
       " 10318: 74535,\n",
       " 88556: 79828,\n",
       " 88808: 93671,\n",
       " 74473: 9069,\n",
       " 88961: 98673,\n",
       " 781: 98673,\n",
       " 72214: 98673,\n",
       " 88237: 9544,\n",
       " 84236: 88899,\n",
       " 94687: 88899,\n",
       " 100834: 7501,\n",
       " 77472: 7501,\n",
       " 72327: 98565,\n",
       " 101423: 98565,\n",
       " 103299: 98565,\n",
       " 71794: 72926,\n",
       " 87836: 88865,\n",
       " 94243: 89681,\n",
       " 74284: 11518,\n",
       " 1320: 74581,\n",
       " 72413: 99844,\n",
       " 8628: 98970,\n",
       " 10326: 66623,\n",
       " 102126: 100779,\n",
       " 96398: 100779,\n",
       " 77442: 100779,\n",
       " 75207: 73429,\n",
       " 100448: 87168,\n",
       " 8599: 80432,\n",
       " 66622: 73229,\n",
       " 72972: 74689,\n",
       " 74544: 79837,\n",
       " 66594: 11232,\n",
       " 66454: 93465,\n",
       " 74438: 9833,\n",
       " 95073: 93616,\n",
       " 99833: 77917,\n",
       " 91953: 4209,\n",
       " 101946: 8587,\n",
       " 72394: 8587,\n",
       " 99834: 8587,\n",
       " 81856: 88823,\n",
       " 79841: 74561,\n",
       " 10372: 91225,\n",
       " 75152: 91225,\n",
       " 99967: 77973,\n",
       " 78570: 9640,\n",
       " 99991: 87728,\n",
       " 9817: 2405,\n",
       " 66447: 11011,\n",
       " 100112: 89992,\n",
       " 2855: 66763,\n",
       " 10340: 74490,\n",
       " 66871: 5193,\n",
       " 94614: 2072,\n",
       " 83698: 91424,\n",
       " 100571: 93550,\n",
       " 98664: 728,\n",
       " 79859: 74938,\n",
       " 74908: 88775,\n",
       " 88772: 95074,\n",
       " 95062: 87729,\n",
       " 82318: 94618,\n",
       " 948: 94618,\n",
       " 10646: 74348,\n",
       " 73304: 94996,\n",
       " 75071: 94669,\n",
       " 77347: 99720,\n",
       " 78026: 102595,\n",
       " 99527: 102595,\n",
       " 77938: 99852,\n",
       " 66663: 3711,\n",
       " 99775: 8585,\n",
       " 77353: 99730,\n",
       " 98402: 99730,\n",
       " 99522: 104016,\n",
       " 72760: 98891,\n",
       " 75015: 9570,\n",
       " 99750: 71532,\n",
       " 82299: 9758,\n",
       " 10045: 85986,\n",
       " 68477: 10682,\n",
       " 2313: 66577,\n",
       " 9812: 81842,\n",
       " 4977: 74440,\n",
       " 74575: 592,\n",
       " 101647: 94507,\n",
       " 5682: 74433,\n",
       " 91304: 93469,\n",
       " 88705: 93666,\n",
       " 90763: 93666,\n",
       " 101665: 93744,\n",
       " 102099: 93744,\n",
       " 93539: 93744,\n",
       " 98505: 93744,\n",
       " 92905: 84266,\n",
       " 88893: 84266,\n",
       " 94112: 92523,\n",
       " 91199: 85995,\n",
       " 99693: 77785,\n",
       " 10778: 82286,\n",
       " 752: 80905,\n",
       " 86748: 2093,\n",
       " 5493: 74720,\n",
       " 75552: 66215,\n",
       " 94661: 79826,\n",
       " 79773: 11482,\n",
       " 94634: 11482,\n",
       " 76481: 7611,\n",
       " 66630: 5117,\n",
       " 7113: 66914,\n",
       " 88811: 88972,\n",
       " 95279: 87175,\n",
       " 92871: 100478,\n",
       " 66426: 82874,\n",
       " 10564: 82352,\n",
       " 88768: 93575,\n",
       " 91960: 93575,\n",
       " 99978: 101620,\n",
       " 7496: 87165,\n",
       " 94699: 91332,\n",
       " 99793: 72946,\n",
       " 93529: 93739,\n",
       " 66434: 84365,\n",
       " 97440: 86212,\n",
       " 74109: 92836,\n",
       " 94642: 81409,\n",
       " 71822: 99508,\n",
       " 98895: 72895,\n",
       " 101832: 72087,\n",
       " 74274: 11060,\n",
       " 85490: 99770,\n",
       " 99947: 102080,\n",
       " 66863: 10450,\n",
       " 66671: 4949,\n",
       " 88805: 88963,\n",
       " 10296: 74890,\n",
       " 77715: 98147,\n",
       " 9708: 98147,\n",
       " 74491: 9068,\n",
       " 98743: 73217,\n",
       " 99843: 88795,\n",
       " 94608: 79901,\n",
       " 73381: 88638,\n",
       " 88970: 72324,\n",
       " 102966: 72324,\n",
       " 98562: 72324,\n",
       " 6111: 72324,\n",
       " 86743: 95014,\n",
       " 80854: 98191,\n",
       " 102657: 98191,\n",
       " 102095: 98191,\n",
       " 5660: 10385,\n",
       " 66457: 10385,\n",
       " 79876: 89001,\n",
       " 11375: 90003,\n",
       " 74526: 1525,\n",
       " 79873: 95856,\n",
       " 95054: 99990,\n",
       " 99979: 98474,\n",
       " 91813: 98474,\n",
       " 99920: 72102,\n",
       " 11002: 74275,\n",
       " 79476: 92538,\n",
       " 79883: 74511,\n",
       " 102699: 77470,\n",
       " 71944: 97982,\n",
       " 100429: 74536,\n",
       " 74630: 9838,\n",
       " 72987: 66467,\n",
       " 7677: 82780,\n",
       " 78118: 79039,\n",
       " 99982: 79039,\n",
       " 95004: 94705,\n",
       " 85657: 94705,\n",
       " 79840: 94771,\n",
       " 936: 74318,\n",
       " 74834: 10025,\n",
       " 88769: 100500,\n",
       " 82770: 93487,\n",
       " 79899: 88532,\n",
       " 89018: 73041,\n",
       " 74497: 5451,\n",
       " 74350: 4945,\n",
       " 10054: 77490,\n",
       " 66462: 72927,\n",
       " 81845: 3750,\n",
       " 5359: 67192,\n",
       " 80416: 5162,\n",
       " 100412: 74559,\n",
       " 100392: 751,\n",
       " 88945: 89016,\n",
       " 10824: 74569,\n",
       " 9380: 75510,\n",
       " 8633: 75510,\n",
       " 8661: 100865,\n",
       " 72481: 100865,\n",
       " 8652: 83513,\n",
       " 79887: 67831,\n",
       " 74528: 9871,\n",
       " 79455: 92500,\n",
       " 94784: 7300,\n",
       " 74373: 3686,\n",
       " 92823: 89430,\n",
       " 91280: 73771,\n",
       " 88894: 73771,\n",
       " 71830: 10926,\n",
       " 79460: 92409,\n",
       " 74390: 65906,\n",
       " 94834: 92669,\n",
       " 100116: 94641,\n",
       " 77579: 99503,\n",
       " 93121: 80260,\n",
       " 72925: 66513,\n",
       " 99862: 7569,\n",
       " 100484: 88652,\n",
       " 7584: 77431,\n",
       " 99803: 77431,\n",
       " 92356: 79453,\n",
       " 97298: 80435,\n",
       " 86000: 95033,\n",
       " 11487: 95033,\n",
       " 4967: 66858,\n",
       " 98672: 93716,\n",
       " 74757: 74113,\n",
       " 73046: 89055,\n",
       " 73368: 84927,\n",
       " 79026: 86740,\n",
       " 67144: 4946,\n",
       " 98054: 84639,\n",
       " 88896: 67318,\n",
       " 77890: 98546,\n",
       " 754: 74687,\n",
       " 10539: 91194,\n",
       " 93668: 93544,\n",
       " 95011: 66557,\n",
       " 11509: 82285,\n",
       " 99301: 86241,\n",
       " 82734: 93461,\n",
       " 74270: 11059,\n",
       " 98049: 77690,\n",
       " 98988: 77690,\n",
       " 11513: 77795,\n",
       " 98660: 77795,\n",
       " 101976: 77795,\n",
       " 79848: 83551,\n",
       " 97938: 93470,\n",
       " 99682: 77781,\n",
       " 66675: 9919,\n",
       " 10599: 89017,\n",
       " 66500: 5768,\n",
       " 100840: 77513,\n",
       " 11099: 77513,\n",
       " 74644: 9683,\n",
       " 92446: 79399,\n",
       " 77525: 72929,\n",
       " 79827: 94623,\n",
       " 80894: 4958,\n",
       " 88243: 7654,\n",
       " 9253: 88552,\n",
       " 94684: 9985,\n",
       " 10408: 89007,\n",
       " 88988: 10471,\n",
       " 92028: 9348,\n",
       " 79444: 69985,\n",
       " 66896: 89261,\n",
       " 88661: 8230,\n",
       " 83585: 7575,\n",
       " 73659: 5681,\n",
       " 66928: 2058,\n",
       " 9138: 95254,\n",
       " 73179: 87551,\n",
       " 87167: 100496,\n",
       " 2999: 75146,\n",
       " 10087: 66455,\n",
       " 74633: 11014,\n",
       " 100434: 87523,\n",
       " 66218: 94619,\n",
       " 74295: 72979,\n",
       " 98225: 93743,\n",
       " 101958: 88965,\n",
       " 77779: 88965,\n",
       " 11495: 88965,\n",
       " 101042: 72479,\n",
       " 82243: 79897,\n",
       " 11191: 78587,\n",
       " 72387: 7749,\n",
       " 99828: 7749,\n",
       " 10205: 7749,\n",
       " 74293: 72931,\n",
       " 101646: 78117,\n",
       " 99981: 78117,\n",
       " 75235: 9593,\n",
       " 100152: 89425,\n",
       " 93993: 89425,\n",
       " 88980: 99688,\n",
       " 78683: 99549,\n",
       " 79473: 92360,\n",
       " 10584: 66561,\n",
       " 88997: 79833,\n",
       " 82724: 11005,\n",
       " 4953: 74385,\n",
       " 66603: 678,\n",
       " 81864: 94004,\n",
       " 9471: 94751,\n",
       " 8654: 94002,\n",
       " 93594: 98722,\n",
       " 91978: 100218,\n",
       " 9622: 94776,\n",
       " 11104: 72329,\n",
       " 98567: 72329,\n",
       " 94148: 92032,\n",
       " 95029: 86875,\n",
       " 95183: 86875,\n",
       " 92542: 94676,\n",
       " 69098: 7746,\n",
       " 102395: 98971,\n",
       " 101822: 98971,\n",
       " 8658: 98971,\n",
       " 77679: 98971,\n",
       " 74273: 10303,\n",
       " 9864: 66440,\n",
       " 11187: 98682,\n",
       " 82345: 4968,\n",
       " 73403: 87914,\n",
       " 99963: 88976,\n",
       " 82358: 94037,\n",
       " 5029: 94037,\n",
       " 87940: 90493,\n",
       " 10488: 74420,\n",
       " 72328: 11106,\n",
       " 93588: 73320,\n",
       " 2027: 74411,\n",
       " 3314: 74839,\n",
       " 99703: 77333,\n",
       " 74652: 1159,\n",
       " 94896: 93142,\n",
       " 94045: 73250,\n",
       " 66184: 67098,\n",
       " 99524: 78024,\n",
       " 11196: 78024,\n",
       " 83483: 3823,\n",
       " 89032: 79894,\n",
       " 73159: 98744,\n",
       " 99935: 5462,\n",
       " 74730: 11510,\n",
       " 88991: 95000,\n",
       " 73326: 98982,\n",
       " 83706: 7668,\n",
       " 73421: 75358,\n",
       " 7476: 99705,\n",
       " 77335: 99705,\n",
       " 91217: 8341,\n",
       " 90019: 10524,\n",
       " 86738: 10475,\n",
       " 66658: 3182,\n",
       " 72930: 74391,\n",
       " 77436: 10069,\n",
       " 102359: 10069,\n",
       " 99811: 10069,\n",
       " 83570: 94085,\n",
       " 66188: 74339,\n",
       " 75099: 92850,\n",
       " 10355: 66533,\n",
       " 94001: 90006,\n",
       " 81398: 595,\n",
       " 10700: 73524,\n",
       " 102723: 71512,\n",
       " 74611: 5524,\n",
       " 79477: 92486,\n",
       " 76225: 7169,\n",
       " 92374: 79465,\n",
       " 100199: 94789,\n",
       " 84215: 7604,\n",
       " 11508: 82725,\n",
       " 92920: 72761,\n",
       " 80902: 2364,\n",
       " 98231: 92884,\n",
       " 72192: 98593,\n",
       " 10734: 98593,\n",
       " 98174: 77732,\n",
       " 4994: 87160,\n",
       " 74296: 11501,\n",
       " 74733: 94610}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_ids = df_item\\\n",
    "    .groupBy(df_item.title, df_item.year)\\\n",
    "    .agg(F.collect_list('item_id').alias('ids'))\\\n",
    "    .select('ids')\\\n",
    "    .filter(F.size(F.col('ids')) > 1)\\\n",
    "    .collect()\n",
    "cor_ids = {}\n",
    "for ids in [row.ids for row in duplicate_ids]:\n",
    "    for iids in ids[1:]:\n",
    "        cor_ids[iids] = ids[0]\n",
    "cor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.filter(df_item.title.like('%old')).select(df_item.title).show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ids = [9055, 100248, 9721, 100247]\n",
    "\n",
    "for _id in _ids:\n",
    "    if _id in cor_ids:\n",
    "        print('Лажа')\n",
    "        break\n",
    "\n",
    "# американская история ужасов old\n",
    "cor_ids[9055] = 100248\n",
    "# карточный домик old\n",
    "cor_ids[9721] = 100247"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Проверить на равенство жанров коррелирующие id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очень неоптимизированный код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_equal_genres_cor_ids = [id_ for id_ in cor_ids if df_item[df_item.item_id == id_][[df_item.genres]].collect() != df_item[df_item.item_id == cor_ids[id_]][[df_item.genres]].collect()]\n",
    "not_equal_genres_cor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_equal_genres_cor_ids), len(cor_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У двух третей дубликатов разные жанры, здесь можно потом будет что-нибудь придумать, чтобы увеличить AUC ROC, пока лень"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполняем пробелы в жанрах\n",
    "\n",
    "Создадим отдельный датафрейм, в котором руками укажем жанры для итемов, потом left join новая колонка, после when(F.isnull(df.genres), df.new_col).otherwise(df.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set()\n",
    "for row in df_item.select(F.split(df_item.genres, ',').alias('words')).collect():\n",
    "    if row.words != None:\n",
    "        for word in row.words:\n",
    "            genres.add(word)\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_genres = [\n",
    " (6151, 'Триллер,Драма,Криминал,Детективы,Сериалы,Зарубежные'),   #2011.0, title='родина'),\n",
    " (9055, 'Ужасы,Фантастика,Триллер,Драма,Сериалы,Зарубежные'),   #2011.0, title='американская история ужасов old'),\n",
    " (9059, 'Боевик,Триллер,Драма,Криминал,Детектив,Сериалы,Зарубежные'),   #2013.0, title='банши'),\n",
    " (9062, 'Комедия,Сериалы,Зарубежные'),   #2012.0, title='вице-президент'),\n",
    " (9064, 'Детективы,Криминал,Триллер,Драма,Сериалы,Зарубежные'),   #2014.0, title='настоящий детектив'),\n",
    " (9180, 'Фантастика,Драма,Боевик,Мелодрама,Приключения,Сериалы,Зарубежные'),   #2011.0, title='игра престолов'),\n",
    " (9632, 'Комедия,Сериалы,Зарубежные'),   #2014.0, title='силиконовая долина'),\n",
    " (9667, 'Драма,Криминал,Сериалы,Зарубежные'),   #2013.0, title='рэй донован'),\n",
    " (9668, 'Драма,Исторический,Сериалы,Зарубежные'),   #2015.0, title='покажите мне героя'),\n",
    " (9699, 'Драма,Музыкальные,Сериалы,Зарубежные'),   #2016.0, title='винил'),\n",
    " (9717, 'Драма,Исторический,Сериалы,Зарубежные'),   #2014.0, title='больница никербокер'),\n",
    " (9720, 'Боевик,Драма,Приключения,Сериалы,Зарубежные'),   #2014.0, title='черные паруса'),\n",
    " (9721, 'Драма,Сериалы,Зарубежные'),   #2013.0, title='карточный домик old'),\n",
    " (9817, 'Фантастика,Драма,Детективы,Сериалы,Зарубежные'),   #2014.0, title='оставленные'),\n",
    " (9819, 'Мультфильм,Комедия,Сериалы,Зарубежные'),   #2016.0, title='звери'),\n",
    " (9821, 'Драма,Сериалы,Зарубежные'),   #2015.0, title='плоть и кости'),\n",
    " (9896, 'Драма,Сериалы,Зарубежные'),   #2016.0, title='девушка по вызову'),\n",
    " (9897, 'Драма,Мелодрама,Комедия,Сериалы,Зарубежные'),   #2015.0, title='вместе'),\n",
    " (9898, 'Драма,Музыкальные,Сериалы,Зарубежные'),   #2015.0, title='империя'),\n",
    " (9914, 'Драма,Криминал,Сериалы,Зарубежные'),   #1999.0, title='клан сопрано'),\n",
    " (10205, 'Триллер,Криминал,Драма,Сериалы,Наши'),  #2015.0, title='метод'),\n",
    " (10208, 'Триллер,Криминал,Детективы,Сериалы,Зарубежные'),  #2011.0, title='мост'),\n",
    " (94973, 'Эротика'),  #2016.0, title='бруклин ли. дневник нимфоманки'),\n",
    " (94974, 'Эротика'),  #2016.0, title='душевные страсти'),\n",
    " (94976, 'Эротика'),  #2016.0, title='лисы в курятнике'),\n",
    " (94977, 'Эротика'),  #2015.0, title='новичкам везет (часть 1)'),\n",
    " (94979, 'Эротика'),  #2015.0, title='знает кошка, чью сметану съела'),\n",
    " (94975, 'Эротика'),  #2015.0, title='гламурный хардкор 3'),\n",
    " (94978, 'Эротика'),  #2016.0, title='сладкая помада'),\n",
    " (94988, 'Эротика'),  #2015.0, title='новичкам везет (часть 2)'),\n",
    " (100247, 'Драма,Сериалы,Зарубежные'), #2013.0, title='карточный домик'),\n",
    " (100248, 'Ужасы,Фантастика,Триллер,Драма,Сериалы,Зарубежные'), #2011.0, title='американская история ужасов'),\n",
    " (103377, 'Мультфильм,Короткометражки,Зарубежные'), #None, title='big buck bunny 1080p')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mis_genres = spark.sparkContext.parallelize(missing_genres).toDF()\\\n",
    "    .select(F.col('_1').alias('item_id'), F.col('_2').alias('mis_genres'))\n",
    "df_mis_genres.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 1. Приклеиваем доп колонкой отсутствующие жанры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_item.join(df_mis_genres, on='item_id', how='leftouter').coalesce(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 2. merge genres and mis_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.withColumn('genres_nn', F.coalesce(df_1.genres, df_1.mis_genres))\n",
    "df_2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.filter(df_2.item_id.isin([9062,65667,9064]))\\\n",
    "    .select('item_id', 'genres', 'mis_genres', 'genres_nn')\\\n",
    "    .show(3, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 3. Сплитим жанры в массив"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.withColumn(\"genres_arr\", F.split(df_2.genres_nn, ','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 4. Коллапсируем синонимы жанров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict[' сказка'] = 'Сказки'\n",
    "replace_dict['Комедии'] = 'Комедия'\n",
    "replace_dict['Арт-хаус'] = 'Артхаус'\n",
    "replace_dict['Анимация'] = 'Мультфильм'\n",
    "replace_dict['Боевики'] = 'Боевик'\n",
    "replace_dict['Военные'] = 'Военный'\n",
    "replace_dict['Детские песни'] = 'Детские'\n",
    "replace_dict['Для самых маленьких'] = 'Детские'\n",
    "replace_dict['Для детей'] = 'Детские'\n",
    "replace_dict['Документальные'] = 'Документальный'\n",
    "replace_dict['Драма'] = 'Драмы'\n",
    "replace_dict['Детективы'] = 'Детектив'\n",
    "replace_dict['Западные мультфильмы'] = 'Мультфильм'\n",
    "replace_dict['Исторические'] = 'Исторический'\n",
    "replace_dict['Комедии'] = 'Комедия'\n",
    "replace_dict['Короткометражки'] = 'Короткометражные'\n",
    "replace_dict['Мелодрама'] = 'Мелодрамы'\n",
    "replace_dict['Музыкальные'] = 'Музыкальный'\n",
    "replace_dict['Мультсериалы'] = 'Мультфильм'\n",
    "replace_dict['Мультфильмы'] = 'Мультфильм'\n",
    "replace_dict['Мультфильмы в 3D'] = 'Мультфильм'\n",
    "replace_dict['Приключение'] = 'Приключения'\n",
    "replace_dict['Наши'] = 'Русские'\n",
    "replace_dict['Русские мультфильмы'] = 'Мультфильм'\n",
    "replace_dict['Семейные'] = 'Семейный'\n",
    "replace_dict['Советские'] = 'Русские'\n",
    "replace_dict['Советское кино'] = 'Русские'\n",
    "replace_dict['Союзмультфильм'] = 'Мультфильм'\n",
    "replace_dict['Спорт'] = 'Спортивные'\n",
    "replace_dict['Триллер'] = 'Триллеры'\n",
    "replace_dict['Фантастика'] = 'Фантастические'\n",
    "replace_dict['Фильмы в 3D'] = 'Фильмы'\n",
    "replace_dict['Фэнтези'] = 'Фантастические'\n",
    "replace_dict['Юмористические'] = 'Комедия'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict_br = spark.sparkContext.broadcast(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.withColumn('genres_arr_colapsed', F.pandas_udf(lambda series: series.apply(lambda arr: [replace_dict_br.value[word] if word in replace_dict_br.value else word for word in arr]), ArrayType(StringType()), F.PandasUDFType.SCALAR)(F.col('genres_arr')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 5. Подсчитываем количество вхождений слов в массив "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(inputCol=\"genres_arr_colapsed\",\n",
    "                                   outputCol=\"genre_vector\",\n",
    "                                   vocabSize=51, # Посчитал заранее\n",
    "                                   binary=True # binary - потому что заменяли синонимы, вдруг там дублирование по ним есть\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = count_vectorizer.fit(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = cv_model.transform(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(cv_model.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хочу посчитать количество всех покупок по жанрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.printSchema()\n",
    "df_train.count(), df_train.filter(df_train.purchase == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.filter(df_train.purchase == 1).select(df_train.user_id).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.select(df_train.user_id).distinct().count(), df_train.select(df_train.item_id).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.select(df_test.user_id).distinct().count(), df_test.select(df_test.item_id).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1941 * 3704)\n",
    "print(5032624 + 2156840)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет - декартовое произведение юзеров и итемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество итемов, которых кто-либо купил\n",
    "df_train.filter(df_train.purchase == 1).select(df_train.item_id).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подклеиваем инфу по жанрам к каждой покупке/не покупке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Шаг 1. Вклеиваем инфу по итемам в train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_1 = df_train.filter(df_train.purchase == 1)\\\n",
    "    .join(df_5.select('item_id', 'genre_vector'), on='item_id')\\\n",
    "    .coalesce(6)\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мапа с информацией фильм, количество покупок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_count = dft_1\\\n",
    "    .rdd\\\n",
    "    .map(lambda row: (row.item_id, 1))\\\n",
    "    .reduceByKey(lambda x, y: x + y)\\\n",
    "    .toDF()\\\n",
    "    .select(F.col('_1').alias('item_id'), F.col('_2').alias('cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_count.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 6: Приклеиваем инфу по количеству покупок к итемам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6 = df_5.join(df_item_count, on='item_id', how='leftouter').coalesce(6)\n",
    "df_6.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 7: cnt null -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = df_6.withColumn('cunt', F.coalesce(df_6.cnt, F.lit(0))) # cunt вместо count, потому что на count начинает ругаться\n",
    "df_7.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итемы Шаг 8: genre_vector * cunt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = df_7.withColumn('weight_vec',\n",
    "                       F.udf(\n",
    "                           lambda vec, cnt: (vec.toArray().astype(int) * cnt).tolist(),\n",
    "                           ArrayType(IntegerType())\n",
    "                       )('genre_vector','cunt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисляем общий вектор покупок по жанрам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vec = df_8.rdd\\\n",
    "    .map(lambda row: (1, row.weight_vec))\\\n",
    "    .reduceByKey(lambda x, y: np.array(x) + np.array(y))\\\n",
    "    .take(1)[0][1]\n",
    "common_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre, count in sorted(zip(cv_model.vocabulary, common_vec), key=lambda row: row[1])[::-1]:\n",
    "    print(genre + ': ' + str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С итемами разобарлись, я так думаю, теперь надо разобраться с юзверами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем стату по юзерам (сколько юзер купил каких жанров) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu = dft_1.rdd.map(lambda row: (row.user_id, row.genre_vector.toArray().astype(int).tolist())).reduceByKey(lambda x, y: (np.array(x) + np.array(y)).tolist())\\\n",
    "    .toDF()\\\n",
    "    .select(F.col('_1').alias('user_id'), F.col('_2').alias('genre_cnt'))\n",
    "dfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu.show(2, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сколько всего итемов купил каждый юзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft_1.filter(dft_1.user_id == 754230).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cnt = dft_1.select(dft_1.user_id, F.lit(1).alias('_1'))\\\n",
    "    .groupBy(dft_1.user_id)\\\n",
    "    .agg(F.count('_1').alias('cnt'))\n",
    "dfu_1 = dfu.join(user_cnt, on='user_id')\n",
    "dfu_1.count(), dfu.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu_cnt0 = df_train.select(df_train.user_id)\\\n",
    "    .distinct()\\\n",
    "    .join(dfu_1.select(dfu_1.user_id), on='user_id', how=\"leftanti\")\\\n",
    "    .coalesce(6)\\\n",
    "    .select('user_id', F.array([F.lit(0)] * len(cv_model.vocabulary)).alias('genre_cnt'), F.lit(0).alias('cnt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu_cnt0.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Юзеры Шаг 2: объединяем платежников и халявщиков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfu_2 = dfu_1.union(dfu_cnt0)\n",
    "dfu_2.printSchema()\n",
    "dfu_2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Промежуточные итоги\n",
    "dfu_2 - содержит инфу по юзерам, сколько каких жанров было куплено и общее количество купленных\n",
    "\n",
    "df_8 - содержит инфу по итемам, сколько каких жанров было куплено и общее количество купленных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfri = F.broadcast(df_8.select(df_8.item_id, df_8.weight_vec.alias('ivec'), df_8.cunt.alias('icount')).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfru = F.broadcast(dfu_2.select(dfu_2.user_id, dfu_2.genre_cnt.alias('uvec'), dfu_2.cnt.alias('ucount')).cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfri, dfru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем намутить фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перемножим вектора юзеров и итемов по жанрам + общее количество юзеров и итемов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = df_train.join(dfri, on='item_id')\\\n",
    "    .join(dfru, on='user_id')\\\n",
    "    .coalesce(6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft1 = dft.withColumn('mvec', F.udf(lambda ivec, uvec: DenseVector(np.array(ivec) * np.array(uvec)), VectorUDT())(dft.ivec, dft.uvec))\n",
    "dft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft2 = dft1.withColumn(\"mcount\", dft1.icount * dft1.ucount)\n",
    "dft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecAssembler = VectorAssembler(inputCols=['mvec', 'mcount'], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft3 = vecAssembler.transform(dft2)\n",
    "dft3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(labelCol=\"purchase\", maxIter=10)\n",
    "gbtc_model = gbtc.fit(dft3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    dft = df.join(dfri, on='item_id')\\\n",
    "    .join(dfru, on='user_id')\\\n",
    "    .coalesce(6);\n",
    "    dft1 = dft.withColumn('mvec', F.udf(lambda ivec, uvec: DenseVector(np.array(ivec) * np.array(uvec)), VectorUDT())(dft.ivec, dft.uvec))\n",
    "    dft2 = dft1.withColumn(\"mcount\", dft1.icount * dft1.ucount)\n",
    "    dft3 = vecAssembler.transform(dft2)\n",
    "    return dft3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred = gbtc.transform(transform(df_test)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.show(5, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.filter(pred.prediction > 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = pred.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pred.drop(pred.purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2 = pred_1.withColumn('purchase', F.udf(lambda prob: float(prob[1]), FloatType())(pred_1.probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pred_2.select(pred_2.user_id, pred_2.item_id, pred_2.purchase).orderBy(pred_2.user_id, pred_2.item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 lab03.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пробуем намутить предсказания через ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS Шаг 1: Схлопываем дубликаты по именам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.pandas_udf(IntegerType())\n",
    "def replaceDuplicate(item_id_sr):\n",
    "    return item_id_sr.apply(lambda item_id: cor_ids[item_id] if item_id in cor_ids else item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = df_train.withColumn('item_id_nd', replaceDuplicate(df_train.item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_1 = df_test.withColumn('item_id_nd', replaceDuplicate(df_test.item_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Шаг 2: Делаем рейтинг из факта покупки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0 (не купил) - рейтинг 1\n",
    "* 1 (купил) - рейтинг 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = df_train_1.withColumn('rating', df_train_1.purchase * F.lit(9) + F.lit(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно сделать не константный рейтинг, а на основе частоты покупаемости итемов и покупательской способности юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_item_id = Window.partitionBy(\"item_id_nd\")\n",
    "window_user_id = Window.partitionBy(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_r = df_train_1.withColumn('r', \n",
    "                                   F.sum(df_train_1.purchase).over(window_item_id)\n",
    "                                   / F.count(F.lit(1)).over(window_item_id)\n",
    "                                   * F.sum(df_train_1.purchase).over(window_user_id)\n",
    "                                   / F.count(F.lit(1)).over(window_user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_r = Window.orderBy('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_nr = df_train_r.withColumn('nr', F.percent_rank().over(window_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо percent_rank можно еще просто нормализацию сделать, посмотрим что тогда лучше себя покажет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_r = VectorAssembler(inputCols=['r'],outputCol='r_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_r = MinMaxScaler(inputCol='r_arr', outputCol='scaled_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_r = Pipeline(stages=[assembler_r, scaler_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_nr = pipeline_r.fit(df_train_r).transform(df_train_r).withColumn('nr', F.udf(lambda v: float(v[0]),FloatType())('scaled_r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = df_train_nr.withColumn('rating', F.lit(5.5) + F.lit(4.5) * (df_train_nr.purchase * df_train_nr.nr - (F.lit(1) - df_train_nr.purchase) * (F.lit(1) - df_train_nr.nr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2.orderBy('rating', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(\n",
    "         userCol=\"user_id\", \n",
    "         itemCol=\"item_id_nd\",\n",
    "         ratingCol=\"rating\", \n",
    "         nonnegative = True, \n",
    "         implicitPrefs = False,\n",
    "         coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = als.fit(df_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Делаем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = als_model.transform(df_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Нормализуем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['prediction'],outputCol='prediction_arr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(inputCol='prediction_arr', outputCol='scaled_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipeline.fit(predictions).transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preds.withColumn('purchase', F.udf(lambda v: float(v[0]),FloatType())(preds.scaled_prediction))\\\n",
    "    .select('user_id', 'item_id', 'purchase')\\\n",
    "    .orderBy('user_id', 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('gbtcmodel.pk', \"wb\") as f:\n",
    "            pickle.dump(gbtc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyToLocal lab05.csv/part-00000-98cefec9-508c-40f4-b366-3df2f52be2e1-c000.csv lab05.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 dmitriy.kamaev dmitriy.kamaev          0 2022-11-02 15:36 lab05.csv/_SUCCESS\r\n",
      "-rw-r--r--   3 dmitriy.kamaev dmitriy.kamaev    1190768 2022-11-02 15:36 lab05.csv/part-00000-98cefec9-508c-40f4-b366-3df2f52be2e1-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls lab05.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
