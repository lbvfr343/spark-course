{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 10 --executor-memory 5g --executor-cores 8 --driver-memory 8g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark-course</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f76b8ef9400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, SparseVector, VectorUDT\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.classification import GBTClassifier, LogisticRegression, GBTClassificationModel, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[2]\") \\\n",
    "                    .appName(\"spark-course\") \\\n",
    "                    .config(\"spark.driver.memory\", \"512m\") \\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "    \"subscribe\": \"input_roman.razumovskiy\",\n",
    "    \"startingOffsets\": \"latest\"\n",
    "}\n",
    "kafka_sdf = spark.readStream.format(\"kafka\").options(**read_kafka_params).load()\n",
    "# kafka_df = spark.read.format(\"kafka\").options(**read_kafka_params).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(s):\n",
    "    try:\n",
    "        domain = s.split('/')[2]\n",
    "        if domain in ['http:','https:']:\n",
    "            domain = s.split('/')[4]\n",
    "        return domain\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "get_domain_udf = F.udf(get_domain, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uid: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- domain: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_type_1 = MapType(StringType(), StringType())\n",
    "json_type_2 = ArrayType(MapType(StringType(), StringType()))\n",
    "\n",
    "clickstream = kafka_sdf.select(F.col('value').cast('string'))\\\n",
    ".select(F.from_json('value', json_type_1).alias('user_json'))\\\n",
    ".select(F.col('user_json')['uid'].alias('uid') \n",
    "        , F.explode(F.from_json(F.col('user_json')['visits'], json_type_2)).alias('visit'))\\\n",
    ".withColumn('url', F.col('visit')['url'])\\\n",
    ".withColumn('timestamp', F.col('visit')['timestamp'].cast('double'))\\\n",
    ".withColumn('domain', get_domain_udf('url'))\\\n",
    ".drop('visit')\n",
    "\n",
    "clickstream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "htf = HashingTF(numFeatures = 1000, inputCol = 'url_list', outputCol = 'features')\n",
    "\n",
    "features_df = clickstream.groupBy('uid')\\\n",
    ".agg(F.collect_list('url').alias('url_list'))\n",
    "\n",
    "features_df = htf.transform(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_model = GBTClassificationModel.load('gender_model')\n",
    "age_model = LogisticRegressionModel.load('age_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = gender_model\\\n",
    ".transform(features_df)\\\n",
    ".select('uid','features',F.col('prediction').cast('int').cast('string').alias('gender'))\\\n",
    ".replace(['0','1'],['F', 'M'],'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = age_model\\\n",
    ".transform(submit_df)\\\n",
    ".select('uid',F.col('prediction').cast('int').cast('string').alias('age'))\\\n",
    ".replace(['0','1','2','3','4'],['18-24', '25-34', '35-44', '45-54', '>=55'],'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f76b8f07b70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_kafka_params = {\n",
    "   \"kafka.bootstrap.servers\": 'spark-master-1.newprolab.com:6667',\n",
    "   \"topic\": \"roman.razumovskiy\"\n",
    "}\n",
    "submit_df.writeStream.outputMode('complete')\\\n",
    "    .format(\"kafka\").options(**write_kafka_params)\\\n",
    "    .option(\"checkpointLocation\", \"streaming/chk/chk_kafka\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
