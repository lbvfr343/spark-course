{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "# from pyspark.sql.types import ArrayType, StringType, NumericType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import SparseVector, VectorUDT\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"test\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|                 cat|                desc| id|lang|                name|      provider|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "|3/business_manage...|This course intro...|  4|  en|Accounting Cycle:...|Canvas Network|\n",
      "|              11/law|This online cours...|  5|  en|American Counter ...|Canvas Network|\n",
      "|5/computer_scienc...|This course is ta...|  6|  fr|Arithmétique: en ...|Canvas Network|\n",
      "|  14/social_sciences|We live in a digi...|  7|  en|Becoming a Dynami...|Canvas Network|\n",
      "|2/biology_life_sc...|This self-paced c...|  8|  en|           Bioethics|Canvas Network|\n",
      "+--------------------+--------------------+---+----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----+-----+\n",
      "|lang|count|\n",
      "+----+-----+\n",
      "|  en|24553|\n",
      "|  es| 1374|\n",
      "|  ru| 1231|\n",
      "|  pt|  187|\n",
      "|  zh|  169|\n",
      "|  de|  166|\n",
      "|  tr|  120|\n",
      "|  fr|  104|\n",
      "|  ja|   77|\n",
      "|  it|   62|\n",
      "+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eclass = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "eclass.show(5)\n",
    "eclass.groupby('lang').count().orderBy('count', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+\n",
      "|   id|lang|                name|\n",
      "+-----+----+--------------------+\n",
      "|23126|  en|Compass - powerfu...|\n",
      "|21617|  en|Preparing for the...|\n",
      "|16627|  es|Aprende Excel: Ni...|\n",
      "|11556|  es|Aprendizaje Colab...|\n",
      "|16704|  ru|Программирование ...|\n",
      "|13702|  ru|Математическая эк...|\n",
      "+-----+----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Тест-кейсы\n",
    "\n",
    "test = [[23126, u'en', u'Compass - powerful SASS library that makes your life easier']\n",
    "        , [21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2']\n",
    "        , [16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche']\n",
    "        , [11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo']\n",
    "        , [16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus']\n",
    "        , [13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]\n",
    "\n",
    "test_df = spark.createDataFrame(test,['id','lang','name']).cache()\n",
    "test_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции для работы с разреженными векторами\n",
    "\n",
    "sparse_mul = F.udf(lambda x, y: SparseVector(x.size, \n",
    "                                             {i: x[int(i)]*y[int(i)] for i in x.indices if i in y.indices})\n",
    "                   , VectorUDT())\n",
    "\n",
    "sparse_corr = F.udf(lambda x, y: float(x.dot(y) / (x.norm(2) * y.norm(2))), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n",
      "[Row(id=23126, recs=[2724, 24419, 20638, 13782, 2633, 2723, 15909, 17208, 2103, 13665], corrs=[0.8350997567176819, 0.7607442736625671, 0.5446198582649231, 0.523579478263855, 0.4605848789215088, 0.4273214638233185, 0.3238350749015808, 0.30374205112457275, 0.26037198305130005, 0.24968795478343964]), Row(id=21617, recs=[21609, 21492, 19784, 21624, 21623, 21630, 21628, 19787, 19748, 19927], corrs=[0.9878465533256531, 0.6460206508636475, 0.6214882731437683, 0.5887160897254944, 0.5808205604553223, 0.5807337760925293, 0.5806847810745239, 0.5511248707771301, 0.5489208102226257, 0.5331961512565613])]\n",
      "es\n",
      "[Row(id=16627, recs=[12660, 11431, 5687, 12247, 5558, 17964, 9598, 9563, 16694, 10738], corrs=[0.48520413041114807, 0.4649285078048706, 0.4363709092140198, 0.42597275972366333, 0.3931557536125183, 0.39208075404167175, 0.38598108291625977, 0.37615591287612915, 0.36538413166999817, 0.2912662923336029]), Row(id=11556, recs=[16488, 10447, 468, 22710, 19330, 13461, 10384, 23357, 21707, 13776], corrs=[0.5940172076225281, 0.47194862365722656, 0.46630871295928955, 0.3924507796764374, 0.3108474612236023, 0.27924564480781555, 0.27571311593055725, 0.24084989726543427, 0.21400988101959229, 0.20493076741695404])]\n",
      "ru\n",
      "[Row(id=13702, recs=[21079, 8313, 17017, 19613, 17015, 1052, 7173, 21033, 28074, 5216], corrs=[0.14450323581695557, 0.1405077427625656, 0.13828144967556, 0.13540157675743103, 0.12947998940944672, 0.12559542059898376, 0.12406779825687408, 0.12281086295843124, 0.12189101427793503, 0.11644206941127777]), Row(id=16704, recs=[18331, 1219, 55, 1228, 1365, 12201, 1250, 1387, 20289, 26980], corrs=[0.1339322179555893, 0.13055551052093506, 0.13007357716560364, 0.13003666698932648, 0.11859108507633209, 0.106294646859169, 0.10025668889284134, 0.08942260593175888, 0.08942260593175888, 0.08369860053062439])]\n"
     ]
    }
   ],
   "source": [
    "# Строим рекомендации отдельно для каждого языка из тест-кейсов\n",
    "\n",
    "recs = {}\n",
    "\n",
    "for lang in ['en','es','ru']:\n",
    "    print(lang)\n",
    "    tfidf = eclass.filter(F.col('lang') == lang)\n",
    "    tfidf = Pipeline(stages=[\n",
    "        RegexTokenizer(inputCol='desc', outputCol='tokens'),\n",
    "        StopWordsRemover(inputCol='tokens', outputCol='words'),\n",
    "        HashingTF(inputCol = 'words', outputCol = 'tf', numFeatures = 10000),\n",
    "        IDF(inputCol='tf', outputCol='idf')\n",
    "    ]).fit(tfidf).transform(tfidf)\n",
    "\n",
    "    tfidf = tfidf.withColumn('tfidf', sparse_mul(F.col('tf'),F.col('idf'))).select('id','lang','tfidf').cache()\n",
    "    \n",
    "    test_tfidf = test_df.join(tfidf, 'id').select(test_df['id'], test_df['lang'], tfidf['tfidf'].alias('test_tfidf')).cache()\n",
    "    \n",
    "    window = Window.partitionBy(test_tfidf['id']).orderBy(F.col('corr').desc())\n",
    "\n",
    "    rec_list = test_tfidf.join(tfidf, 'lang')\\\n",
    "    .withColumn('corr', sparse_corr(test_tfidf['test_tfidf'], tfidf['tfidf']))\\\n",
    "    .select(test_tfidf['id'], test_tfidf['lang'], tfidf['id'].alias('rec_id'), 'corr')\\\n",
    "    .filter(~F.isnan('corr'))\\\n",
    "    .filter(F.col('corr') < 1)\\\n",
    "    .withColumn('rank', F.rank().over(window))\\\n",
    "    .filter(F.col('rank') <= 10)\\\n",
    "    .orderBy(test_tfidf['id'], 'rank')\\\n",
    "    .groupBy(test_tfidf['id'])\\\n",
    "    .agg(F.collect_list('rec_id').alias('recs'), F.collect_list('corr').alias('corrs'))\\\n",
    "    .collect()\n",
    "    \n",
    "    print(rec_list)\n",
    "    \n",
    "    for x in rec_list:\n",
    "        recs[str(x['id'])] = x['recs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/home/roman.razumovskiy/lab02.json', 'w') as recs_json:\n",
    "    json.dump(recs, recs_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r",
      "\r\n",
      "\"1666\": [23420, 418, 24961, 12247, 25750, 9498, 23146, 23506, 11431, 24134], \r",
      "\r\n",
      "\"16566\": [1488, 560, 20965, 9416, 19330, 18721, 9406, 23304, 9025, 22781], \r",
      "\r\n",
      "\"21226\": [1365, 1760, 13782, 20638, 24419, 15909, 2724, 25782, 13348, 17499], \r",
      "\r\n",
      "\"21642\": [209, 21673, 21081, 22298, 19417, 380, 8110, 16971, 12205, 6776], \r",
      "\r\n",
      "\"1704\": [119, 1327, 20362, 1228, 55, 1247, 1365, 913, 20095, 989], \r",
      "\r\n",
      "\"7062\": [864, 1111, 1410, 8123, 13057, 1396, 1033, 22053, 8083, 21079]\r",
      "\r\n",
      "}\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! cat /share/submission-files/slaba02/lab02.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
