{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 5g pyspark-shell'\n",
    "#os.environ[\"PYSPARK_SUBMIT_ARGS\"]='pyspark-shell'\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.types import ArrayType, DoubleType, BooleanType, FloatType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col, array_contains, split, array_distinct, explode, collect_set, when, lit\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные:\n",
    "- TRAIN - датасет, на котром тренируется модель\n",
    "- TEST - датасет, на котром проверям качество своей модели, целевой признак отсутствует (без указания purchase, который и нужно предсказать)\n",
    "- ITEMS - весь контент, который представлен на платформе E-Contenta (много ненужной информации, поля нужно фильтровать). Здесь представлена подробная информация о контенте, который предложен пользователям. Нам нужны тольео 5 полей. Причем в поле жанр может быть несколько жанров, которые перечислены через запятую => на это нужно обратить внимание.\n",
    "- VIEW PROGRAMMES - метрики и дополнительные данные о просмотрах пользователями. В частности здесь указано, как долго пользовательс мотрел ту или иную идиницу контента. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|1654   |74107  |0       |\n",
      "|1654   |89249  |0       |\n",
      "|1654   |99982  |0       |\n",
      "+-------+-------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_train = StructType(fields = [\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"item_id\", IntegerType(), True),\n",
    "    StructField(\"purchase\", IntegerType(), True),\n",
    "])\n",
    "\n",
    "df_train = spark.read.csv(\"/labs/slaba03/laba03_train.csv\", sep = \",\", header = True, schema = schema_train)\n",
    "df_train.show(3,  vertical = False, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|user_id|item_id|\n",
      "+-------+-------+\n",
      "|1654   |94814  |\n",
      "|1654   |93629  |\n",
      "|1654   |9980   |\n",
      "+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_test = StructType(fields = [\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"item_id\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "test = spark.read.csv(\"/labs/slaba03/laba03_test.csv\", sep = \",\", header = True, schema = schema_test)\n",
    "test.show(3, vertical = False, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------\n",
      " item_id      | 65667                                                    \n",
      " content_type | 1                                                        \n",
      " title        | на пробах только девушки (all girl auditions)            \n",
      " year         | 2013.0                                                   \n",
      " genres       | Эротика                                                  \n",
      "-RECORD 1----------------------------------------------------------------\n",
      " item_id      | 65669                                                    \n",
      " content_type | 1                                                        \n",
      " title        | скуби ду: эротическая пародия (scooby doo: a xxx parody) \n",
      " year         | 2011.0                                                   \n",
      " genres       | Эротика                                                  \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_items = StructType(fields = [\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"channel_id\", IntegerType()),\n",
    "    StructField(\"datetime_availability_start\", StringType()),\n",
    "    StructField(\"datetime_availability_stop\", StringType()),\n",
    "    StructField(\"datetime_show_start\", StringType()),\n",
    "    StructField(\"datetime_show_stop\", StringType()),\n",
    "    StructField(\"content_type\", IntegerType()),\n",
    "    StructField(\"title\", StringType(), nullable = True),\n",
    "    StructField(\"year\", FloatType(), nullable = True),\n",
    "    StructField(\"genres\", StringType()),\n",
    "    StructField(\"region_id\", IntegerType())\n",
    "])\n",
    "\n",
    "df_items = spark.read.csv(\"/labs/slaba03/laba03_items.csv\", sep = \"\\t\", header = True, schema = schema_items)\n",
    "df_items = df_items.select([\"item_id\", \"content_type\", \"title\", \"year\", \"genres\"])\n",
    "df_items.show(2,  vertical = True, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.na.fill(value=-1,subset=[\"year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(content_type=1), Row(content_type=0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items.select('content_type').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+--------+\n",
      "|user_id|item_id|  ts_start|    ts_end|ite_type|\n",
      "+-------+-------+----------+----------+--------+\n",
      "|      0|7101053|1491409931|1491411600|    live|\n",
      "|      0|7101054|1491412481|1491451571|    live|\n",
      "|      0|7101054|1491411640|1491412481|    live|\n",
      "+-------+-------+----------+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_programmes = StructType(fields = [\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", StringType()),\n",
    "    StructField(\"ts_start\", IntegerType()),\n",
    "    StructField(\"ts_end\", IntegerType()),\n",
    "    StructField(\"ite_type\", StringType())\n",
    "])\n",
    "\n",
    "df_programmes = spark.read.csv(\"/labs/slaba03/laba03_views_programmes.csv\", sep = \",\", header = True, \n",
    "                              schema = schema_programmes)\n",
    "df_programmes.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### План решения\n",
    "1. **Генерация пизнакови и фильтрация**. Нужно составитьтакие признаки, которые охарактеризовали бы покупаемость того или иного контента с некоторой вероятностью. Также надо составить статистику для users, с какой вероятностью этот user вообще покупает како-либо контент. \n",
    "   - 2 типа признаков: 1) характеризуют покупаемость того или иного контента (то есть с какой веротяностью покупается контент в зависимости от признаков этого контента => для этого используем one hot encoding), 2) user-statistics, с какой вероятностью вообще покупается какой то контент (для этого используем target encoding).\n",
    "   - В таблице ITEMS есть бинарный признак content_type - нас интересуют только платные передачи. Поэтому необходимо сделать фильтрацию. \n",
    "   - В таблице ITEMS нас интересуют только пять полей: item_id, content_type, title, year, genres.\n",
    "   - **Target Encoding** - это encoding для категориальных признаков, который содержит в себе инофрмацию о частоте таргета в категориальных признаках. То есть с какой веротяностью таргет (единица) встречается в том или ином категориальном признаке. Перед использованием Target Encoding необходимо разделить тренировочный датасет на 3 части - train, validation и датасет для расчета статистики. Мы считатем статситсику по юзерам и контенту на раннем промежутке времени, а дальше сделать join этой статситики к train и validation и test. Это показательный признак, который попожет знам в значительной степени. \n",
    "       - Например, мы можем посчитать статситику, нкакова вероятность, что конкретный user/фильм вообще покупаются (на основе laba03_train посчитать, как интенсивно покупает пользователь и покупаемость items)\n",
    "   - Если в признаке есть несколько жанров, то они перечислены через запятую => на это нужно обратить внимание. Для обработки жанров будет использоваться **One Hot Encoding** (!!! НО при этом не нужно использовать onehotencoding для всех комбинаций жанров, так как этих комбинаций жанров очень много => это очень сильно раздует объем фичей). Также ожно применить CountVectorizer к жанрам и полученный вектор  использовать как фичу. \n",
    "   - Необходимо использовать информацию по времени просмотра, которая представлена в файле VIEW PROGRAMME. Таймстэмпы ts_start и ts_end можно использовать для feature-engineering. Можно рассчитать время простмотра для разных типов просмотров - live и pvr.\n",
    "2. **Построение модели GBTClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем на train и validation\n",
    "train = df_train.sampleBy(\"purchase\", fractions={0: 0.8, 1: 0.8}, seed=5757)\n",
    "\n",
    "valid = df_train.join(train, on=[\"user_id\", \"item_id\"], how=\"leftanti\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_prob = train.groupBy('user_id')\\\n",
    "                .sum().select(col(\"sum(purchase)\").alias(\"user_purchases\"), col(\"user_id\")).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_prob = train.groupBy('item_id')\\\n",
    "                        .sum().select(col(\"sum(purchase)\").alias(\"item_prob\"), col(\"item_id\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(train_prob, on='user_id', how='left')\n",
    "valid = valid.join(train_prob, on='user_id', how='left')\n",
    "test = test.join(train_prob, on='user_id', how='left')\n",
    "\n",
    "train = train.join(item_prob, on='item_id', how='left')\n",
    "valid = valid.join(item_prob, on='item_id', how='left')\n",
    "test = test.join(item_prob, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|user_attempts|user_id|\n",
      "+-------------+-------+\n",
      "|         2089| 754230|\n",
      "|         2058| 761341|\n",
      "|         2059| 780033|\n",
      "|         2089| 798454|\n",
      "|         2104| 825061|\n",
      "|         2032| 833685|\n",
      "|         2114| 846231|\n",
      "|         2128| 851486|\n",
      "|         2089| 867850|\n",
      "|         2122| 870928|\n",
      "|         2064| 927211|\n",
      "|         2084| 776188|\n",
      "|         2103| 901457|\n",
      "|         2045| 879401|\n",
      "|         2064| 928140|\n",
      "|         2080| 824008|\n",
      "|         2073| 880451|\n",
      "|         2063| 890476|\n",
      "|         2070| 900203|\n",
      "|         2094| 937345|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_user_nums = train.groupBy('user_id').count().select(col(\"count\").alias(\"user_attempts\"), col(\"user_id\"))\\\n",
    "                            .cache()\n",
    "\n",
    "train_item_attempts = train.groupBy('item_id').count().select(col(\"count\").alias(\"item_attempts\"), col(\"item_id\"))\\\n",
    "                            .cache()\n",
    "\n",
    "train_user_nums.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(train_user_nums, on='user_id', how='left')\n",
    "valid = valid.join(train_user_nums, on='user_id', how='left')\n",
    "test = test.join(train_user_nums, on='user_id', how='left')\n",
    "\n",
    "train = train.join(train_item_attempts, on='item_id', how='left')\n",
    "valid = valid.join(train_item_attempts, on='item_id', how='left')\n",
    "test = test.join(train_item_attempts, on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('user_addict', (train.user_purchases / train.user_attempts))\n",
    "valid = valid.withColumn('user_addict', col('user_purchases') / col('user_attempts'))\n",
    "test = test.withColumn('user_addict', col('user_purchases') / col('user_attempts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.withColumn('item_addict', col('item_prob') / col('item_attempts'))\n",
    "valid = valid.withColumn('item_addict', col('item_prob') / col('item_attempts'))\n",
    "test = test.withColumn('item_addict', col('item_prob') / col('item_attempts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[item_attempts: bigint, item_id: int]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prob.unpersist()\n",
    "item_prob.unpersist()\n",
    "train_user_nums.unpersist()\n",
    "train_item_attempts.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Выбираю колонки, которые войдут в features для GBT\n",
    "cols = ['item_prob', 'user_purchases', 'user_addict', 'item_addict']\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "\n",
    "train_data = assembler.transform(train).cache()\n",
    "valid_data = assembler.transform(valid)\n",
    "test_data = assembler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"purchase\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    gbt\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"purchase\", metricName='areaUnderROC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"purchase\", maxDepth = 5, maxIter=2)\n",
    "\n",
    "gbt_model = gbt.fit(train_data)\n",
    "predictions_valid = gbt_model.transform(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920015019857043"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"purchase\", metricName='areaUnderROC')\n",
    "score = evaluator.evaluate(predictions_valid)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_pd = test_predictions.select(\"user_id\", \"item_id\", col(\"probability\").alias(\"purchase\")).toPandas()\n",
    "predictions_pd = predictions_pd.sort_values(by=['user_id', 'item_id'])\n",
    "predictions_pd['purchase'] = predictions_pd['purchase'].apply(lambda x: x[1])\n",
    "predictions_pd.to_csv('lab03.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
