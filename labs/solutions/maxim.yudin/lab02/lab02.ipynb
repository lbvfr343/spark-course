{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-cores 3 --executor-memory 3g --conf spark.locality.wait=0s --driver-memory 10g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT, Vectors\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Maksim Yudin lab02\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Maksim Yudin lab02\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllCoursesDf(spark: SparkSession):\n",
    "    courses = spark.read.json(\"hdfs:///labs/slaba02/DO_record_per_line.json\") \\\n",
    "        .select(col(\"id\"), col(\"lang\"), col('name'), col(\"desc\"))\n",
    "    \n",
    "    return courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureCount = 10000\n",
    "\n",
    "allCoursesDf = getAllCoursesDf(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictCoursesDf(spark: SparkSession):\n",
    "    sourceData = spark.createDataFrame([\n",
    "        (23126, \"en\", \"Compass - powerful SASS library that makes your life easier\"),\n",
    "        (21617, \"en\", \"Preparing for the AP* Computer Science A Exam \\u2014 Part 2\"),\n",
    "        (16627, \"es\", \"Aprende Excel: Nivel Intermedio by Alfonso Rinsche\"),\n",
    "        (11556, \"es\", \"Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo\"),\n",
    "        (16704, \"ru\",\n",
    "        \"\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus\"),\n",
    "        (13702, \"ru\",\n",
    "        \"\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430\")\n",
    "    ], [\"id\", \"lang\", 'desc'])\n",
    "\n",
    "    return sourceData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictDataDf = getPredictCoursesDf(spark)\n",
    "predictCoursesDf = predictDataDf.alias(\"predictDataDf\").join(allCoursesDf.alias(\"allCoursesDf\"), predictDataDf.id == allCoursesDf.id, \"left\")\\\n",
    ".select(col(\"predictDataDf.id\"), col(\"predictDataDf.lang\"), col(\"predictDataDf.desc\").alias('name'), col(\"allCoursesDf.desc\").alias('desc'))\n",
    "predictCoursesDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitDataframe(allCourses):\n",
    "    tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"words\")\n",
    "    wordsData = tokenizer.transform(allCourses)\n",
    "\n",
    "    remover = StopWordsRemover(inputCol=\"words\", outputCol=\"cleanWords\")\n",
    "    cleanWordsData = remover.transform(wordsData) \\\n",
    "        .select(col(\"id\"), col(\"lang\"),\\\n",
    "                col('name'),\\\n",
    "                col('cleanWords').alias(\"words\"))\n",
    "\n",
    "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=featureCount)\n",
    "    featurizedData = hashingTF.transform(cleanWordsData)\n",
    "    \n",
    "    #featurizedData.show(1, truncate=0, vertical=True)\n",
    "\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(featurizedData)\n",
    "    rescaledData = idfModel.transform(featurizedData)\n",
    "    #rescaledData = rescaledData.drop(\"words\", \"rawFeatures\") \\\n",
    "        #.drop(\"words\", \"rawFeatures\")\n",
    "    #rescaledData.show(1, truncate=0, vertical=True)\n",
    "\n",
    "    return rescaledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denseVectorColumn(x):\n",
    "    return udf(lambda: x, VectorUDT())()\n",
    "\n",
    "def to_dense(sparse_vector):\n",
    "    return Vectors.dense(sparse_vector)\n",
    "\n",
    "def to_sparse(dense_vector):\n",
    "    size = len(dense_vector)\n",
    "    pairs = [(i, v) for i, v in enumerate(dense_vector.values.tolist()) if v != 0]\n",
    "    return Vectors.sparse(size, pairs)\n",
    "\n",
    "def calcCos(v, u):\n",
    "    try:\n",
    "        return float(v.dot(u) / (v.norm(2) * u.norm(2)))\n",
    "    except Exception as e:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparseToDenseUdf = udf(to_dense, VectorUDT())\n",
    "calcCosUdf = udf(lambda v, u: calcCos(v, u), FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfLanguages = predictCoursesDf.select(col('lang')).distinct()\n",
    "dfLangArray = dfLanguages.collect()\n",
    "featuresByLang = {}\n",
    "for l in dfLangArray:\n",
    "    dataByLangDf = allCoursesDf.where(col('lang') == l[0])\n",
    "    #dfByLang.printSchema()\n",
    "    fitDataDf = fitDataframe(dataByLangDf)\n",
    "    \n",
    "    resultDf = fitDataDf.withColumn('featureAsDenseVector', sparseToDenseUdf(fitDataDf['features']))\\\n",
    "        .drop('words', 'rawFeatures', 'features')\n",
    "    \n",
    "    resultDf.repartition(1)\n",
    "    resultDf.cache()\n",
    "    resultDf.count()\n",
    "    \n",
    "    \n",
    "    featuresByLang[l[0]] = resultDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allCoursesRescaledData = fitDataframe(allCourses)\n",
    "\n",
    "fitPredictDataDf = fitDataframe(predictCoursesDf)\n",
    "#fitPredictDataDf.show(1, truncate=0, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitPredictDataDf = fitPredictDataDf\\\n",
    "        .withColumn('featureAsDenseVector', sparseToDenseUdf(fitPredictDataDf['features']))\\\n",
    "        .drop('words', 'rawFeatures', 'features')\n",
    "\n",
    "#fitPredictDataDf.where(col('id') == 23126).show(1, truncate=0, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+--------------------+--------------------+\n",
      "|   id|lang|                name|featureAsDenseVector|\n",
      "+-----+----+--------------------+--------------------+\n",
      "|23126|  en|Compass - powerfu...|[0.0,0.0,0.0,0.0,...|\n",
      "+-----+----+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "23126\n",
      "en\n",
      "+-----+----+--------------------+--------------------+-----------------------------+-------------+\n",
      "|   id|lang|                name|featureAsDenseVector|oneCourseFeatureAsDenseVector|cosSimilarity|\n",
      "+-----+----+--------------------+--------------------+-----------------------------+-------------+\n",
      "| 8571|  en|Adjust the Bust: ...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8624|  en|Amigurumi: Design...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8835|  en| Artistic Digitizing|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "|  574|  en|Business Analysis...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "|  583|  en|Concepts of the H...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8544|  en|        Crazy Quilts|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8587|  en| Dot-to-Dot Quilting|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8552|  en|  Elegant Lace Cakes|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "|11701|  en|Expressive Figure...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "| 8515|  en|Family Scrapbooki...|[0.0,0.0,0.0,0.0,...|         [0.0,0.0,0.0,0.0,...|          NaN|\n",
      "+-----+----+--------------------+--------------------+-----------------------------+-------------+\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-adb9261f3825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcourses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mstrJson\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'\"'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\": ['\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mcourseIndex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcourse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcourses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "def vector_column(x): \n",
    "    return udf(lambda: x, VectorUDT())()\n",
    "\n",
    "fitPredictDataDfArray = fitPredictDataDf.where(col('id') == 23126).collect()\n",
    "fitPredictDataDf.show(1)\n",
    "\n",
    "rowIndex = 0\n",
    "strJson = '{\\n'\n",
    "\n",
    "for course in fitPredictDataDfArray:\n",
    "    courseId = course[0]\n",
    "    courseLang = course[1]\n",
    "    print(courseId)\n",
    "    print(courseLang)\n",
    "    \n",
    "    allFeatureLangDF = featuresByLang[courseLang]\n",
    "    coursesFeaturesById = fitPredictDataDf.where(col(\"id\") == courseId)\n",
    "    #allFeatureLangDF.show()\n",
    "    #coursesFeaturesById.show()\n",
    "    \n",
    "    \n",
    "    vec = DenseVector(course[3])\n",
    "    \n",
    "    df = allFeatureLangDF.where(col(\"lang\") == courseLang)\\\n",
    "        .withColumn(\"oneCourseFeatureAsDenseVector\", vector_column(vec))\n",
    "    #df.show(10)\n",
    "    #df.printSchema()\n",
    "    resultFinal = df\\\n",
    "    .withColumn(\"cosSimilarity\", calcCosUdf(df[\"oneCourseFeatureAsDenseVector\"], df[\"featureAsDenseVector\"]))\\\n",
    "    #.select(lit(courseId), col(\"id\"), col(\"name\"), col(\"cosSimilarity\"))\\\n",
    "    \n",
    "    res = resultFinal.orderBy(col(\"cosSimilarity\").desc(), col(\"name\").asc(), col(\"id\").asc())\\\n",
    "    .limit(10)\n",
    "    \n",
    "    res.show()\n",
    "    \n",
    "    courses = res.collect()\n",
    "    strJson += '\"' + str(row[0]) + '\": ['\n",
    "    courseIndex = 0\n",
    "    for course in courses:\n",
    "        courseIndex += 1\n",
    "        strJson += str(course[1])\n",
    "        if (courseIndex < len(courses)):\n",
    "            strJson += ', '\n",
    "        else:\n",
    "            strJson += ']'\n",
    "\n",
    "    if (rowIndex < len(rescaledSourceDataCollected)):\n",
    "        strJson += ', \\n'\n",
    "        \n",
    "strJson += '\\n}'\n",
    "print(strJson)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
