{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_home = '/usr/hdp/current/spark2-client'\n",
    "os.environ[\"SPARK_HOME\"]=spark_home\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]=\"--num-executors 5 --executor-cores 1 --executor-memory 5g --driver-memory 2g --conf spark.sql.broadcastTimeout=6000 --conf spark.sql.catalogImplementation=in-memory pyspark-shell\"\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application_1667306389915_1680'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "\n",
    "conf = SparkConf().set(\"spark.app.name\", \"lab03\")\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = HiveContext(sc)\n",
    "\n",
    "sc.applicationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window as W\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "to_array = F.udf(lambda v: v.toArray().tolist(), T.ArrayType(T.FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_schema = T.StructType([\n",
    "    T.StructField(\"user_id\", T.IntegerType()),\n",
    "    T.StructField(\"item_id\", T.IntegerType()),\n",
    "    T.StructField(\"purchase\", T.IntegerType())\n",
    "])\n",
    "      \n",
    "df_user_train = spark.read.option(\"header\", True).schema(user_train_schema).csv(\"/labs/slaba03/laba03_train.csv\")\n",
    "\n",
    "items_schema = T.StructType([\n",
    "    T.StructField('item_id', T.IntegerType()),\n",
    "    T.StructField('channel_id', T.IntegerType()),\n",
    "    T.StructField('datetime_availability_start', T.StringType()),\n",
    "    T.StructField('datetime_availability_stop', T.StringType()),\n",
    "    T.StructField('datetime_show_start', T.StringType()),\n",
    "    T.StructField('datetime_show_stop', T.StringType()),\n",
    "    T.StructField('content_type', T.IntegerType()),\n",
    "    T.StructField('title', T.StringType(), nullable=True),\n",
    "    T.StructField('year', T.FloatType(), nullable=True),\n",
    "    T.StructField('genres', T.StringType()),\n",
    "    T.StructField('region_id', T.IntegerType())\n",
    "])\n",
    "\n",
    "df_items = spark.read.option(\"header\", True).option(\"sep\", \"\\t\").schema(items_schema).csv(\"/labs/slaba03/laba03_items.csv\")\n",
    "\n",
    "views_schema = T.StructType([\n",
    "    T.StructField(\"user_id\", T.IntegerType()),\n",
    "    T.StructField(\"item_id\", T.IntegerType()),\n",
    "    T.StructField(\"ts_start\", T.IntegerType()),\n",
    "    T.StructField(\"ts_end\", T.IntegerType()),\n",
    "    T.StructField(\"item_type\", T.StringType())\n",
    "])\n",
    "\n",
    "df_views = spark.read.option(\"header\", True).schema(views_schema).csv(\"/labs/slaba03/laba03_views_programmes.csv\")\n",
    "\n",
    "user_test_schema = T.StructType([\n",
    "    T.StructField(\"user_id\", T.IntegerType(), True),\n",
    "    T.StructField(\"item_id\", T.IntegerType(), True)\n",
    "])\n",
    "\n",
    "df_user_test = spark.read.option(\"header\", True).schema(user_test_schema).csv(\"/labs/slaba03/laba03_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchase_sum = df_user_train.groupBy(\"user_id\").agg(F.sum(\"purchase\").alias(\"user_purchase_sum\")).cache()\n",
    "user_purchase_cnt = df_user_train.groupBy(\"user_id\").agg(F.count(\"purchase\").alias(\"user_purchase_cnt\")).cache()\n",
    "\n",
    "item_purchase_sum = df_user_train.groupBy(\"item_id\").agg(F.sum(\"purchase\").alias(\"item_purchase_sum\")).cache()\n",
    "item_purchase_cnt = df_user_train.groupBy(\"item_id\").agg(F.count(\"purchase\").alias(\"item_purchase_cnt\")).cache()\n",
    "\n",
    "train = (\n",
    "    df_user_train.join(user_purchase_sum, on=\"user_id\", how='left')\n",
    "    .join(item_purchase_sum, on=\"item_id\", how='left')\n",
    "    .join(user_purchase_cnt, on=\"user_id\", how='left')\n",
    "    .join(user_purchase_cnt, on=\"item_id\", how='left')\n",
    "    .withColumn(\"user_avg_check\", F.col(\"user_purchase_sum\") / F.col(\"user_purchase_cnt\"))\n",
    "    .withColumn(\"item_avg_check\", F.col(\"item_purchase_sum\") / F.col(\"item_purchase_cnt\"))\n",
    ")\n",
    "\n",
    "test = (\n",
    "    df_user_test.join(user_purchase_sum, on=\"user_id\", how=\"left\")\n",
    "    .join(item_purchase_sum, on=\"item_id\", how=\"left\")\n",
    "    .join(user_purchase_cnt, on=\"user_id\", how=\"left\")\n",
    "    .join(user_purchase_cnt, on=\"item_id\", how=\"left\")\n",
    "    .withColumn(\"user_avg_check\", F.col(\"user_purchase_sum\") / F.col(\"user_purchase_cnt\"))\n",
    "    .withColumn(\"item_avg_check\", F.col(\"item_purchase_sum\") / F.col(\"item_purchase_cnt\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 ms, sys: 23.5 ms, total: 48.9 ms\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cols = [\"user_purchase_sum\", \"item_purchase_sum\", \"user_avg_check\", \"item_avg_check\"]\n",
    "assembler = VectorAssembler(inputCols=cols, outputCol=\"features\")\n",
    "gbtc = GBTClassifier(labelCol=\"purchase\", maxDepth=4, minInstancesPerNode=3)\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    assembler,\n",
    "    gbtc\n",
    "])\n",
    "\n",
    "pipeline_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model.write().overwrite().save(\"tmp/lab03/pipeline_model\")\n",
    "# pipeline_model = PipelineModel.load(\"tmp/lab03/pipeline_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------------------+------------------------------+------------------------------+----------+\n",
      "|user_id|item_id|                      features|                 rawPrediction|                   probability|prediction|\n",
      "+-------+-------+------------------------------+------------------------------+------------------------------+----------+\n",
      "|   1654|  94814|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "|   1654|  93629|[5.0,4.0,0.0019470404984423...|[1.5387234865562902,-1.5387...|[0.9559528092591364,0.04404...|       0.0|\n",
      "|   1654|   9980|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "|   1654|  95099|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "|   1654|  11265|[5.0,6.0,0.0019470404984423...|[1.5365226766791593,-1.5365...|[0.9557670976884263,0.04423...|       0.0|\n",
      "|   1654|  88896|[5.0,4.0,0.0019470404984423...|[1.5387234865562902,-1.5387...|[0.9559528092591364,0.04404...|       0.0|\n",
      "|   1654|  67740|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "|   1654|  74271|[5.0,7.0,0.0019470404984423...|[1.5365226766791593,-1.5365...|[0.9557670976884263,0.04423...|       0.0|\n",
      "|   1654|  99871|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "|   1654|  78570|[5.0,1.0,0.0019470404984423...|[1.5397214895662545,-1.5397...|[0.956036778708755,0.043963...|       0.0|\n",
      "+-------+-------+------------------------------+------------------------------+------------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict = pipeline_model.transform(test)\n",
    "test_predict.select(\"user_id\", \"item_id\", \"features\", \"rawPrediction\", \"probability\", \"prediction\").show(10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = test_predict.withColumn(\"purchase\", to_array(F.col(\"probability\")).getItem(1)) \\\n",
    ".withColumn(\"\", F.row_number().over(W.orderBy(\"user_id\", \"item_id\")) - F.lit(1)).select(\"\", \"user_id\", \"item_id\", \"purchase\")\n",
    "test_target.coalesce(1).orderBy(\"user_id\", \"item_id\").write.mode(\"overwrite\").option(\"header\", True).csv(\"tmp/lab03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -f lab03.csv\n",
    "! hdfs dfs -get tmp/lab03/part-* lab03.csv\n",
    "! sed -i 's/\\\"//g' lab03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
