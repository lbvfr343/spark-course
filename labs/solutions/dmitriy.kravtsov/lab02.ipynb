{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1QefkD-2ne3"
   },
   "source": [
    "##  Лаба 2. Content-based рекомендательная система образовательных курсов – Spark Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# запускаем Спарк \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "    \n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f858d0e65f8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GaLdydKx2ne5"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "conf = SparkConf()\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"dmitriy.sokolov.slaba2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "mTvaLfH52ne6",
    "outputId": "72312f08-57ab-4391-9345-97943c1d8b03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>dmitriy.sokolov.slaba2</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f485c2fe4e0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ReRdyYn52ne6",
    "outputId": "a45df51c-0326-4d68-c458-e80c5ed1eee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vGjfXhbg2ne7"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "w9ZB0-Ql2ne7",
    "outputId": "3159da4e-5d29-480f-c547-1adc0a2c9664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "|id   |lang|\n",
      "+-----+----+\n",
      "|23126|en  |\n",
      "|21617|en  |\n",
      "|16627|es  |\n",
      "|11556|es  |\n",
      "|16704|ru  |\n",
      "|13702|ru  |\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks = spark.createDataFrame([\n",
    "    [23126, u'en'], \n",
    "    [21617, u'en'], \n",
    "    [16627, u'es'], \n",
    "    [11556, u'es'], \n",
    "    [16704, u'ru'], \n",
    "    [13702, u'ru']\n",
    "],  ['id', 'lang'])\n",
    "\n",
    "tasks.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iZv5sPCq2ne8",
    "outputId": "b1fd80ec-4fcc-4a37-fe9c-8ec65d3f866b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cat: string (nullable = true)\n",
      " |-- desc: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- provider: string (nullable = true)\n",
      "\n",
      "CPU times: user 3.68 ms, sys: 0 ns, total: 3.68 ms\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Читаем входные данные\n",
    "df = spark.read \\\n",
    "          .format(\"json\") \\\n",
    "          .option(\"sep\", \"|\") \\\n",
    "          .load(\"/labs/slaba02/DO_record_per_line.json\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u0WOBM8B2ne8",
    "outputId": "47b76798-3a76-454b-c1df-e2be8a28c4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---+----+----------------------------------------------------------------------+--------------+\n",
      "|cat                                      |desc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |id |lang|name                                                                  |provider      |\n",
      "+-----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---+----+----------------------------------------------------------------------+--------------+\n",
      "|3/business_management|6/economics_finance|This course introduces the basic financial statements used by most businesses, as well as the essential tools used to prepare them. This course will serve as a resource to help business students succeed in their upcoming university-level accounting classes, and as a refresher for upper division accounting students who are struggling to recall elementary concepts essential to more advanced accounting topics. Business owners will also benefit from this class by gaining essential skills necessary to organize and manage information pertinent to operating their business. At the conclusion of the class, students will understand the balance sheet, income statement, and cash flow statement. They will be able to differentiate between cash basis and accrual basis techniques, and know when each is appropriate. They’ll also understand the accounting equation, how to journalize and post transactions, how to adjust and close accounts, and how to prepare key financial reports. All material for this class is written and delivered by the professor, and can be previewed here. Students must have access to a spreadsheet program to participate.|4  |en  |Accounting Cycle: The Foundation of Business Measurement and Reporting|Canvas Network|\n",
      "+-----------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---+----+----------------------------------------------------------------------+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Смотрим что прочитали\n",
    "\n",
    "df.show(1, False)\n",
    "# мдя, а JupyterLab не ломает талицу, делает нормальный гориз. скроллинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bwApbBOY2ne9",
    "outputId": "926d4371-b3f5-4779-f8b6-881b5ff16df7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+--------------------+\n",
      "| id|lang|      filtered_words|\n",
      "+---+----+--------------------+\n",
      "|  4|  en|[course, introduc...|\n",
      "|  5|  en|[online, course, ...|\n",
      "|  6|  fr|[course, taught, ...|\n",
      "+---+----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "CPU times: user 124 ms, sys: 17.5 ms, total: 141 ms\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Рассчитываем TF-IDF по текстовому полю desc\n",
    "\n",
    "from pyspark.ml.feature import HashingTF, IDF, StopWordsRemover, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"desc\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "wordsData = remover.transform(wordsData)\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "    \n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "df = rescaledData\n",
    "df.cache()\n",
    "\n",
    "df.select(\"id\", \"lang\", \"filtered_words\").show(3, truncate = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pW-euEbd2ne9"
   },
   "outputs": [],
   "source": [
    "# Косинусная мера близости\n",
    "\n",
    "def cos_sim_udf(v1):   \n",
    "    def cos_sim(v2):  \n",
    "        dev = float(v1.norm(2) * v2.norm(2))\n",
    "        res = 0\n",
    "        if dev != 0:\n",
    "            res = float(v1.dot(v2)) / dev\n",
    "        return res \n",
    "    return f.udf(cos_sim, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6aFX-tXQ2ne-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 127 ms, sys: 4.53 ms, total: 132 ms\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.functions import desc\n",
    "out = {}\n",
    "\n",
    "for row in tasks.sort('id').collect():\n",
    "    id = row[0]\n",
    "    lang = row[1]\n",
    "    vector = rescaledData[rescaledData['id'] == id][['features']].collect()[0][0]\n",
    "    data = (df\n",
    "            .filter(rescaledData.lang == lang)\n",
    "            .filter(rescaledData.id != id)\n",
    "            .withColumn('dist', cos_sim_udf(vector)('features'))\n",
    "            .sort(desc('dist'), 'name', 'id')\n",
    "            .select('id')\n",
    "            .limit(10)\n",
    "            .collect()\n",
    "           )\n",
    "    out.update({str(id): [int(row.id) for row in data]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ApjfHX242ne-",
    "outputId": "5f182361-16f6-401e-ea2f-af5a89443b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"11556\": [16488, 13461, 468, 23357, 19330, 16929, 387, 10447, 11554, 9289], \"13702\": [864, 1216, 7173, 1052, 8313, 17017, 19613, 21017, 17015, 8082], \"16627\": [11431, 12247, 13021, 25010, 11575, 5687, 5372, 12863, 9598, 22680], \"16704\": [1365, 20645, 1426, 20105, 8217, 1236, 1164, 1219, 8123, 875], \"21617\": [21609, 21608, 21616, 21492, 21624, 21623, 21630, 21628, 21508, 21703], \"23126\": [13782, 13665, 24419, 20638, 2724, 25782, 2633, 2723, 13348, 15909]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "out = json.dumps(out)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SZDmZFyL2ne_"
   },
   "outputs": [],
   "source": [
    "with open('lab02.json', 'w') as file:\n",
    "    file.write(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "id": "ennypma-2ne_",
    "outputId": "9e3bce79-7196-40eb-8fee-8fbf2eb97ead"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f858d0e65f8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
