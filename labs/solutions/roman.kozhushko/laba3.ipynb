{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 2 --driver-memory 4g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"RIK_lab3\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import keyword_only\n",
    "\n",
    "from pyspark.ml import Transformer, Pipeline\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover, CountVectorizer, VectorAssembler\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier, RandomForestClassifier, MultilayerPerceptronClassifier\n",
    "    \n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, FloatType, ArrayType, StringType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import udf, col, when, isnan, isnull, broadcast, lower, pandas_udf, row_number, explode, split\n",
    "from pyspark.sql.functions import array, collect_set, collect_list, lit, asc, desc, sum, count, PandasUDFType\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors, SparseVector, DenseVector, VectorUDT\n",
    "\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -head /labs/slaba03/laba03_items.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (StructType()\n",
    "      .add(\"user_id\", IntegerType(), True)\n",
    "      .add(\"item_id\", IntegerType(), True)\n",
    "      .add(\"purchase\", IntegerType(), True))\n",
    "      \n",
    "df_user = (spark.read.format(\"csv\")\n",
    "           .option(\"header\", True)\n",
    "           .schema(schema)\n",
    "           .load(\"/labs/slaba03/laba03_train.csv\")\n",
    "           .repartition(10)\n",
    "           .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = (StructType()\n",
    "      .add(\"user_id\", IntegerType(), True)\n",
    "      .add(\"item_id\", IntegerType(), True)) \n",
    "      \n",
    "      \n",
    "df_user_test = (spark.read.format(\"csv\")\n",
    "                .option(\"header\", True)\n",
    "                .schema(schema)\n",
    "                .load(\"/labs/slaba03/laba03_test.csv\")\n",
    "                .repartition(10)\n",
    "                .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_user_test.where(df_user_test.item_id.isin(ids)).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# views_programmes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_users_schema = StructType(fields=[\n",
    "    StructField('user_id', IntegerType()),\n",
    "    StructField('item_id', IntegerType()),\n",
    "    StructField('ts_start', IntegerType()),\n",
    "    StructField('ts_end', IntegerType()),\n",
    "    StructField('item_type', StringType()),\n",
    "])\n",
    "\n",
    "df_views_programmes = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(read_users_schema) \\\n",
    "      .load(\"/labs/slaba03/laba03_views_programmes.csv\")\n",
    "\n",
    "df_views_programmes = (df_views_programmes\n",
    "                       .withColumn('duration', df_views_programmes.ts_end - df_views_programmes.ts_start)\n",
    "                       .drop('ts_start', 'ts_end'))\n",
    "\n",
    "df_views_programmes = df_views_programmes.groupby('user_id', 'item_id', 'item_type').agg(sum(\"duration\").alias(\"duration\"))\n",
    "\n",
    "df_views_programmes = df_views_programmes.repartition(10).cache()\n",
    "\n",
    "df_views_programmes.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_items_schema = StructType(fields=[\n",
    "    StructField('item_id', IntegerType()), \n",
    "    StructField('channel_id', FloatType(), nullable=True),\n",
    "    StructField('datetime_availability_start', StringType(), nullable=True),\n",
    "    StructField('datetime_availability_stop', StringType(), nullable=True),\n",
    "    StructField('datetime_show_start', StringType(), nullable=True),\n",
    "    StructField('datetime_show_stop', StringType(), nullable=True),\n",
    "    StructField('content_type', IntegerType()),\n",
    "    StructField('title', StringType(), nullable=True),\n",
    "    StructField('year', FloatType(), nullable=True),\n",
    "    StructField('genres', StringType(), nullable=True),\n",
    "    StructField('region_id', FloatType(), nullable=True),\n",
    "])\n",
    "\n",
    "df_items = (spark.read.format(\"csv\")\n",
    "            .option(\"header\", True)\n",
    "            .option(\"sep\", \"\\t\")\n",
    "            .schema(read_items_schema)\n",
    "            .load(\"/labs/slaba03/laba03_items.csv\")\n",
    "           )\n",
    "\n",
    "df_items = (df_items\n",
    "            .withColumn(\"year\", \n",
    "                        when(df_items.item_id == 103377, 2008.0)\n",
    "                        .when(df_items.item_id == 95141, 2014.0)\n",
    "                        .when(df_items.item_id == 72544, 2009.0)\n",
    "                        .when(df_items.item_id == 8544, 1994.0)\n",
    "                        .otherwise(df_items.year))\n",
    "            .withColumn(\"genres\", \n",
    "                        when(df_items.item_id == 103377, 'Анимация,Короткометражные')\n",
    "                        .otherwise(df_items.genres))\n",
    "           )\n",
    "    \n",
    "df_items = (df_items\n",
    "            .repartition(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "# print(df_items.filter(df_items.item_id.isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет фичей года выпуска для контента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = (\n",
    "    df_items\n",
    "    .withColumn(\"year_cat\", array((((df_items.year - 1910.0)/10) + 1).cast(IntegerType()).cast(StringType())))\n",
    "    .withColumn(\"year_cat_str\", (((df_items.year - 1910.0)/10) + 1).cast(IntegerType()).cast(StringType()))\n",
    ")\n",
    "\n",
    "# df_items.filter(df_items.year.isNotNull()).limit(2).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items = df_items.drop('year_cat_vector')\n",
    "count_vectorizer_year = CountVectorizer(inputCol='year_cat', outputCol=\"year_cat_vector\", binary=False)\n",
    "count_vectorizer_year_model = count_vectorizer_year.fit(df_items)\n",
    "df_items = count_vectorizer_year_model.transform(df_items)\n",
    "\n",
    "\n",
    "normalizer_year = Normalizer(inputCol='year_cat_vector', outputCol=\"year_cat_norm\")\n",
    "df_items_year = normalizer_year.transform(df_items).select('item_id', 'year_cat_norm')\n",
    "df_items = df_items.drop(\"year_cat_vector\")\n",
    "\n",
    "df_items_year.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет фичей года выпуска для клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_year = (df_user\n",
    "                .filter(df_user.purchase == 1)\n",
    "                .join(df_items, df_user.item_id == df_items.item_id, 'left')\n",
    "                .select(df_user.user_id, df_items.year_cat_str.alias(\"year_cat_str\")))\n",
    "           \n",
    "df_user_uniq = df_user.select('user_id').distinct()\n",
    "df_user_year = (df_user_uniq\n",
    "                .join(df_user_year, df_user_uniq.user_id == df_user_year.user_id, 'left')\n",
    "                .select(df_user_uniq.user_id, df_user_year.year_cat_str))\n",
    "    \n",
    "df_user_year = df_user_year.groupBy('user_id').agg(collect_set('year_cat_str').alias('year_cat'))\n",
    "df_user_year = count_vectorizer_year_model.transform(df_user_year)\n",
    "df_user_year = normalizer_year.transform(df_user_year)\n",
    "df_user_year = df_user_year.drop(\"year_cat\", \"year_cat_vector\")\n",
    "\n",
    "df_user_year.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет времени просмотра контента и пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_duration = (\n",
    "    df_views_programmes.join(df_items, df_views_programmes.item_id == df_items.item_id, 'inner')\n",
    "    .select(df_items.item_id, df_views_programmes.duration).groupby('item_id').sum(\"duration\")\n",
    "    .selectExpr([\"item_id\", \"`sum(duration)` as one_duration\"])\n",
    ")\n",
    "\n",
    "max_duration = df_item_duration.selectExpr(\"max(one_duration)\").collect()[0][0]\n",
    "\n",
    "df_item_duration = (\n",
    "    df_item_duration.select('item_id', 'one_duration', lit(max_duration).alias('max_duration'))\n",
    "    .selectExpr(['item_id', 'one_duration / max_duration as duration'])\n",
    ")\n",
    "\n",
    "df_item_duration = (df_items\n",
    "                    .join(df_item_duration, df_item_duration.item_id == df_items.item_id, 'left')\n",
    "                    .select(df_items.item_id, df_item_duration.duration)\n",
    "                    .fillna(value=0.0, subset=[\"duration\"])\n",
    "                    .distinct()\n",
    "                    .coalesce(10)\n",
    "                    .cache())\n",
    "\n",
    "# df_item_duration.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_duration = (\n",
    "    df_views_programmes.join(df_user, df_views_programmes.user_id == df_user.user_id, 'inner')\n",
    "    .select(df_user.user_id, df_views_programmes.duration).groupby('user_id').sum(\"duration\")\n",
    "    .selectExpr([\"user_id\", \"`sum(duration)` as one_duration\"])\n",
    ")\n",
    "\n",
    "max_duration = df_user_duration.selectExpr(\"max(one_duration)\").collect()[0][0]\n",
    "\n",
    "df_user_duration = (\n",
    "    df_user_duration.select('user_id', 'one_duration', lit(max_duration).alias('max_duration'))\n",
    "    .selectExpr(['user_id', 'one_duration / max_duration as duration'])\n",
    ")\n",
    "\n",
    "\n",
    "df_user_duration = (df_user\n",
    "                    .join(df_user_duration, df_user_duration.user_id == df_user.user_id, 'left')\n",
    "                    .select(df_user.user_id, df_user_duration.duration)\n",
    "                    .fillna(value=0.0, subset=[\"duration\"])\n",
    "                    .distinct()\n",
    "                    .coalesce(10)\n",
    "                    .cache())\n",
    "\n",
    "# df_user_duration.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет индекса покупаемости для контента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_item_stat = df_user.groupby(\"item_id\").agg(sum(\"purchase\").alias(\"sum_purchase\"), count(\"purchase\").alias(\"count_purchase\"))\n",
    "df_user_item_stat = df_user_item_stat.withColumn(\"item_purchase_rate\", df_user_item_stat.sum_purchase / df_user_item_stat.count_purchase)\n",
    "df_user_item_stat = df_user_item_stat.select(\"item_id\", \"item_purchase_rate\")\n",
    "\n",
    "df_user_item_stat.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет индекса покупаемости для клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_user_stat = df_user.groupby(\"user_id\").agg(sum(\"purchase\").alias(\"sum_purchase\"), count(\"purchase\").alias(\"count_purchase\"))\n",
    "df_user_user_stat = df_user_user_stat.withColumn(\"user_purchase_rate\", df_user_user_stat.sum_purchase / df_user_user_stat.count_purchase)\n",
    "df_user_user_stat = df_user_user_stat.select(\"user_id\", \"user_purchase_rate\")\n",
    "\n",
    "df_user_user_stat.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет фичей жанра для контента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_genres(s):\n",
    "    replace_map = {\n",
    "        'Арт-хаус': 'Артхаус',\n",
    "        'Боевики': 'Боевик',\n",
    "        'Военные': 'Военный',\n",
    "        'Военные': 'Военный',\n",
    "        'Детские': 'Детский',\n",
    "        'Для детей': 'Детский',\n",
    "        'Для самых маленьких': 'Детский',\n",
    "        'Для всей семьи': 'Семейные',\n",
    "        'Для взрослых': 'Эротика',\n",
    "        'Документальные': 'Документальный',\n",
    "        'Драмы': 'Драма',\n",
    "        'Западные мультфильмы': 'Зарубежные,Анимация',\n",
    "        'Исторические': 'Исторический',\n",
    "        'Короткометражки': 'Короткометражные',\n",
    "        'Детский песни': 'Детский,Музыкальные',\n",
    "        'Мультфильмы в 3D': 'Анимация',\n",
    "        'Мультфильмы': 'Анимация',\n",
    "        'Мультсериалы': 'Анимация,Сериалы',\n",
    "        'Мюзиклы': 'Музыкальные',\n",
    "        'Русские мультфильмы': 'Анимация,Русские',\n",
    "        'Аниме': 'Анимация',\n",
    "        'Спорт': 'Спортивные',\n",
    "        'Спортивныеивные': 'Спортивные',\n",
    "        'Наши': 'Русские',\n",
    "        'Фильмы в 3D': 'Фильмы',\n",
    "        'Юмористические': 'Юмористические,Передачи',\n",
    "        'Кулинария': 'Передачи',\n",
    "        'Игры': 'Передачи',\n",
    "        'О здоровье': 'Передачи',\n",
    "        'Охота и рыбалка': 'Передачи',\n",
    "        'Реалити-шоу': 'Передачи',\n",
    "        'Видеоигры': 'Видеоигры,Передачи',\n",
    "        'Фильмы-спектакли': 'Музыкальные,Фильмы',\n",
    "        'Познавательные': 'Развивающие,Передачи',\n",
    "        'Хочу всё знать': 'Развивающие,Передачи',\n",
    "        'Фантастические': 'Фантастика',\n",
    "        'Фэнтези': 'Фантастика',\n",
    "        'Союзмультфильм': 'Союзмультфильм,Анимация',\n",
    "        'Юмористические': 'Комедии',\n",
    "        'Развлекательные': 'Комедии',\n",
    "        'Комедия': 'Комедии',\n",
    "        'Вестерн': 'Фильмы,Зарубежные,Боевик',\n",
    "        'Советское кино': 'Советские,Фильмы',\n",
    "        'Прочие': 'General',\n",
    "        'Мультфильм': 'Анимация',\n",
    "        'Музыкальный': 'Музыкальные',\n",
    "        'Семейный': 'Семейные',\n",
    "        'Приключение': 'Приключения',\n",
    "        'Научная фантастика': 'Фантастика',\n",
    "        'сказка': 'Сказки',\n",
    "        'Триллер': 'Триллеры',\n",
    "    }\n",
    "    if s is None:\n",
    "        return ['General']\n",
    "    \n",
    "    for key in replace_map:\n",
    "        s = str(s).replace(key, replace_map[key])\n",
    "        \n",
    "    return s.split(',')\n",
    "\n",
    "replace_genres_udf = udf(replace_genres, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_items_genres = df_items.withColumn(\"genres_arr\", replace_genres_udf(\"genres\"))\n",
    "\n",
    "count_vectorizer = CountVectorizer(inputCol='genres_arr', outputCol=\"genres_vector\", binary=False)\n",
    "count_vectorizer_model = count_vectorizer.fit(df_items_genres)\n",
    "df_items_genres = count_vectorizer_model.transform(df_items_genres)\n",
    "\n",
    "normalizer = Normalizer(inputCol='genres_vector', outputCol=\"genres_norm\")\n",
    "df_items_genres = normalizer.transform(df_items_genres)\n",
    "\n",
    "df_items_genres = df_items_genres.select('item_id', 'genres_norm')\n",
    "\n",
    "df_items_genres.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет фичей жанра для клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_genres = (\n",
    "    df_user\n",
    "    .join(df_items, df_user.item_id == df_items.item_id, 'inner')\n",
    "    .select(\n",
    "        df_user.user_id, \n",
    "        replace_genres_udf(df_items.genres).alias(\"genres_arr\"), \n",
    "        df_user.purchase\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "df_user_genres = df_user_genres.select(\n",
    "    df_user_genres.user_id, \n",
    "    explode(df_user_genres.genres_arr).alias('genres'), \n",
    "    df_user.purchase\n",
    ")\n",
    "\n",
    "df_user_genres_all = df_user_genres.groupBy('user_id').agg(collect_list('genres').alias('genres_arr'))\n",
    "df_user_genres_all = count_vectorizer_model.transform(df_user_genres_all)\n",
    "\n",
    "df_user_genres_purchase = df_user_genres.filter(df_user.purchase == 1)\n",
    "df_user_uniq = df_user.select('user_id').distinct()\n",
    "df_user_genres_purchase = (df_user_uniq\n",
    "                .join(df_user_genres_purchase, df_user_uniq.user_id == df_user_genres_purchase.user_id, 'left')\n",
    "                .select(df_user_uniq.user_id, df_user_genres_purchase.genres))\n",
    "\n",
    "df_user_genres_purchase = (\n",
    "    df_user_genres_purchase\n",
    "    .groupBy('user_id')\n",
    "    .agg(collect_list('genres').alias('genres_arr')))\n",
    "df_user_genres_purchase = count_vectorizer_model.transform(df_user_genres_purchase)\n",
    "\n",
    "df_user_genres = df_user_genres_all.join(\n",
    "    df_user_genres_purchase,\n",
    "    df_user_genres_all.user_id == df_user_genres_purchase.user_id,\n",
    "    'inner'\n",
    ").select(\n",
    "    df_user_genres_all.user_id, \n",
    "    df_user_genres_all.genres_vector.alias('genres_vector_all'),\n",
    "    df_user_genres_purchase.genres_vector.alias('genres_vector_purchase') \n",
    ")\n",
    "\n",
    "normalizer = Normalizer(inputCol='genres_vector_all', outputCol=\"genres_norm_all\")\n",
    "df_user_genres = normalizer.transform(df_user_genres)\n",
    "\n",
    "normalizer = Normalizer(inputCol='genres_vector_purchase', outputCol=\"genres_norm_purchase\")\n",
    "df_user_genres = normalizer.transform(df_user_genres)\n",
    "\n",
    "df_user_genres.select('user_id', 'genres_norm_all', 'genres_norm_purchase').coalesce(10).cache()\n",
    "\n",
    "df_user_genres.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем набор для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_user.select(df_user.user_id, df_user.item_id, df_user.purchase.alias('target'))\n",
    "# df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи жанра\n",
    "df_train = (df_train\n",
    "            .join(df_user_genres, df_train.user_id == df_user_genres.user_id, 'inner')\n",
    "            .join(df_items_genres, df_train.item_id == df_items_genres.item_id, 'inner')\n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                \n",
    "                df_user_genres.genres_norm_all,\n",
    "                df_user_genres.genres_norm_purchase,\n",
    "                df_items_genres.genres_norm\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "# df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи покупаемости\n",
    "df_train = (df_train\n",
    "            .join(df_user_user_stat, df_user_user_stat.user_id == df_train.user_id, 'inner')\n",
    "            .join(df_user_item_stat, df_user_item_stat.item_id == df_train.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                df_train.genres_norm_all,\n",
    "                df_train.genres_norm_purchase,\n",
    "                df_train.genres_norm,\n",
    "                \n",
    "                df_user_user_stat.user_purchase_rate,\n",
    "                df_user_item_stat.item_purchase_rate,\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "# df_train.filter((df_train.user_id == 816426) & (df_train.item_id == 91200)).show()\n",
    "# df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи года выпуска\n",
    "df_train = (df_train\n",
    "            .join(df_user_year, df_user_year.user_id == df_train.user_id, 'inner')\n",
    "            .join(df_items_year, df_items_year.item_id == df_train.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                df_train.genres_norm_all,\n",
    "                df_train.genres_norm_purchase,\n",
    "                df_train.genres_norm,\n",
    "                df_train.user_purchase_rate,\n",
    "                df_train.item_purchase_rate,\n",
    "                \n",
    "                df_user_year.year_cat_norm.alias('user_year_norm'),\n",
    "                df_items_year.year_cat_norm.alias('item_year_norm')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "# df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи длительности просмотра\n",
    "df_train = (df_train\n",
    "            .join(df_user_duration, df_user_duration.user_id == df_train.user_id, 'inner')\n",
    "            .join(df_item_duration, df_item_duration.item_id == df_train.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_train.user_id,\n",
    "                df_train.item_id,\n",
    "                df_train.target,\n",
    "                df_train.genres_norm_all,\n",
    "                df_train.genres_norm_purchase,\n",
    "                df_train.genres_norm,\n",
    "                df_train.user_purchase_rate,\n",
    "                df_train.item_purchase_rate,\n",
    "                df_train.user_year_norm,\n",
    "                df_train.item_year_norm,\n",
    "                \n",
    "                df_user_duration.duration.alias('user_duration'),\n",
    "                df_item_duration.duration.alias('item_duration')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "# df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединяем все фичи\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"genres_norm_all\", \n",
    "        \"genres_norm_purchase\", \n",
    "        \"genres_norm\", \n",
    "        \"user_purchase_rate\", \"item_purchase_rate\",\n",
    "        \"user_year_norm\", \"item_year_norm\",\n",
    "        \"user_duration\", \"item_duration\"\n",
    "    ], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_train = assembler.transform(df_train).select(\"features\", \"target\")\n",
    "df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# балансируем выборку\n",
    "# print(df_train.filter(df_train.target == 0).count())\n",
    "# print(df_train.filter(df_train.target == 1).count())\n",
    "\n",
    "samle_count = df_train.filter(df_train.target == 1).count() / df_train.filter(df_train.target == 0).count()\n",
    "df_train = df_train.filter(df_train.target == 1).union(df_train.filter(df_train.target == 0).sample(samle_count)).coalesce(10)\n",
    "\n",
    "print(df_train.filter(df_train.target == 0).count())\n",
    "print(df_train.filter(df_train.target == 1).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GBTClassifier(labelCol=\"target\", featuresCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"target\", featuresCol='features', maxDepth=30, maxBins=16)\n",
    "\n",
    "gbparamGrid = (ParamGridBuilder()\n",
    "#                .addGrid(rf.maxDepth, [20, 30])\n",
    "               .addGrid(rf.numTrees, [50, 100, 150])\n",
    "#                .addGrid(rf.maxBins, [4 , 8, 16])\n",
    "\n",
    "               .build())\n",
    "\n",
    "gbevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"target\")\n",
    "\n",
    "gbcv = CrossValidator(estimator=rf,\n",
    "                      estimatorParamMaps=gbparamGrid,\n",
    "                      evaluator=gbevaluator,\n",
    "                      numFolds=5,\n",
    "                      #parallelism=2\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcvModel = gbcv.fit(df_train)\n",
    "print(gbcvModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcv.getParallelism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbcvModel.bestModel.extractParamMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol=\"target\", maxIter=30)\n",
    "lr_model = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtc = GBTClassifier(labelCol=\"target\", featuresCol='features', maxIter=15)\n",
    "gbtc_model = gbtc.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"target\", featuresCol='features', numTrees=200, maxDepth=20, maxBins=128)\n",
    "rf_model = rf.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_len = len(df_train.select('features').limit(1).collect()[0][0])\n",
    "\n",
    "mp = MultilayerPerceptronClassifier(labelCol=\"target\", featuresCol='features', maxIter=300, layers=[features_len, 200, 50, 100, 4, 2])\n",
    "mp_model = mp.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем набор для тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи жанра\n",
    "df_test = (df_test\n",
    "            .join(df_user_genres, df_test.user_id == df_user_genres.user_id, 'inner')\n",
    "            .join(df_items_genres, df_test.item_id == df_items_genres.item_id, 'inner')\n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                \n",
    "                df_user_genres.genres_norm_all,\n",
    "                df_user_genres.genres_norm_purchase,\n",
    "                df_items_genres.genres_norm\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache()\n",
    "           )\n",
    "\n",
    "# df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи покупаемости\n",
    "df_test = (df_test\n",
    "            .join(df_user_user_stat, df_user_user_stat.user_id == df_test.user_id, 'inner')\n",
    "            .join(df_user_item_stat, df_user_item_stat.item_id == df_test.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                df_test.genres_norm_all,\n",
    "                df_test.genres_norm_purchase,\n",
    "                df_test.genres_norm,\n",
    "                \n",
    "                df_user_user_stat.user_purchase_rate,\n",
    "                df_user_item_stat.item_purchase_rate,\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "# df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи года выпуска\n",
    "df_test = (df_test\n",
    "            .join(df_user_year, df_user_year.user_id == df_test.user_id, 'inner')\n",
    "            .join(df_items_year, df_items_year.item_id == df_test.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                df_test.genres_norm_all,\n",
    "                df_test.genres_norm_purchase,\n",
    "                df_test.genres_norm,\n",
    "                df_test.user_purchase_rate,\n",
    "                df_test.item_purchase_rate,\n",
    "                \n",
    "                df_user_year.year_cat_norm.alias('user_year_norm'),\n",
    "                df_items_year.year_cat_norm.alias('item_year_norm')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "# df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем фичи длительности просмотра\n",
    "df_test = (df_test\n",
    "            .join(df_user_duration, df_user_duration.user_id == df_test.user_id, 'inner')\n",
    "            .join(df_item_duration, df_item_duration.item_id == df_test.item_id, 'inner')          \n",
    "            .select(\n",
    "                df_test.user_id,\n",
    "                df_test.item_id,\n",
    "                df_test.genres_norm_all,\n",
    "                df_test.genres_norm_purchase,\n",
    "                df_test.genres_norm,\n",
    "                df_test.user_purchase_rate,\n",
    "                df_test.item_purchase_rate,\n",
    "                df_test.user_year_norm,\n",
    "                df_test.item_year_norm,\n",
    "                \n",
    "                df_user_duration.duration.alias('user_duration'),\n",
    "                df_item_duration.duration.alias('item_duration')\n",
    "            )\n",
    "            .coalesce(10)\n",
    "            .cache())\n",
    "\n",
    "# df_train.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# объединяем все фичи\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"genres_norm_all\", \n",
    "        \"genres_norm_purchase\", \n",
    "        \"genres_norm\", \n",
    "        \"user_purchase_rate\", \"item_purchase_rate\",\n",
    "        \"user_year_norm\", \"item_year_norm\",\n",
    "        \"user_duration\", \"item_duration\",\n",
    "    ], \n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_test = assembler.transform(df_test).select(\"user_id\", \"item_id\", \"features\")\n",
    "df_test.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = lr_model.transform(df_test)\n",
    "# predictions = gbtc_model.transform(df_test)\n",
    "# predictions = gbcvModel.transform(df_test)\n",
    "predictions = rf_model.transform(df_test)\n",
    "# predictions = mp_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_user_test.count())\n",
    "# print(predictions.count())\n",
    "# predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = (df_user_test\n",
    "#                 .join(predictions, \n",
    "#                       (df_user_test.user_id == predictions.user_id) & (df_user_test.item_id == predictions.item_id), \n",
    "#                       'left')\n",
    "#                 .select(df_user_test.user_id, df_user_test.item_id, predictions.prediction.alias(\"purchase\"))\n",
    "#                 .fillna(value=0.0, subset=[\"purchase\"])\n",
    "#                 .coalesce(10)\n",
    "#                 .cache()\n",
    "#                )\n",
    "\n",
    "# print(df_user_test.count())\n",
    "# print(predictions.count())\n",
    "# predictions.show(5)\n",
    "\n",
    "(\n",
    "    predictions\n",
    "    .select(predictions.user_id, predictions.item_id, predictions.prediction.alias(\"purchase\"))\n",
    "    .sort(\"user_id\", \"item_id\")\n",
    "    .toPandas()\n",
    "    .to_csv('lab03.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
