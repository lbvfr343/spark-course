{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.{SparkContext, SparkConf}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.types.StringType\n",
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "\n",
    "import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier, LogisticRegression}\n",
    "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\n",
    "import org.apache.spark.ml.linalg.Vector\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "import org.apache.spark.sql.functions.col\n",
    "import org.apache.spark.sql.types.DoubleType\n",
    "\n",
    "import org.apache.spark.ml.feature.VectorAssembler\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "\n",
    "import org.apache.hadoop.conf.Configuration\n",
    "import org.apache.hadoop.fs.{FileSystem, Path}\n",
    "import sys.process._\n",
    "\n",
    "\n",
    "//Create Hadoop Configuration from Spark\n",
    "val conf = new SparkConf().set(\"spark.driver.memory\", \"4g\")\n",
    "val sc = new SparkContext(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fs = FileSystem.get(spark.sparkContext.hadoopConfiguration)\n",
    "val result_path = new Path(\"lab05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val csvOptions = Map(\"header\" -> \"true\", \"inferSchema\" -> \"true\")\n",
    "val train = spark.read.options(csvOptions).csv(\"/labs/slaba05/lab05_train.csv\")\n",
    "val test = spark.read.options(csvOptions).csv(\"/labs/slaba05/lab05_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df : DataFrame) : DataFrame = {\n",
    "\n",
    "    val to_index_pipe_array = Array(\n",
    "        new StringIndexer().setInputCol(\"CLNT_TRUST_RELATION\").setOutputCol(\"CLNT_TRUST_RELATION_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_MARITAL_STATUS\").setOutputCol(\"APP_MARITAL_STATUS_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_KIND_OF_PROP_HABITATION\").setOutputCol(\"APP_KIND_OF_PROP_HABITATION_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"CLNT_JOB_POSITION_TYPE\").setOutputCol(\"CLNT_JOB_POSITION_TYPE_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"CLNT_JOB_POSITION\").setOutputCol(\"CLNT_JOB_POSITION_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_DRIVING_LICENSE\").setOutputCol(\"APP_DRIVING_LICENSE_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_EDUCATION\").setOutputCol(\"APP_EDUCATION_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_TRAVEL_PASS\").setOutputCol(\"APP_TRAVEL_PASS_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_CAR\").setOutputCol(\"APP_CAR_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_POSITION_TYPE\").setOutputCol(\"APP_POSITION_TYPE_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_EMP_TYPE\").setOutputCol(\"APP_EMP_TYPE_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"APP_COMP_TYPE\").setOutputCol(\"APP_COMP_TYPE_IND\").setHandleInvalid(\"keep\"),\n",
    "        new StringIndexer().setInputCol(\"PACK\").setOutputCol(\"PACK_IND\").setHandleInvalid(\"keep\")\n",
    "    )\n",
    "\n",
    "    val to_index_pipe = new Pipeline().setStages(to_index_pipe_array)\n",
    "    val to_index_pipe_model = to_index_pipe.fit(df)\n",
    "    \n",
    "    val df2 = to_index_pipe_model.transform(df)\n",
    "    \n",
    "    val df3 = df2.withColumn(\"CR_PROD_CNT_IL\",col(\"CR_PROD_CNT_IL\").cast(DoubleType))\n",
    "        .withColumn(\"CR_PROD_CNT_VCU\",col(\"CR_PROD_CNT_VCU\").cast(DoubleType))\n",
    "        .withColumn(\"CR_PROD_CNT_TOVR\",col(\"CR_PROD_CNT_TOVR\").cast(DoubleType))\n",
    "        .withColumn(\"CR_PROD_CNT_PIL\",col(\"CR_PROD_CNT_PIL\").cast(DoubleType))\n",
    "        .withColumn(\"AGE\",col(\"AGE\").cast(DoubleType))\n",
    "        .withColumn(\"CR_PROD_CNT_CC\",col(\"CR_PROD_CNT_CC\").cast(DoubleType))\n",
    "        .withColumn(\"CR_PROD_CNT_CCFP\",col(\"CR_PROD_CNT_CCFP\").cast(DoubleType))\n",
    "    \n",
    "    val col_df = df3.columns\n",
    "    val buf = collection.mutable.ArrayBuffer(col_df: _*)\n",
    "    buf --= Array(\"_c0\", \"ID\", \"CLNT_TRUST_RELATION\", \"APP_MARITAL_STATUS\", \"APP_KIND_OF_PROP_HABITATION\"\n",
    "                  , \"CLNT_JOB_POSITION_TYPE\", \"CLNT_JOB_POSITION\", \"APP_DRIVING_LICENSE\", \"APP_EDUCATION\"\n",
    "                  , \"APP_TRAVEL_PASS\", \"APP_CAR\", \"APP_POSITION_TYPE\", \"APP_EMP_TYPE\", \"APP_COMP_TYPE\", \"PACK\"\n",
    "                  , \"TARGET\")\n",
    "    val array_col = buf.toArray\n",
    "    val assembler = new VectorAssembler().\n",
    "        setInputCols(array_col).\n",
    "        setOutputCol(\"features\")\n",
    "    \n",
    "    return assembler.transform(df3.na.fill(0))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val train_faetures_non_balance = create_features(train)\n",
    "\n",
    "val sample_count = (train_faetures_non_balance.filter(col(\"TARGET\") === 1).count() + 0.0) / (train_faetures_non_balance.count() + 0.0)\n",
    "val train_faetures = train_faetures_non_balance.filter(col(\"TARGET\") === 1)\n",
    "    .union(train_faetures_non_balance.filter(col(\"TARGET\") === 0).sample(sample_count))\n",
    "\n",
    "val test_faetures = create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rf = new RandomForestClassifier()\n",
    "    .setLabelCol(\"TARGET\")\n",
    "    .setFeaturesCol(\"features\")\n",
    "    .setNumTrees(50)\n",
    "    .setMaxDepth(30)\n",
    "    .setMaxBins(64)\n",
    "\n",
    "val rfModel = rf.fit(train_faetures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val predictions = rfModel.transform(test_faetures)\n",
    "\n",
    "if(fs.exists(result_path))\n",
    "    fs.delete(result_path, true)\n",
    "\n",
    "predictions.selectExpr(\"ID as id\", \"prediction as target\")\n",
    "    .coalesce(1)\n",
    "    .write.format(\"csv\")\n",
    "    .option(\"delimiter\", \"\\t\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .save(\"from_hdfs_lab05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
