{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 1 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"Ilya_chulyukin\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover,VectorAssembler\n",
    "import pyspark.sql.functions as f_\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml import Pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter =[[23126, u'en', u'Compass - powerful SASS library that makes your life easier']\n",
    "           ,[21617, u'en', u'Preparing for the AP* Computer Science A Exam \\u2014 Part 2']\n",
    "           ,[16627, u'es', u'Aprende Excel: Nivel Intermedio by Alfonso Rinsche']\n",
    "           ,[11556, u'es', u'Aprendizaje Colaborativo by UNID Universidad Interamericana para el Desarrollo']\n",
    "           ,[16704, u'ru', u'\\u041f\\u0440\\u043e\\u0433\\u0440\\u0430\\u043c\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430\\u043d\\u0438\\u0435 \\u043d\\u0430 Lazarus']\n",
    "           ,[13702, u'ru', u'\\u041c\\u0430\\u0442\\u0435\\u043c\\u0430\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u0430\\u044f \\u044d\\u043a\\u043e\\u043d\\u043e\\u043c\\u0438\\u043a\\u0430']]\n",
    "l_parm_id=[i[0] for i in parameter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'en', 'es', 'es', 'ru', 'ru']\n"
     ]
    }
   ],
   "source": [
    "print([i[1] for i in parameter])\n",
    "# english, spanish, russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В PySpark есть специальный список стоп-слов, доступный через loadDefaultStopWords(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords =\\\n",
    "    StopWordsRemover.loadDefaultStopWords(\"english\") +\\\n",
    "    StopWordsRemover.loadDefaultStopWords(\"russian\") +\\\n",
    "    StopWordsRemover.loadDefaultStopWords(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " \"i'll\",\n",
       " \"you'll\",\n",
       " \"he'll\",\n",
       " \"she'll\",\n",
       " \"we'll\",\n",
       " \"they'll\",\n",
       " \"i'd\",\n",
       " \"you'd\",\n",
       " \"he'd\",\n",
       " \"she'd\",\n",
       " \"we'd\",\n",
       " \"they'd\",\n",
       " \"i'm\",\n",
       " \"you're\",\n",
       " \"he's\",\n",
       " \"she's\",\n",
       " \"it's\",\n",
       " \"we're\",\n",
       " \"they're\",\n",
       " \"i've\",\n",
       " \"we've\",\n",
       " \"you've\",\n",
       " \"they've\",\n",
       " \"isn't\",\n",
       " \"aren't\",\n",
       " \"wasn't\",\n",
       " \"weren't\",\n",
       " \"haven't\",\n",
       " \"hasn't\",\n",
       " \"hadn't\",\n",
       " \"don't\",\n",
       " \"doesn't\",\n",
       " \"didn't\",\n",
       " \"won't\",\n",
       " \"wouldn't\",\n",
       " \"shan't\",\n",
       " \"shouldn't\",\n",
       " \"mustn't\",\n",
       " \"can't\",\n",
       " \"couldn't\",\n",
       " 'cannot',\n",
       " 'could',\n",
       " \"here's\",\n",
       " \"how's\",\n",
       " \"let's\",\n",
       " 'ought',\n",
       " \"that's\",\n",
       " \"there's\",\n",
       " \"what's\",\n",
       " \"when's\",\n",
       " \"where's\",\n",
       " \"who's\",\n",
       " \"why's\",\n",
       " 'would',\n",
       " 'и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между',\n",
       " 'de',\n",
       " 'la',\n",
       " 'que',\n",
       " 'el',\n",
       " 'en',\n",
       " 'y',\n",
       " 'a',\n",
       " 'los',\n",
       " 'del',\n",
       " 'se',\n",
       " 'las',\n",
       " 'por',\n",
       " 'un',\n",
       " 'para',\n",
       " 'con',\n",
       " 'no',\n",
       " 'una',\n",
       " 'su',\n",
       " 'al',\n",
       " 'lo',\n",
       " 'como',\n",
       " 'más',\n",
       " 'pero',\n",
       " 'sus',\n",
       " 'le',\n",
       " 'ya',\n",
       " 'o',\n",
       " 'este',\n",
       " 'sí',\n",
       " 'porque',\n",
       " 'esta',\n",
       " 'entre',\n",
       " 'cuando',\n",
       " 'muy',\n",
       " 'sin',\n",
       " 'sobre',\n",
       " 'también',\n",
       " 'me',\n",
       " 'hasta',\n",
       " 'hay',\n",
       " 'donde',\n",
       " 'quien',\n",
       " 'desde',\n",
       " 'todo',\n",
       " 'nos',\n",
       " 'durante',\n",
       " 'todos',\n",
       " 'uno',\n",
       " 'les',\n",
       " 'ni',\n",
       " 'contra',\n",
       " 'otros',\n",
       " 'ese',\n",
       " 'eso',\n",
       " 'ante',\n",
       " 'ellos',\n",
       " 'e',\n",
       " 'esto',\n",
       " 'mí',\n",
       " 'antes',\n",
       " 'algunos',\n",
       " 'qué',\n",
       " 'unos',\n",
       " 'yo',\n",
       " 'otro',\n",
       " 'otras',\n",
       " 'otra',\n",
       " 'él',\n",
       " 'tanto',\n",
       " 'esa',\n",
       " 'estos',\n",
       " 'mucho',\n",
       " 'quienes',\n",
       " 'nada',\n",
       " 'muchos',\n",
       " 'cual',\n",
       " 'poco',\n",
       " 'ella',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'algunas',\n",
       " 'algo',\n",
       " 'nosotros',\n",
       " 'mi',\n",
       " 'mis',\n",
       " 'tú',\n",
       " 'te',\n",
       " 'ti',\n",
       " 'tu',\n",
       " 'tus',\n",
       " 'ellas',\n",
       " 'nosotras',\n",
       " 'vosostros',\n",
       " 'vosostras',\n",
       " 'os',\n",
       " 'mío',\n",
       " 'mía',\n",
       " 'míos',\n",
       " 'mías',\n",
       " 'tuyo',\n",
       " 'tuya',\n",
       " 'tuyos',\n",
       " 'tuyas',\n",
       " 'suyo',\n",
       " 'suya',\n",
       " 'suyos',\n",
       " 'suyas',\n",
       " 'nuestro',\n",
       " 'nuestra',\n",
       " 'nuestros',\n",
       " 'nuestras',\n",
       " 'vuestro',\n",
       " 'vuestra',\n",
       " 'vuestros',\n",
       " 'vuestras',\n",
       " 'esos',\n",
       " 'esas',\n",
       " 'estoy',\n",
       " 'estás',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estáis',\n",
       " 'están',\n",
       " 'esté',\n",
       " 'estés',\n",
       " 'estemos',\n",
       " 'estéis',\n",
       " 'estén',\n",
       " 'estaré',\n",
       " 'estarás',\n",
       " 'estará',\n",
       " 'estaremos',\n",
       " 'estaréis',\n",
       " 'estarán',\n",
       " 'estaría',\n",
       " 'estarías',\n",
       " 'estaríamos',\n",
       " 'estaríais',\n",
       " 'estarían',\n",
       " 'estaba',\n",
       " 'estabas',\n",
       " 'estábamos',\n",
       " 'estabais',\n",
       " 'estaban',\n",
       " 'estuve',\n",
       " 'estuviste',\n",
       " 'estuvo',\n",
       " 'estuvimos',\n",
       " 'estuvisteis',\n",
       " 'estuvieron',\n",
       " 'estuviera',\n",
       " 'estuvieras',\n",
       " 'estuviéramos',\n",
       " 'estuvierais',\n",
       " 'estuvieran',\n",
       " 'estuviese',\n",
       " 'estuvieses',\n",
       " 'estuviésemos',\n",
       " 'estuvieseis',\n",
       " 'estuviesen',\n",
       " 'estando',\n",
       " 'estado',\n",
       " 'estada',\n",
       " 'estados',\n",
       " 'estadas',\n",
       " 'estad',\n",
       " 'he',\n",
       " 'has',\n",
       " 'ha',\n",
       " 'hemos',\n",
       " 'habéis',\n",
       " 'han',\n",
       " 'haya',\n",
       " 'hayas',\n",
       " 'hayamos',\n",
       " 'hayáis',\n",
       " 'hayan',\n",
       " 'habré',\n",
       " 'habrás',\n",
       " 'habrá',\n",
       " 'habremos',\n",
       " 'habréis',\n",
       " 'habrán',\n",
       " 'habría',\n",
       " 'habrías',\n",
       " 'habríamos',\n",
       " 'habríais',\n",
       " 'habrían',\n",
       " 'había',\n",
       " 'habías',\n",
       " 'habíamos',\n",
       " 'habíais',\n",
       " 'habían',\n",
       " 'hube',\n",
       " 'hubiste',\n",
       " 'hubo',\n",
       " 'hubimos',\n",
       " 'hubisteis',\n",
       " 'hubieron',\n",
       " 'hubiera',\n",
       " 'hubieras',\n",
       " 'hubiéramos',\n",
       " 'hubierais',\n",
       " 'hubieran',\n",
       " 'hubiese',\n",
       " 'hubieses',\n",
       " 'hubiésemos',\n",
       " 'hubieseis',\n",
       " 'hubiesen',\n",
       " 'habiendo',\n",
       " 'habido',\n",
       " 'habida',\n",
       " 'habidos',\n",
       " 'habidas',\n",
       " 'soy',\n",
       " 'eres',\n",
       " 'es',\n",
       " 'somos',\n",
       " 'sois',\n",
       " 'son',\n",
       " 'sea',\n",
       " 'seas',\n",
       " 'seamos',\n",
       " 'seáis',\n",
       " 'sean',\n",
       " 'seré',\n",
       " 'serás',\n",
       " 'será',\n",
       " 'seremos',\n",
       " 'seréis',\n",
       " 'serán',\n",
       " 'sería',\n",
       " 'serías',\n",
       " 'seríamos',\n",
       " 'seríais',\n",
       " 'serían',\n",
       " 'era',\n",
       " 'eras',\n",
       " 'éramos',\n",
       " 'erais',\n",
       " 'eran',\n",
       " 'fui',\n",
       " 'fuiste',\n",
       " 'fue',\n",
       " 'fuimos',\n",
       " 'fuisteis',\n",
       " 'fueron',\n",
       " 'fuera',\n",
       " 'fueras',\n",
       " 'fuéramos',\n",
       " 'fuerais',\n",
       " 'fueran',\n",
       " 'fuese',\n",
       " 'fueses',\n",
       " 'fuésemos',\n",
       " 'fueseis',\n",
       " 'fuesen',\n",
       " 'sintiendo',\n",
       " 'sentido',\n",
       " 'sentida',\n",
       " 'sentidos',\n",
       " 'sentidas',\n",
       " 'siente',\n",
       " 'sentid',\n",
       " 'tengo',\n",
       " 'tienes',\n",
       " 'tiene',\n",
       " 'tenemos',\n",
       " 'tenéis',\n",
       " 'tienen',\n",
       " 'tenga',\n",
       " 'tengas',\n",
       " 'tengamos',\n",
       " 'tengáis',\n",
       " 'tengan',\n",
       " 'tendré',\n",
       " 'tendrás',\n",
       " 'tendrá',\n",
       " 'tendremos',\n",
       " 'tendréis',\n",
       " 'tendrán',\n",
       " 'tendría',\n",
       " 'tendrías',\n",
       " 'tendríamos',\n",
       " 'tendríais',\n",
       " 'tendrían',\n",
       " 'tenía',\n",
       " 'tenías',\n",
       " 'teníamos',\n",
       " 'teníais',\n",
       " 'tenían',\n",
       " 'tuve',\n",
       " 'tuviste',\n",
       " 'tuvo',\n",
       " 'tuvimos',\n",
       " 'tuvisteis',\n",
       " 'tuvieron',\n",
       " 'tuviera',\n",
       " 'tuvieras',\n",
       " 'tuviéramos',\n",
       " 'tuvierais',\n",
       " 'tuvieran',\n",
       " 'tuviese',\n",
       " 'tuvieses',\n",
       " 'tuviésemos',\n",
       " 'tuvieseis',\n",
       " 'tuviesen',\n",
       " 'teniendo',\n",
       " 'tenido',\n",
       " 'tenida',\n",
       " 'tenidos',\n",
       " 'tenidas',\n",
       " 'tened']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка источника\n",
    "{\n",
    "- \"lang\": \"en\",\n",
    "- \"name\": \"Accounting Cycle: The Foundation of Business Measurement and Reporting\",\n",
    "- \"cat\": \"3/business_management|6/economics_finance\",\n",
    "- \"provider\": \"Canvas Network\",\n",
    "- \"id\": 4,\n",
    "- \"desc\": \"This course introduces the basic financial statements used by most businesses, as well as the essential tools used to prepare them. This course will serve as a resource to help business students succeed in their upcoming university-level accounting classes, and as a refresher for upper division accounting students who are struggling to recall elementary concepts essential to more advanced accounting topics. Business owners will also benefit from this class by gaining essential skills necessary to organize and manage information pertinent to operating their business. At the conclusion of the class, students will understand the balance sheet, income statement, and cash flow statement. They will be able to differentiate between cash basis and accrual basis techniques, and know when each is appropriate. They\\u2019ll also understand the accounting equation, how to journalize and post transactions, how to adjust and close accounts, and how to prepare key financial reports. All material for this class is written and delivered by the professor, and can be previewed here. Students must have access to a spreadsheet program to participate.\"  \n",
    "}  \n",
    "\n",
    "Интересует id, lang и desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\p{Prop}  Match a character that has the given Unicode property.  \n",
    "\\p{L} matches a single code point in the category \"letter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Источник\n",
    "source = spark.read.json('/labs/slaba02/DO_record_per_line.json')\n",
    "courses = source.select(\"id\", \"lang\"\n",
    "                  ,f_.lower(f_.regexp_replace('desc',r'[^\\pL{0-9}\\p{Space}]','' )).alias('document'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE\n",
    "- разделить на слова\n",
    "- убрать стоп слова\n",
    "- посчитать TF — term frequency: по сути, сколько раз слово встречается в этом документе.\n",
    "- посчитать DF – document frequency: по сути, число документов, в которых есть вхождение этого слова. Мы хотим \"штрафовать\" слово за частое появление в документах, поэтому делаем инверсию этой величины – буква I в TFIDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = Tokenizer(inputCol=\"document\", outputCol=\"words\")\n",
    "stopwordsremove = StopWordsRemover(inputCol=\"words\", outputCol=\"words_removed\", stopWords=stopwords)\n",
    "tf_metric = HashingTF(inputCol=\"words_removed\", outputCol=\"tf\")\n",
    "tfidf_metric = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "pipeline = Pipeline(stages=[\n",
    "    tokenize,\n",
    "    stopwordsremove,\n",
    "    tf_metric,\n",
    "    tfidf_metric\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = pipeline.fit(courses)\n",
    "tfidf_return = fitted.transform(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('lang', 'string'),\n",
       " ('document', 'string'),\n",
       " ('words', 'array<string>'),\n",
       " ('words_removed', 'array<string>'),\n",
       " ('tf', 'vector'),\n",
       " ('tfidf', 'vector')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_return.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crossJoin  параметра и всех описаний\n",
    "Присоединяем параметр к документам с учетом языка, при этом искючаем сами параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_tfidf =  tfidf_return.where(f_.col('id').isin(l_parm_id))\\\n",
    "                         .select(f_.col('id').alias('par_id')\n",
    "                                ,f_.col('lang')\n",
    "                                ,f_.col('tfidf').alias('par_tfidf')\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataFrame - параметр\n",
    "cross_matrix = tfidf_return.join(par_tfidf, \"lang\", \"inner\").where('''par_id !=id ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54310"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_matrix.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lang: string, id: bigint, document: string, words: array<string>, words_removed: array<string>, tf: vector, tfidf: vector, par_id: bigint, par_tfidf: vector]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Косинус векторов \n",
    "Умножаем один вектор на другой и делим на произведение их длин. \n",
    "- Вектор точка продукта: матричное умножение векторов (dot)\n",
    "- для подсчета нормы векторов: сумма квадратов компонент (norm_type = 2)  \n",
    "\n",
    "Чем больше косинус, тем лучше  \n",
    "И нам нужно только 10 курсов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF cosinus\n",
    "@f_.udf(FloatType())\n",
    "def cos_sim(vector_a,vector_b):\n",
    "    return float(vector_a.dot(vector_b) / (vector_a.norm(2) * vector_b.norm(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_matrix = cross_matrix\\\n",
    "            .select('*', cos_sim('tfidf','par_tfidf').alias('v_cos'))\\\n",
    "            .where(\"v_cos !='NaN'\")\\\n",
    "            .select('*'\n",
    "                   ,f_.row_number().over(Window.partitionBy(\"par_id\")\\\n",
    "                                                .orderBy(f_.col('v_cos').desc(),f_.col('id'))).alias('rn'))\\\n",
    "            .where(\"rn <= 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomended = cosine_matrix.groupBy(f_.col('par_id')).agg(f_.collect_list(f_.col('id')).alias('array_10'))\\\n",
    "                          .orderBy('par_id').collect()\n",
    "recomended_json ={}\n",
    "for i in recomended: recomended_json[str(i[0])]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('11556', [16488, 468, 13461, 22710, 23357, 10447, 19330, 21707, 11523, 9465]), ('13702', [864, 21079, 8123, 1041, 28074, 13057, 1396, 1052, 1033, 8300]), ('16627', [11431, 12247, 12660, 5687, 17964, 16694, 12598, 11575, 12863, 21704]), ('16704', [1236, 1247, 1228, 1365, 1164, 1233, 1273, 20288, 8186, 8203]), ('21617', [21609, 21608, 21616, 21492, 21624, 21623, 21703, 21630, 21628, 21508]), ('23126', [14760, 13665, 13782, 15909, 19270, 25782, 17499, 13348, 7153, 25071])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomended_json.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11556', [16488, 468, 13461, 22710, 23357, 10447, 19330, 21707, 11523, 9465])\n",
      "('13702', [864, 21079, 8123, 1041, 28074, 13057, 1396, 1052, 1033, 8300])\n",
      "('16627', [11431, 12247, 12660, 5687, 17964, 16694, 12598, 11575, 12863, 21704])\n",
      "('16704', [1236, 1247, 1228, 1365, 1164, 1233, 1273, 20288, 8186, 8203])\n",
      "('21617', [21609, 21608, 21616, 21492, 21624, 21623, 21703, 21630, 21628, 21508])\n",
      "('23126', [14760, 13665, 13782, 15909, 19270, 25782, 17499, 13348, 7153, 25071])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i) for i in recomended_json.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lab02.json', 'w') as fp:\n",
    "    json.dump(recomended_json, fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "11556 : [16488, 468, 13461, 22710, 23357, 10447, 19330, 21707, 11523, 9465]\n",
    "13702 : [864, 21079, 8123, 1041, 28074, 13057, 1396, 1052, 1033, 8300]\n",
    "16627 : [11431, 12247, 12660, 5687, 17964, 16694, 12598, 11575, 12863, 21704]\n",
    "16704 : [1236, 1247, 1228, 1365, 1164, 1233, 1273, 20288, 8186, 8203]\n",
    "21617 : [21609, 21608, 21616, 21492, 21624, 21623, 21703, 21630, 21628, 21508]\n",
    "23126 : [14760, 13665, 13782, 15909, 19270, 25782, 17499, 13348, 7153, 25071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
