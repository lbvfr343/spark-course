{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 5 --executor-memory 4g --executor-cores 1 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"ilchulyukin_laba3\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4047\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ilchulyukin_laba3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=ilchulyukin_laba3>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import SparseVector, DenseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover, CountVectorizer,StringIndexer,OneHotEncoder\n",
    "import pyspark.sql.functions as f_\n",
    "from pyspark.sql.types import FloatType, StructType, StructField, IntegerType, StringType, ArrayType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml import Pipeline\n",
    "import json\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение источников\n",
    "- laba03_train.csv - содержатся факты покупки (колонка purchase) пользователями (колонка user_id) телепередач (колонка item_id). \n",
    "- laba03_test.csv — тестовый датасет без указанного целевого признака purchase, который вам и предстоит предсказать.\n",
    "- laba03_items.csv — дополнительные данные по items. В данном файле много лишней или ненужной информации, так что задача её фильтрации и отбора ложится на вас.\n",
    "- laba03_views_programmes.csv - Дополнительный файл по просмотрам передач "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = StructType([StructField('user_id',StringType(),True)\n",
    "               ,StructField('item_id',StringType(),True)\n",
    "               ,StructField('purchase',IntegerType(),True)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5032624\n",
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  74107|       0|\n",
      "|   1654|  89249|       0|\n",
      "|   1654|  99982|       0|\n",
      "|   1654|  89901|       0|\n",
      "|   1654| 100504|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-------+\n",
      "|purchase|  count|\n",
      "+--------+-------+\n",
      "|       1|  10904|\n",
      "|       0|5021720|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_csv = spark.read.csv('/labs/slaba03/laba03_train.csv', s, sep = \",\", header = True)\n",
    "print(train_csv.count())\n",
    "train_csv.show(5)\n",
    "# Распределение по целевой переменной\n",
    "train_csv.groupBy(\"purchase\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156840\n",
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  94814|    null|\n",
      "|   1654|  93629|    null|\n",
      "|   1654|   9980|    null|\n",
      "|   1654|  95099|    null|\n",
      "|   1654|  11265|    null|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_csv  = spark.read.csv('/labs/slaba03/laba03_test.csv', s, sep = \",\", header = True)\n",
    "print(test_csv.count())\n",
    "test_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### laba03_items.csv — дополнительные данные по items.\n",
    "Поля в файле, на которых хотелось бы остановиться:\n",
    "- item_id — primary key. Соответствует item_id в предыдущем файле.\n",
    "- content_type — тип телепередачи (1 — платная, 0 — бесплатная). Вас интересуют платные передачи.\n",
    "- title — название передачи, текстовое поле.\n",
    "- year — год выпуска передачи, число.\n",
    "- genres — поле с жанрами передачи, разделёнными через запятую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635568\n",
      "+-------+------------+--------------------+----+-------+--------+\n",
      "|item_id|content_type|               title|year| genres|year_grp|\n",
      "+-------+------------+--------------------+----+-------+--------+\n",
      "|  65667|           1|на пробах только ...|2013|Эротика|    2010|\n",
      "|  65669|           1|скуби ду эротичес...|2011|Эротика|    2010|\n",
      "|  65668|           1|горячие девочки д...|2011|Эротика|    2010|\n",
      "|  65671|           1|соблазнительницы ...|2011|Эротика|    2010|\n",
      "|  65670|           1|секретные сексмат...|2010|Эротика|    2010|\n",
      "+-------+------------+--------------------+----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_csv = spark.read.csv('/labs/slaba03/laba03_items.csv', sep=\"\\t\", header = True)\\\n",
    "                 .select('item_id'\n",
    "                        ,'content_type'\n",
    "                        ,f_.regexp_replace('title',r'[^\\pL0-9\\p{Space}]','' ).alias('title')\n",
    "                        ,f_.coalesce(f_.col('year'),f_.lit(0)).cast('Integer').alias('year')\n",
    "                        ,f_.coalesce(f_.regexp_replace(\n",
    "                                f_.regexp_replace(\n",
    "                                    f_.regexp_replace(f_.col('genres'), r'[^\\pL0-9,\\p{Space}]','')\n",
    "                                        ,' ','_')\n",
    "                                            ,',',' '),f_.lit('n/a')).alias('genres')\n",
    "\n",
    "\n",
    "                        )\\\n",
    "                    .select(\"*\"\n",
    "                    ,f_.when(f_.col('year') <= f_.lit(1964), f_.lit(1964))\\\n",
    "                       .when((f_.col('year') >= f_.lit(1965))&(f_.col('year') <= f_.lit(1975)), f_.lit(1975))\\\n",
    "                       .when((f_.col('year') >= f_.lit(1976))&(f_.col('year') <= f_.lit(1985)), f_.lit(1985))\\\n",
    "                       .when((f_.col('year') >= f_.lit(1986))&(f_.col('year') <= f_.lit(1996)), f_.lit(1996))\\\n",
    "                       .when((f_.col('year') >= f_.lit(1997))&(f_.col('year') <= f_.lit(2004)), f_.lit(2004))\\\n",
    "                       .when((f_.col('year') >= f_.lit(2005))&(f_.col('year') <= f_.lit(2008)), f_.lit(2008))\\\n",
    "                       .when((f_.col('year') >= f_.lit(2006))&(f_.col('year') <= f_.lit(2010)), f_.lit(2010))\\\n",
    "                              .otherwise(f_.round(f_.col('year').cast('integer'),-1)).alias('year_grp')\n",
    "                           )\n",
    "\n",
    "\n",
    "print(items_csv.count())\n",
    "items_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### laba03_views_programmes.csv — Дополнительный файл по просмотрам передач \n",
    " ... с полями::\n",
    "- ts_start — время начала просмотра.\n",
    "- ts_end — время окончания просмотра.\n",
    "- item_type — тип просматриваемого контента:\n",
    "        live — просмотр \"вживую\", в момент показа контента в эфире.\n",
    "        pvr — просмотр в записи, после показа контента в эфире."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20845607\n",
      "+-------+-------+----------+----------+---------+\n",
      "|user_id|item_id|  ts_start|    ts_end|item_type|\n",
      "+-------+-------+----------+----------+---------+\n",
      "|      0|7101053|1491409931|1491411600|     live|\n",
      "|      0|7101054|1491412481|1491451571|     live|\n",
      "|      0|7101054|1491411640|1491412481|     live|\n",
      "|      0|6184414|1486191290|1486191640|     live|\n",
      "|    257|4436877|1490628499|1490630256|     live|\n",
      "+-------+-------+----------+----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "views_programmes_csv = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', sep=\",\", header = True)\n",
    "print(views_programmes_csv.count())\n",
    "views_programmes_csv.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### item_id из items_csv нужны только те, которые есть в tran или test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3704\n",
      "+-------+------------+-------------------+----+--------------------+--------+\n",
      "|item_id|content_type|              title|year|              genres|year_grp|\n",
      "+-------+------------+-------------------+----+--------------------+--------+\n",
      "| 100140|           1|            поездка|2014|             Комедии|    2010|\n",
      "| 100263|           1|          фортитьюд|2015|Ужасы Детективы Т...|    2020|\n",
      "| 100735|           1|сенлоран стиль этоя|2014|Артхаус Драмы Мел...|    2010|\n",
      "|   1159|           1|              залив|2012|Ужасы Триллеры Фа...|    2010|\n",
      "|   2136|           1|          проклятая|2009|Ужасы Триллеры За...|    2010|\n",
      "+-------+------------+-------------------+----+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|               title|count|\n",
      "+--------------------+-----+\n",
      "|гидра затерянный ...|    1|\n",
      "|              риф 3d|    3|\n",
      "|   храбрый портняжка|    1|\n",
      "|            не горюй|    1|\n",
      "|      волшебная сила|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|              genres|count|\n",
      "+--------------------+-----+\n",
      "|Фантастика Боевик...|   27|\n",
      "|Приключения Комед...|   11|\n",
      "|               Ужасы|    5|\n",
      "|Военные Драмы Ист...|    2|\n",
      "|Комедии Советское...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+-----+\n",
      "|year_grp|count|\n",
      "+--------+-----+\n",
      "|    1964|  130|\n",
      "|    1975|  183|\n",
      "|    1985|  193|\n",
      "|    1996|  119|\n",
      "|    2004|  182|\n",
      "|    2008|  427|\n",
      "|    2010| 1751|\n",
      "|    2020|  719|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items_cache = train_csv.select('item_id').union(test_csv.select('item_id')).distinct()\\\n",
    "                       .join(items_csv,['item_id'],'left').cache()\n",
    "print(items_cache.count())\n",
    "items_cache.show(5)\n",
    "items_cache.groupBy(\"title\").count().show(5)\n",
    "items_cache.groupBy(\"genres\").count().show(5)\n",
    "items_cache.groupBy('year_grp').count().orderBy('year_grp').show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи User_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ = train_csv.join(items_cache.select(\"item_id\", \"title\", \"year\", \"genres\", \"year_grp\"),[\"item_id\"], \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5032624"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_.select(\"user_id\",\"item_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Программы\n",
    "- количество предложенных программ пользователю\n",
    "- количество купленных пользователем программ\n",
    "- доля купленных программ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_progs = user_.groupBy(\"user_id\").agg(\n",
    "                                          f_.count(\"item_id\").alias(\"user_items_cnt\")\n",
    "                                         ,f_.sum(\"purchase\").alias(\"purchase_user_items_cnt\")\n",
    "                                         ,(f_.sum(\"purchase\")/f_.count(\"item_id\")).alias(\"user_rate\")\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Жанры\n",
    "- genres_buy_cnt - количество купленных пользователем жанров\n",
    "- top_3_genres_buy_txt -  top 3 купленных жанров\n",
    "- genre - все жанры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_token = Tokenizer(inputCol = \"genres\", outputCol = \"genre\").transform(user_)\n",
    "\n",
    "user_genre_ = genre_token\\\n",
    "   .select(\"user_id\", f_.explode(\"genre\").alias(\"genres\"), \"genre\", \"purchase\")\\\n",
    "   .groupBy(\"user_id\", \"genres\").agg(f_.count(\"*\").alias(\"genre_count\")\n",
    "                                    ,f_.sum(\"purchase\").alias(\"genre_buy_count\")\n",
    "                                    ,f_.max(\"genre\").alias(\"genre\")\n",
    "                                     )\\\n",
    "   .select(\"user_id\", \"genres\", \"genre\"\n",
    "          ,f_.sum(f_.col(\"genre_buy_count\")).over(Window.partitionBy(\"user_id\")).alias(\"genres_buy_cnt\")\n",
    "           \n",
    "          ,f_.row_number().over(Window.partitionBy(\"user_id\")\\\n",
    "                                .orderBy(f_.col(\"genre_count\").cast(\"Integer\").desc())).alias(\"genres_rn\")\n",
    "          ,f_.row_number().over(Window.partitionBy(\"user_id\")\\\n",
    "                                .orderBy(f_.col(\"genre_buy_count\").cast(\"Integer\").desc())).alias(\"genres_buy_rn\")\n",
    "                 )\n",
    "\n",
    "user_genre_buy = user_genre_.where(\"genres_buy_rn < 4\")\\\n",
    "                        .groupBy(\"user_id\").agg(f_.max(\"genre\").alias(\"genre\")\n",
    "                                               ,f_.max(\"genres_buy_cnt\").alias(\"genres_buy_cnt\")\n",
    "                                               ,f_.collect_set(\"genres\").alias(\"top_3_genres_buy_txt\")\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ftr = user_progs.join(user_genre_buy, [\"user_id\"], \"left\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ftr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+\n",
      "|user_id|user_items_cnt|purchase_user_items_cnt|           user_rate|               genre|genres_buy_cnt|top_3_genres_buy_txt|\n",
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+\n",
      "| 867363|          2569|                      1|3.892565200467107...|[фильмы, фантасти...|             4|[мистические, фан...|\n",
      "| 882935|          2585|                      2|7.736943907156673E-4|[эротика, триллер...|             5|[зарубежные, дете...|\n",
      "| 889974|          2548|                      0|                 0.0|[русские_мультфил...|             0|[полнометражные, ...|\n",
      "| 891250|          2624|                      0|                 0.0|[фильмы, фантасти...|             0|[фантастика, дете...|\n",
      "| 902451|          2600|                      1|3.846153846153846E-4|[эротика, комедии...|             2|[драмы, военные, ...|\n",
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_ftr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_buy_conv = CountVectorizer(inputCol = \"top_3_genres_buy_txt\", outputCol = \"top_3_genres_buy_v\", binary = True)\n",
    "genre_conv = CountVectorizer(inputCol = \"genre\", outputCol = \"genres_v\", binary = True)\n",
    "user_features = Pipeline(\n",
    "                    stages=[genre_buy_conv, genre_conv] \n",
    "                        )\n",
    "\n",
    "user_features_final =user_features.fit(user_ftr).transform(user_ftr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'user_items_cnt',\n",
       " 'purchase_user_items_cnt',\n",
       " 'user_rate',\n",
       " 'genre',\n",
       " 'genres_buy_cnt',\n",
       " 'top_3_genres_buy_txt',\n",
       " 'top_3_genres_buy_v',\n",
       " 'genres_v']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|user_id|user_items_cnt|purchase_user_items_cnt|           user_rate|               genre|genres_buy_cnt|top_3_genres_buy_txt|  top_3_genres_buy_v|            genres_v|\n",
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "| 867363|          2569|                      1|3.892565200467107...|[фильмы, фантасти...|             4|[мистические, фан...|(83,[14,15,32],[1...|(74,[0,10,18],[1....|\n",
      "| 882935|          2585|                      2|7.736943907156673E-4|[эротика, триллер...|             5|[зарубежные, дете...|(83,[0,4,18],[1.0...|(74,[0,1,2,3],[1....|\n",
      "| 889974|          2548|                      0|                 0.0|[русские_мультфил...|             0|[полнометражные, ...|(83,[11,13,72],[1...|(74,[8,9,22,26,29...|\n",
      "| 891250|          2624|                      0|                 0.0|[фильмы, фантасти...|             0|[фантастика, дете...|(83,[15,18,39],[1...|(74,[0,10,18],[1....|\n",
      "| 902451|          2600|                      1|3.846153846153846E-4|[эротика, комедии...|             2|[драмы, военные, ...|(83,[1,24,25],[1....|(74,[0,1,4,6,12],...|\n",
      "+-------+--------------+-----------------------+--------------------+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_features_final.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Фичи  Items\n",
    "- группы годов выпуска программ\n",
    "    - StringIndexer - индексация строк по количеству вхождений\n",
    "    - OneHotEncoder - векторизация категорий (индексов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PySpark есть специальный список стоп-слов, доступный через loadDefaultStopWords(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_cache.where(\"genres is null\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['item_id', 'content_type', 'title', 'year', 'genres', 'year_grp']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_cache.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Год выпуска\n",
    "year_group_index  = StringIndexer(inputCol = \"year_grp\", outputCol = \"yearIndex\")\n",
    "year_group_vector = OneHotEncoder(inputCol = \"yearIndex\", outputCol = \"year_group_v\")\n",
    "\n",
    "transform_features_pipeline = Pipeline(\n",
    "                    stages=[\n",
    "                            year_group_index,\n",
    "                            year_group_vector\n",
    "                           ] \n",
    "                                )\n",
    "transform_features_pipeline_models = transform_features_pipeline.fit(items_cache)                                               \n",
    "item_data = transform_features_pipeline_models.transform(items_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_csv.join(item_data,['item_id'],'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5032624"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select(\"user_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Покупательный рейтинг фильма\n",
    "item_rate = train.groupBy('item_id')\\\n",
    "                 .agg(f_.sum(f_.col('purchase')).alias('item_buy')\n",
    "                     ,(f_.sum(f_.col('purchase').cast('integer'))/f_.count('*')).alias('item_rate')\n",
    "                            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рейтинг просмотров зрителя\n",
    "user_views= views_programmes_csv.join(items_cache.select('item_id','content_type'),['item_id'],'left')\\\n",
    "        .select('*', (f_.col('ts_end')-f_.col('ts_start')).alias('time'))\\\n",
    "        .groupBy('user_id')\\\n",
    "        .agg( f_.count('*').alias('views_cnt')\n",
    "             ,f_.avg(f_.col('time')).alias('views_avg_time')\n",
    "             ,f_.sum(f_.when(f_.col('item_type')==f_.lit('live'),f_.lit(1)).otherwise(f_.lit(0))\n",
    "                    ).alias('views_live_cnt')\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+---------+\n",
      "|item_id|user_id|  ts_start|    ts_end|item_type|\n",
      "+-------+-------+----------+----------+---------+\n",
      "|7101053|      0|1491409931|1491411600|     live|\n",
      "|7101054|      0|1491412481|1491451571|     live|\n",
      "|7101054|      0|1491411640|1491412481|     live|\n",
      "|6184414|      0|1486191290|1486191640|     live|\n",
      "|4436877|    257|1490628499|1490630256|     live|\n",
      "|7489015|   1654|1493434801|1493435401|     live|\n",
      "|7489023|   1654|1493444101|1493445601|     live|\n",
      "|6617053|   1654|1489186156|1489200834|     live|\n",
      "|6438693|   1654|1487840070|1487840433|     live|\n",
      "|6526859|   1654|1488705452|1488706154|     live|\n",
      "|6526754|   1654|1488532396|1488532895|      pvr|\n",
      "|6239098|   1654|1486732011|1486732410|     live|\n",
      "|6438763|   1654|1488305761|1488307286|      pvr|\n",
      "|7489013|   1654|1493433301|1493434201|     live|\n",
      "|6317094|   1654|1486829784|1486830389|     live|\n",
      "+-------+-------+----------+----------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "views_programmes_csv.join(items_cache.select('item_id'),['item_id'],'left').show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id', 'item_id', 'ts_start', 'ts_end', 'item_type']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views_programmes_csv.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фичи  short list\n",
    " - purchase_user_items_cnt - количество купленных программ пользователем\n",
    " - item_buy - количество пользователей, купивших программу\n",
    " - user_rate - рейтинг покупок пользователя\n",
    " - item_rate - рейтинг покупаемости прграммы \n",
    " - genres_buy_cnt - количество жанров, купленных пользователем\n",
    " - top_3_genres_buy_v - TOP 3 жанра, купленных пользователем\n",
    " - genres_v - все жанры, купленные пользователем\n",
    " - year_group_v - группа года выпуска программы \n",
    " - views_avg_time - среднее время просмотра программ пользователем\n",
    " - views_live_cnt - количество просмотров пользователем программ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr_short_list=[\n",
    " \"purchase_user_items_cnt\"\n",
    ",\"item_buy\"\n",
    ",'user_rate'\n",
    ",'item_rate'  \n",
    ",'genres_buy_cnt'\n",
    ",'top_3_genres_buy_v'\n",
    ",'genres_v'\n",
    ",'year_group_v'\n",
    "    \n",
    ",'views_avg_time'\n",
    ",'views_live_cnt'             ]\n",
    "assembler = VectorAssembler(inputCols = ftr_short_list, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.95 ms, sys: 0 ns, total: 7.95 ms\n",
      "Wall time: 93.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data_ = train.alias('t')\\\n",
    "    .join(user_features_final.alias(\"f\"),['user_id'],'left')\\\n",
    "    .join(item_rate.alias('r'),['item_id'],'left')\\\n",
    "    .join(user_views.alias('v'),['user_id'],'left')\\\n",
    "    .fillna( { \n",
    "                'views_avg_time':0,\n",
    "                'views_live_cnt':0\n",
    "                    } )\n",
    "train_data=assembler.transform(train_data_)\\\n",
    "    .select('user_id','item_id',f_.col('purchase').cast('integer').alias('purchase'),'features')\\\n",
    "        .repartition(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted tmp_data_lab03\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r -skipTrash tmp_data_lab03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.57 ms, sys: 777 µs, total: 10.3 ms\n",
      "Wall time: 56.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data.write.parquet('tmp_data_lab03',mode = 'overwrite')\n",
    "train_data = spark.read.parquet('tmp_data_lab03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_data.sampleBy(\"purchase\", fractions = {0: 0.8, 1: 0.8}, seed = 1868)\n",
    "valid_sample = train_data.join(train_sample, on=[\"item_id\",'user_id'], how = \"leftanti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9117878371015103 0.9190757313103809\n",
      "CPU times: user 33.6 ms, sys: 4.26 ms, total: 37.9 ms\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"probability\", labelCol=\"purchase\"\n",
    "                                         ,metricName = 'areaUnderROC')\n",
    "logreg = LogisticRegression(featuresCol = 'features', labelCol = \"purchase\", maxIter = 130, regParam = 0.05)\n",
    "logreg_model = logreg.fit(train_sample)\n",
    "predictions_v = logreg_model.transform(valid_sample)\n",
    "predictions_t = logreg_model.transform(train_sample)\n",
    "roc_v = evaluator.evaluate(predictions_v)\n",
    "roc_t = evaluator.evaluate(predictions_t)\n",
    "print(roc_v, roc_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['purchase_user_items_cnt', 'item_buy', 'user_rate', 'item_rate', 'genres_buy_cnt', 'top_3_genres_buy_v', 'genres_v', 'year_group_v', 'views_avg_time', 'views_live_cnt'] 0.9190757313103809 (130 / 0.05)  \n"
     ]
    }
   ],
   "source": [
    "print(ftr_short_list, roc_t, '(130 / 0.05)', ' ')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['purchase_user_items_cnt', 'item_buy', 'user_rate', 'item_rate', 'genres_buy_cnt', 'top_3_genres_buy_v', 'genres_cat', 'year_group_cat', 'views_avg_time', 'views_live_cnt', 'user_buy_view_rate', 'idf_title'] 0.9218055825758888 (130 / 0.05)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9219773846198998\n",
      "CPU times: user 36.6 ms, sys: 27.7 ms, total: 64.3 ms\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol = \"probability\", labelCol = \"purchase\"\n",
    "                                         ,metricName = 'areaUnderROC')\n",
    "gbt = GBTClassifier(featuresCol = 'features'\n",
    "                   ,labelCol = \"purchase\", maxDepth = 4, maxBins = 50, minInstancesPerNode = 3)\n",
    "gbt_model = gbt.fit(train_sample)\n",
    "predictions_ = gbt_model.transform(valid_sample)\n",
    "roc_= evaluator.evaluate(predictions_)\n",
    "print(roc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_ = test_csv.join(item_data,['item_id'],'left').alias('t')\\\n",
    "    .join(user_features_final.alias(\"f\"),['user_id'],'left')\\\n",
    "    .join(item_rate.alias('i'),['item_id'],'left')\\\n",
    "    .join(user_views.alias('v'),['user_id'],'left')\\\n",
    "    .fillna( { \n",
    "                'views_avg_time':0,\n",
    "                'views_live_cnt':0                    } )\n",
    "test_data = assembler.transform(test_data_)\\\n",
    "                     .select('user_id','item_id',f_.col('purchase').cast('integer').alias('purchase'),'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+--------------------+\n",
      "|user_id|item_id|purchase|            features|\n",
      "+-------+-------+--------+--------------------+\n",
      "| 867363| 100263|    null|(171,[0,1,2,3,4,1...|\n",
      "| 867363| 100735|    null|(171,[0,1,2,3,4,1...|\n",
      "| 867363|   1159|    null|(171,[0,1,2,3,4,1...|\n",
      "| 867363|  74605|    null|(171,[0,2,4,19,20...|\n",
      "| 867363|  81824|    null|(171,[0,1,2,3,4,1...|\n",
      "+-------+-------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxDepth, [3, 4, 5])\\\n",
    "                              .addGrid(gbt.minInstancesPerNode, [2, 3, 4])\\\n",
    "                              .addGrid(gbt.maxBins, [50, 55])\\\n",
    "                              .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted test_data_lab03\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r -skipTrash test_data_lab03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2156840 2156840\n",
      "CPU times: user 3.56 ms, sys: 7.42 ms, total: 11 ms\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_data.write.parquet('test_data_lab03',mode='overwrite')\n",
    "test_data = spark.read.parquet('test_data_lab03')\n",
    "print(test_csv.count(),test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "@f_.udf(ArrayType(FloatType()))\n",
    "def vector_to_list(v):\n",
    "    return v.toArray().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_logreg = logreg_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = predictions_logreg\\\n",
    "    .select('user_id','item_id', vector_to_list('probability').getItem(1).alias('purchase'))\\\n",
    "    .orderBy(f_.col('user_id').asc(),f_.col('item_id').cast(\"Integer\").asc()).coalesce(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gbt = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = predictions_gbt\\\n",
    "    .select('user_id','item_id', vector_to_list('probability').getItem(1).alias('purchase'))\\\n",
    "    .orderBy(f_.col('user_id').asc(),f_.col('item_id').cast(\"Integer\").asc()).coalesce(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "+-------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_.where(\"purchase = 'NaN'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.34 ms, sys: 787 µs, total: 9.12 ms\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "output_.orderBy(f_.col('user_id').asc(),f_.col('item_id').cast(\"Integer\").asc())\\\n",
    ".write.csv('lab03_.csv',mode = 'overwrite',sep = ',',header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   3 ilya.chulyukin ilya.chulyukin          0 2022-11-06 01:03 /user/ilya.chulyukin/lab03_.csv/_SUCCESS\r\n",
      "-rw-r--r--   3 ilya.chulyukin ilya.chulyukin   52015790 2022-11-06 01:03 /user/ilya.chulyukin/lab03_.csv/part-00000-07e30d77-9835-4a60-bac2-c071d44d0ebc-c000.csv\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /user/ilya.chulyukin/lab03_.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hadoop fs -mv lab03_.csv/part-00000-*.csv lab03_.csv/lab03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r lab03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -get -f hdfs://spark-master-1.newprolab.com:8020/user/ilya.chulyukin/lab03_.csv/lab03.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
