{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запуск спарк, импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.4.7\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.6.5 (default, Apr 29 2018 16:14:56)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import Row\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "import re\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .config(conf=conf)\n",
    "         .appName(\"lab03\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-4.newprolab.com:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f67485206a0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls /labs/slaba03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', header = True, sep = '\\t')\n",
    "test = spark.read.csv('/labs/slaba03/laba03_test.csv', header = True, sep = ',')\n",
    "train = spark.read.csv('/labs/slaba03/laba03_train.csv', header = True, sep = ',')\n",
    "views = spark.read.csv('/labs/slaba03/laba03_views_programmes.csv', header = True, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) laba03_train.csv содержатся факты покупки (колонка purchase) пользователями (колонка user_id) телепередач (колонка item_id). \n",
    "\n",
    "2) laba03_items.csv — дополнительные данные по items. Поля в файле, на которых хотелось бы остановиться:\n",
    "\n",
    "* item_id — primary key. Соответствует item_id в предыдущем файле.\n",
    "* content_type — тип телепередачи (1 — платная, 0 — бесплатная). Интересуют <b>платные</b> передачи.\n",
    "* title — название передачи, текстовое поле.\n",
    "* year — год выпуска передачи, число.\n",
    "* genres — поле с жанрами передачи, разделёнными через запятую.\n",
    "\n",
    "3) laba03_test.csv — тестовый датасет без указанного целевого признака purchase, который необходимо предсказать.\n",
    "\n",
    "4) laba03_views_programmes.csv - просмотры передач с полями:\n",
    "\n",
    "* ts_start — время начала просмотра.\n",
    "* ts_end — время окончания просмотра.\n",
    "* item_type — тип просматриваемого контента: live — \"вживую\", pvr — в записи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@pandas_udf('array<string>', PandasUDFType.SCALAR) \n",
    "def text_compile(s):\n",
    "   # regex = re.split(r'\\W+', re.U)\n",
    "    words = s.str.split(',')\n",
    "    \n",
    "    return words\n",
    "\n",
    "text_compile_udf = pandas_udf(text_compile, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование таблиц\n",
    "### Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = (views\n",
    "         .withColumn(\"start_time\", F.to_timestamp(F.from_unixtime(F.col(\"ts_start\"))))\n",
    "         .withColumn(\"end_time\", F.to_timestamp(F.from_unixtime(F.col(\"ts_end\"))))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "views = views.withColumn(\"DiffInSeconds\", F.col(\"ts_end\") - F.col(\"ts_start\"))\n",
    "views =  (views\n",
    "          .withColumn(\"DiffInMinutes\",F.round(views[\"DiffInSeconds\"]/60, 2))\n",
    "          .withColumn(\"DiffInHours\",F.round(views[\"DiffInSeconds\"]/3600, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+---------+-------------------+-------------------+-------------+-------------+-----------+\n",
      "|user_id|item_id|  ts_start|    ts_end|item_type|         start_time|           end_time|DiffInSeconds|DiffInMinutes|DiffInHours|\n",
      "+-------+-------+----------+----------+---------+-------------------+-------------------+-------------+-------------+-----------+\n",
      "|      0|7101053|1491409931|1491411600|     live|2017-04-05 19:32:11|2017-04-05 20:00:00|       1669.0|        27.82|       0.46|\n",
      "|      0|7101054|1491412481|1491451571|     live|2017-04-05 20:14:41|2017-04-06 07:06:11|      39090.0|        651.5|      10.86|\n",
      "|      0|7101054|1491411640|1491412481|     live|2017-04-05 20:00:40|2017-04-05 20:14:41|        841.0|        14.02|       0.23|\n",
      "|      0|6184414|1486191290|1486191640|     live|2017-02-04 09:54:50|2017-02-04 10:00:40|        350.0|         5.83|        0.1|\n",
      "|    257|4436877|1490628499|1490630256|     live|2017-03-27 18:28:19|2017-03-27 18:57:36|       1757.0|        29.28|       0.49|\n",
      "+-------+-------+----------+----------+---------+-------------------+-------------------+-------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "views.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_items = items.select('item_id', 'title', 'content_type').join(views, on = 'item_id', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|content_type|\n",
      "+------------+\n",
      "|           0|\n",
      "|        null|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "views_items.select('content_type').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во views только бесплатный контент, поэтому не использую это датафрейм далее.\n",
    "Мб добавить средний просмотр?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = spark.read.csv('/labs/slaba03/laba03_items.csv', header = True, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_sel = ['item_id', 'content_type', 'title', 'year', 'genres', 'region_id']\n",
    "items = items.select(cols_to_sel).filter(F.col('content_type') == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Комедии', 'Комедия'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Для детей', 'Детские'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Драмы', 'Драма'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Документальные', 'Документальный'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Артхаус', 'Арт-хаус'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Боевики', 'Боевик'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Военные', 'Военный'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Исторические', 'Исторический'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Короткометражки', 'Короткометражные'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Мелодрамы', 'Мелодрама'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Музыкальные', 'Музыкальный'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Мультфильмы', 'Мультфильм'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Приключение', 'Приключения'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Семейные', 'Семейный'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'сказка', 'Сказка'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Сказки', 'Сказка'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', ' Сказка', 'Сказка'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Советское кино', 'Советские'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Спортивные', 'Спорт'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Триллеры', 'Триллер'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Фантастические', 'Фантастика'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Русские мультфильмы', 'Союзмультфильм'))\n",
    "items = items.withColumn('genres', F.regexp_replace('genres', 'Наши', 'Русские'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn(\"genres_list\", text_compile_udf(F.col(\"genres\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn('col1',F.lit('Передачи'))\n",
    "items = items.withColumn(\"col2\", text_compile_udf(F.col(\"col1\")))\n",
    "items = items.withColumn(\"genres_list\", F.array_except(\"genres_list\", \"col2\")).drop(*['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "items = items.select('*',F.size('genres_list').alias('genre_cnt'))\n",
    "items = items.withColumn(\"genre_cnt_distinct\", F.size(F.array_distinct(\"genres_list\")))\n",
    "\n",
    "## Проверка, что нет повторяющихся жанров\n",
    "print(items.filter(F.col('genre_cnt_distinct')!=F.col('genre_cnt')).select('item_id', 'title', 'genres_list').count())\n",
    "# СПОЙЛЕР: их нет\n",
    "\n",
    "items = items.drop(*['genre_cnt_distinct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------------+------+-------+---------+-----------+---------+\n",
      "|item_id|content_type|               title|  year| genres|region_id|genres_list|genre_cnt|\n",
      "+-------+------------+--------------------+------+-------+---------+-----------+---------+\n",
      "|  65667|           1|на пробах только ...|2013.0|Эротика|     null|  [Эротика]|        1|\n",
      "|  65669|           1|скуби ду: эротиче...|2011.0|Эротика|     null|  [Эротика]|        1|\n",
      "|  65668|           1|горячие девочки д...|2011.0|Эротика|     null|  [Эротика]|        1|\n",
      "|  65671|           1|соблазнительницы ...|2011.0|Эротика|     null|  [Эротика]|        1|\n",
      "|  65670|           1|секретные секс-ма...|2010.0|Эротика|     null|  [Эротика]|        1|\n",
      "+-------+------------+--------------------+------+-------+---------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_df = items.select(items.item_id,F.explode(items.genres_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|genre_cnt|count|\n",
      "+---------+-----+\n",
      "|       -1|   33|\n",
      "|        1|  244|\n",
      "|        2|  822|\n",
      "|        3| 1358|\n",
      "|        4|  775|\n",
      "|        5|  309|\n",
      "|        6|  106|\n",
      "|        7|   46|\n",
      "|        8|   11|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.select('item_id', 'genre_cnt').groupBy('genre_cnt').count().sort('genre_cnt').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  74107|       0|\n",
      "|   1654|  89249|       0|\n",
      "|   1654|  99982|       0|\n",
      "|   1654|  89901|       0|\n",
      "|   1654| 100504|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5032624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делаем панельный датафрейм с жанрами фильмов\n",
    "train_exploded = train.join(genres_df, on = 'item_id', how = 'left')\n",
    "train_exploded = train_exploded.withColumnRenamed('col','genre').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обрабатываем юзеров\n",
    "##### Общая статистика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_purchase = train_exploded.groupBy('user_id','genre').agg(F.sum(F.col('purchase')).alias('purchase')) \n",
    "#сколько раз юзер оплачивал каждый жанр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"user_id\")\n",
    "user_purchase = user_purchase.withColumn('max_purch', F.max('purchase').over(windowSpec))\n",
    "user_purchase = (user_purchase.join(\n",
    "    train.groupBy('user_id')\n",
    "    .agg(F.sum(F.col('purchase')).alias('cnt'), \n",
    "         F.mean(F.col('purchase')).alias('mean')),\n",
    "    on = 'user_id'))\n",
    "\n",
    "user_purchase = user_purchase.fillna('Без жанра', subset = ['genre'])\n",
    "user_purchase = (user_purchase.withColumn('nTop', \n",
    "                                          F.rank().over(windowSpec.orderBy(F.col('purchase').desc()))\n",
    "                                         )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_purchase.filter(F.col('cnt')==0).select('user_id').distinct().count()\n",
    "#сколько юзеров вообще ничего не покупали"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(cnt)|\n",
      "+--------+\n",
      "|   490.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_purchase.agg({'cnt': 'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+----+\n",
      "|%25|%50|%75| %90|\n",
      "+---+---+---+----+\n",
      "|1.0|2.0|5.0|14.0|\n",
      "+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = user_purchase.select('user_id', 'cnt').distinct()\n",
    "\n",
    "cnt = temp.agg(F.expr('percentile(cnt, array(0.25))')[0].alias('%25'),\n",
    "               F.expr('percentile(cnt, array(0.5))')[0].alias('%50'),\n",
    "               F.expr('percentile(cnt, array(0.75))')[0].alias('%75'),\n",
    "               F.expr('percentile(cnt, array(0.9))')[0].alias('%90')\n",
    "              )\n",
    "\n",
    "cnt.show()\n",
    "\n",
    "#Использую далее для отсечек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PIVOT\n",
    "По строкам юзеры, по столбцам предпочитаемые жанры на основе покупока"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF = train_exploded.groupBy('user_id').pivot(\"genre\").agg(F.sum(F.col('purchase')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF = pivotDF.fillna(0)\n",
    "pivotDF = pivotDF.withColumnRenamed('null', 'Без жанра')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF = (pivotDF.join(\n",
    "    train.groupBy('user_id')\n",
    "    .agg(\n",
    "        F.sum(F.col('purchase')).alias('cnt'), \n",
    "        F.mean(F.col('purchase')).alias('user_mean')\n",
    "    ), \n",
    "    on = 'user_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По персентилям (рассчитаны выше) создаются столбцы характеристик как много клиент покупал\n",
    "#Используется абсолют, так как доли очень низкие\n",
    "pivotDF = pivotDF.withColumn('user_low', F.when(F.col('cnt') < 1, 1).otherwise(0))\n",
    "pivotDF = pivotDF.withColumn('user_midlow', F.when((F.col('cnt') >= 1) & (F.col('cnt') < 2), 1).otherwise(0))\n",
    "pivotDF = pivotDF.withColumn('user_mid', F.when((F.col('cnt') >= 2) & (F.col('cnt') < 5), 1).otherwise(0))\n",
    "pivotDF = pivotDF.withColumn('user_midhigh', F.when((F.col('cnt') >= 5) & (F.col('cnt') < 14), 1).otherwise(0))\n",
    "pivotDF = pivotDF.withColumn('user_high', F.when(F.col('cnt') >= 14, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivotDF = pivotDF.withColumnRenamed('cnt', 'user_cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_cnt</th>\n",
       "      <th>user_low</th>\n",
       "      <th>user_midlow</th>\n",
       "      <th>user_mid</th>\n",
       "      <th>user_midhigh</th>\n",
       "      <th>user_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>588378</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747028</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>865152</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  user_cnt  user_low  user_midlow  user_mid  user_midhigh  user_high\n",
       "0  588378     138.0         0            0         0             0          1\n",
       "1  747028     490.0         0            0         0             0          1\n",
       "2  865152     116.0         0            0         0             0          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivotDF.filter(F.col('user_cnt')>100).select('user_id', 'user_cnt', 'user_low', \n",
    "                                        'user_midlow', 'user_mid', 'user_midhigh', 'user_high').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Интенсивность покупок определённых жанров\n",
    "for colm in pivotDF.columns[1:len(pivotDF.columns)-7]:\n",
    "    pivotDF = pivotDF.withColumn(f'{colm}_low', F.when(F.col(colm) < 3, 1).otherwise(0))\n",
    "    pivotDF = pivotDF.withColumn(f'{colm}_midlow', F.when((F.col(colm) >= 3) & (F.col(colm) < 7), 1).otherwise(0))\n",
    "    pivotDF = pivotDF.withColumn(f'{colm}_mid', F.when((F.col(colm) >= 7) & (F.col(colm) < 15), 1).otherwise(0))\n",
    "    pivotDF = pivotDF.withColumn(f'{colm}_midhigh', F.when((F.col(colm) >= 15) & (F.col(colm) < 50), 1).otherwise(0))\n",
    "    pivotDF = pivotDF.withColumn(f'{colm}_high', F.when(F.col(colm) >= 50, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обработаем фильмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_purchase = train.groupBy('item_id').agg(F.sum(F.col('purchase')).alias('cnt'),\n",
    "                                             F.mean(F.col('purchase')).alias('item_mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|%60|%75|%90|\n",
      "+---+---+---+\n",
      "|1.0|2.0|7.0|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = item_purchase.select('item_id', 'cnt').distinct()\n",
    "\n",
    "cnt = temp.agg(F.expr('percentile(cnt, array(0.6))')[0].alias('%60'),\n",
    "               F.expr('percentile(cnt, array(0.75))')[0].alias('%75'),\n",
    "               F.expr('percentile(cnt, array(0.9))')[0].alias('%90')\n",
    "              )\n",
    "\n",
    "cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_purchase = item_purchase.withColumn('item_no', F.when(F.col('cnt') < 1, 1).otherwise(0))\n",
    "item_purchase = item_purchase.withColumn('item_low', F.when((F.col('cnt') >= 1) & (F.col('cnt') < 2), 1).otherwise(0))\n",
    "item_purchase = item_purchase.withColumn('item_mid', F.when((F.col('cnt') >= 2) & (F.col('cnt') < 7), 1).otherwise(0))\n",
    "item_purchase = item_purchase.withColumn('item_high', F.when(F.col('cnt') >= 7, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_purchase = item_purchase.withColumnRenamed('cnt', 'item_cnt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обрабатываем жанры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre = train_exploded.groupBy('item_id').pivot(\"genre\").agg(F.sum(F.col('purchase')))\n",
    "item_genre = item_genre.withColumnRenamed('null', 'Без жанра')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre = (item_genre.join(\n",
    "    train.groupBy('item_id').agg(\n",
    "        F.sum(F.col('purchase')).alias('cnt')\n",
    "    ), on = 'item_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in item_genre.columns[1:len(item_genre.columns)-1]:\n",
    "    item_genre = item_genre.withColumn(genre, F.col(genre)/F.col('cnt'))\n",
    "\n",
    "item_genre = item_genre.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre = item_genre.drop(*['cnt'])\n",
    "for genre in item_genre.columns[1:]:\n",
    "    item_genre = item_genre.withColumnRenamed(genre, f'item_{genre}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Формирование рабочего df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941\n",
      "3704\n"
     ]
    }
   ],
   "source": [
    "print(train.select('user_id').distinct().count())\n",
    "print(train.select('item_id').distinct().count())\n",
    "\n",
    "### для проверок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_df = train.join(pivotDF, on = 'user_id')\n",
    "\n",
    "purchase_df.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_df = purchase_df.join(item_purchase, on = 'item_id')\n",
    "\n",
    "purchase_df.select('item_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_df = purchase_df.join(item_genre, on = 'item_id')\n",
    "\n",
    "purchase_df.select('item_id').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### cols = purchase_df.columns[3:]\n",
    "cols = [x for x in purchase_df.columns[65:] if \"_high\" not in x]\n",
    "cols = [x for x in cols if \"_cnt\" not in x]\n",
    "cols = [x for x in cols if \"_mean\" not in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline+Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "assemblerInputs = cols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- purchase: float (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(purchase_df)\n",
    "purchase_df = pipelineModel.transform(purchase_df)\n",
    "selectedCols = ['purchase', 'features'] +  ['user_id', 'item_id']\n",
    "purchase_df = purchase_df.select(selectedCols)\n",
    "purchase_df = purchase_df.withColumn('purchase', purchase_df.purchase.cast('float'))\n",
    "purchase_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "#### Train-test-split \n",
    "Для проверки алгоритма, обучала его на 70% данных трейна и соответственно тестировала на 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3522587\n",
      "Test Dataset Count: 1510037\n"
     ]
    }
   ],
   "source": [
    "trainM, testM = purchase_df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(trainM.count()))\n",
    "print(\"Test Dataset Count: \" + str(testM.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'purchase', maxIter=10)\n",
    "lrModel = lr.fit(trainM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 0.863812746420513\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-------+-------+--------------------+--------------------+----------+\n",
      "|purchase|            features|user_id|item_id|       rawPrediction|         probability|prediction|\n",
      "+--------+--------------------+-------+-------+--------------------+--------------------+----------+\n",
      "|     0.0|(317,[0,4,8,12,16...| 651811|  74605|[6.94930158765915...|[0.99904161447376...|       0.0|\n",
      "|     0.0|(317,[0,4,8,12,16...| 703514| 100140|[6.94930158765915...|[0.99904161447376...|       0.0|\n",
      "|     0.0|(317,[0,4,8,12,16...| 746365|  74605|[6.94930158765915...|[0.99904161447376...|       0.0|\n",
      "|     0.0|(317,[0,4,8,12,16...| 759924|  74605|[6.94930158765915...|[0.99904161447376...|       0.0|\n",
      "|     0.0|(317,[0,4,8,12,16...| 765762|    691|[6.94930158765915...|[0.99904161447376...|       0.0|\n",
      "+--------+--------------------+-------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lrPreds = lrModel.transform(testM)\n",
    "lrPreds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.8642501598161314\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "lrEval = BinaryClassificationEvaluator(labelCol = 'purchase')\n",
    "print('Test Area Under ROC', lrEval.evaluate(lrPreds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение на всей train выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'purchase', maxIter=10)\n",
    "lrModel = lr.fit(purchase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set areaUnderROC: 0.8644187252007944\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lrModel.summary\n",
    "print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запускаем на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  94814|    null|\n",
      "|   1654|  93629|    null|\n",
      "|   1654|   9980|    null|\n",
      "|   1654|  95099|    null|\n",
      "|   1654|  11265|    null|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941\n",
      "3704\n"
     ]
    }
   ],
   "source": [
    "print(test.select('user_id').distinct().count())\n",
    "print(test.select('item_id').distinct().count())\n",
    "\n",
    "### для проверок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_df_test = test.join(pivotDF, on = 'user_id')\n",
    "\n",
    "#purchase_df_test.select('user_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_df_test = purchase_df_test.join(item_purchase, on = 'item_id')\n",
    "\n",
    "#purchase_df_test.select('item_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchase_df_test = purchase_df_test.join(item_genre, on = 'item_id')\n",
    "\n",
    "#purchase_df_test.select('item_id').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(purchase_df_test)\n",
    "purchase_df_test = pipelineModel.transform(purchase_df_test)\n",
    "selectedCols = ['features'] +  ['user_id', 'item_id']\n",
    "purchase_df_test = purchase_df_test.select(selectedCols)\n",
    "purchase_df_test.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrPreds = lrModel.transform(purchase_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = lrPreds.select('user_id', 'item_id', 'probability')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.write.parquet(\"/user/alexandra.kolesova/predict_result.parquet\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = spark.read.parquet(\"/user/alexandra.kolesova/predict_result.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstelement=F.udf(lambda v:float(v[1]),FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = predict_df.withColumn(\"prob_1\", firstelement(\"probability\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prob_1: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_df.selectExpr('user_id', 'item_id', 'prob_1 as purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+\n",
      "|user_id|item_id|    purchase|\n",
      "+-------+-------+------------+\n",
      "|   1654| 100026| 9.387307E-4|\n",
      "|   1654| 100029|9.7587716E-4|\n",
      "|   1654| 100095|0.0010013141|\n",
      "|   1654| 100100| 9.680851E-4|\n",
      "|   1654| 100106| 9.575816E-4|\n",
      "+-------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.sort('user_id', 'item_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.coalesce(1).write.options(header='True', delimiter=',').csv(\"/user/alexandra.kolesova/predict_result.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 items\r\n",
      "drwxr-xr-x   - alexandra.kolesova alexandra.kolesova          0 2022-10-31 22:04 /user/alexandra.kolesova/.sparkStaging\r\n",
      "drwxr-xr-x   - alexandra.kolesova alexandra.kolesova          0 2022-10-31 22:12 /user/alexandra.kolesova/predict_result.csv\r\n",
      "drwxr-xr-x   - alexandra.kolesova alexandra.kolesova          0 2022-10-31 20:11 /user/alexandra.kolesova/predict_result.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/alexandra.kolesova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -copyToLocal /user/alexandra.kolesova/predict_result.csv result.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.toPandas().to_csv('lab03.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Остановка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
