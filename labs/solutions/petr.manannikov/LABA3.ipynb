{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --driver-memory 2g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.app.name\", \"PM app\") \n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"PM app\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://spark-master-5.newprolab.com:4043\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PM app</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb6707e4630>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get: `laba03_test.csv': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -get /labs/slaba03/laba03_test.csv #laba03_views_programmes.csv #laba03_train.csv #laba03_test.csv #laba03_items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id\tchannel_id\tdatetime_availability_start\tdatetime_availability_st\n",
      "op\tdatetime_show_start\tdatetime_show_stop\tcontent_type\ttitle\t\n",
      "year\tgenres\tregion_id\n",
      "65667\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t\n",
      "1\tна пробах только девушки (all girl auditions)\t2013.0\tЭротика\t\n",
      "65669\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t\n",
      "1\tскуби ду: эротическая пародия (scooby doo: a xxx parody)\t2011.0\t\n",
      "Эротика\t\n",
      "65668\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t\n",
      "1\tгорячие девочки для горячих девочек (hot babes 4 hot babes)\t2011.0\t\n",
      "Эротика\t\n",
      "65671\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t\n",
      "1\tсоблазнительницы женатых мужчин (top heavy homewreckers)\t2011.0\t\n",
      "Эротика\t\n",
      "65670\t\t1970-01-01T00:00:00Z\t2018-01-01T00:00:00Z\t\t\t\n",
      "1\tсекретные секс-материалы ii: темная секс пародия (the sex files ii: a da\n",
      "rk xxx parody)\t2010.0\tЭротика\t\n",
      "65809\t\t1970-01-01T00:00:00Z\t2099-12-31T21:00:00Z\t\t\t\n",
      "1\tвсе о мужчинах\t2016.0\tКомедии\t\n",
      "65810\t\t1970-01-01T00:00:00Z\t2099-12-31T21:00:00Z\t\t\t\n",
      "1\t8 лучших свиданий (сурдоперевод)\t2016.0\tКомедии,Мелодрамы\t\n",
      "326\t\t1970-01-01T00:00:00Z\t2099-12-31T21:00:00Z\t\t\t\n",
      "1\tвизантия\t2012.0\tУжасы,Триллеры,Драмы,Фантастика,Зарубежные\t\n",
      "\u001b[Km--More--(0%)\u001b[m"
     ]
    }
   ],
   "source": [
    "! more laba03_items.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! more laba03_views_programmes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\",\"true\")\\\n",
    "          .option(\"sep\", \",\")\\\n",
    "          .load(\"/labs/slaba03/laba03_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "|   1654|  94814|    null|\n",
      "|   1654|  93629|    null|\n",
      "|   1654|   9980|    null|\n",
      "|   1654|  95099|    null|\n",
      "|   1654|  11265|    null|\n",
      "|   1654|  88896|    null|\n",
      "|   1654|  67740|    null|\n",
      "|   1654|  74271|    null|\n",
      "|   1654|  99871|    null|\n",
      "|   1654|  78570|    null|\n",
      "+-------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156840"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "programmes_schema = StructType(fields=[\n",
    "    StructField(\"user_id\", IntegerType()),\n",
    "    StructField(\"item_id\", IntegerType()),\n",
    "    StructField(\"ts_start\", LongType()),\n",
    "    StructField(\"ts_end\", LongType()),\n",
    "    StructField(\"item_type\", StringType())    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "programmes = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\",\"true\")\\\n",
    "          .option(\"sep\", \",\")\\\n",
    "          .load(\"/labs/slaba03/laba03_views_programmes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+----------+---------+\n",
      "|user_id|item_id|  ts_start|    ts_end|item_type|\n",
      "+-------+-------+----------+----------+---------+\n",
      "|      0|7101053|1491409931|1491411600|     live|\n",
      "|      0|7101054|1491412481|1491451571|     live|\n",
      "|      0|7101054|1491411640|1491412481|     live|\n",
      "|      0|6184414|1486191290|1486191640|     live|\n",
      "|    257|4436877|1490628499|1490630256|     live|\n",
      "|   1654|7489015|1493434801|1493435401|     live|\n",
      "|   1654|7489023|1493444101|1493445601|     live|\n",
      "|   1654|6617053|1489186156|1489200834|     live|\n",
      "|   1654|6438693|1487840070|1487840433|     live|\n",
      "|   1654|6526859|1488705452|1488706154|     live|\n",
      "+-------+-------+----------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "programmes.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "programmes.createOrReplaceTempView(\"programmes_ql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "  user_id\n",
    ", item_id\n",
    ", item_type\n",
    ", to_timestamp(from_unixtime(ts_start,'yyyy-MM-dd HH:mm:ss')) as ts_start\n",
    ", to_timestamp(from_unixtime(ts_end,'yyyy-MM-dd HH:mm:ss')) as ts_end\n",
    "--, datediff(to_timestamp(from_unixtime(ts_start,'yyyy-MM-dd HH:mm:ss')),to_timestamp(from_unixtime(ts_end,'yyyy-MM-dd HH:mm:ss'))) as diff\n",
    ", round((ts_end - ts_start)/60) as diff_sec\n",
    "--,item_type\n",
    "FROM programmes_ql\n",
    "--where 'user_id' = 1654\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------+-------------------+-------------------+--------+\n",
      "|user_id|item_id|item_type|           ts_start|             ts_end|diff_sec|\n",
      "+-------+-------+---------+-------------------+-------------------+--------+\n",
      "|      0|7101053|     live|2017-04-05 19:32:11|2017-04-05 20:00:00|    28.0|\n",
      "|      0|7101054|     live|2017-04-05 20:14:41|2017-04-06 07:06:11|   652.0|\n",
      "|      0|7101054|     live|2017-04-05 20:00:40|2017-04-05 20:14:41|    14.0|\n",
      "|      0|6184414|     live|2017-02-04 09:54:50|2017-02-04 10:00:40|     6.0|\n",
      "|    257|4436877|     live|2017-03-27 18:28:19|2017-03-27 18:57:36|    29.0|\n",
      "|   1654|7489015|     live|2017-04-29 06:00:01|2017-04-29 06:10:01|    10.0|\n",
      "|   1654|7489023|     live|2017-04-29 08:35:01|2017-04-29 09:00:01|    25.0|\n",
      "|   1654|6617053|     live|2017-03-11 01:49:16|2017-03-11 05:53:54|   245.0|\n",
      "|   1654|6438693|     live|2017-02-23 11:54:30|2017-02-23 12:00:33|     6.0|\n",
      "|   1654|6526859|     live|2017-03-05 12:17:32|2017-03-05 12:29:14|    12.0|\n",
      "+-------+-------+---------+-------------------+-------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\",\"true\")\\\n",
    "          .option(\"sep\", \"\\t\")\\\n",
    "          .load(\"/labs/slaba03/laba03_items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+---------------------------------------------+------+-------+---------+\n",
      "|item_id|channel_id|datetime_availability_start|datetime_availability_stop|datetime_show_start|datetime_show_stop|content_type|title                                        |year  |genres |region_id|\n",
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+---------------------------------------------+------+-------+---------+\n",
      "|65667  |null      |1970-01-01T00:00:00Z       |2018-01-01T00:00:00Z      |null               |null              |1           |на пробах только девушки (all girl auditions)|2013.0|Эротика|null     |\n",
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+---------------------------------------------+------+-------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.show(1,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.createOrReplaceTempView(\"items_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = \"\"\"\n",
    "SELECT \n",
    " count(distinct item_id) as count_paid_channels\n",
    "FROM items_sql\n",
    "where content_type ==1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count_paid_channels|\n",
      "+-------------------+\n",
      "|               3704|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(q0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT \n",
    "  item_id\n",
    ", channel_id\n",
    ", datetime_availability_start as av_start\n",
    ", datetime_availability_stop as av_stop\n",
    ", datetime_show_start as show_st\n",
    ", datetime_show_stop as show_st\n",
    ", content_type\n",
    ", title\n",
    ", year\n",
    ", genres\n",
    ",split(genres,',')[0] as first_genre\n",
    ", region_id\n",
    "FROM items_sql\n",
    "where content_type ==1\n",
    "\n",
    "--user_id = 1654\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+--------------------+-------+-------+------------+---------------------------------------------+------+-------+-----------+---------+\n",
      "|item_id|channel_id|av_start            |av_stop             |show_st|show_st|content_type|title                                        |year  |genres |first_genre|region_id|\n",
      "+-------+----------+--------------------+--------------------+-------+-------+------------+---------------------------------------------+------+-------+-----------+---------+\n",
      "|65667  |null      |1970-01-01T00:00:00Z|2018-01-01T00:00:00Z|null   |null   |1           |на пробах только девушки (all girl auditions)|2013.0|Эротика|Эротика    |null     |\n",
      "+-------+----------+--------------------+--------------------+-------+-------+------------+---------------------------------------------+------+-------+-----------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items2 = spark.sql(q)\n",
    "items2.show(1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|item_id|first_genre|\n",
      "+-------+-----------+\n",
      "|  65667|    Эротика|\n",
      "|  65669|    Эротика|\n",
      "|  65668|    Эротика|\n",
      "|  65671|    Эротика|\n",
      "|  65670|    Эротика|\n",
      "|  65809|    Комедии|\n",
      "|  65810|    Комедии|\n",
      "|    326|      Ужасы|\n",
      "|    336|      Ужасы|\n",
      "|    357|    Комедии|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items3 = items2.select('item_id','first_genre').na.drop()\n",
    "items3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3671"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer = StringIndexer(inputCol=\"first_genre\", outputCol=\"genre_Index\")\n",
    "model = stringIndexer.fit(items3)\n",
    "indexed = model.transform(items3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------+\n",
      "|item_id|first_genre|genre_Index|\n",
      "+-------+-----------+-----------+\n",
      "|  65667|    Эротика|        9.0|\n",
      "|  65669|    Эротика|        9.0|\n",
      "|  65668|    Эротика|        9.0|\n",
      "|  65671|    Эротика|        9.0|\n",
      "|  65670|    Эротика|        9.0|\n",
      "|  65809|    Комедии|        0.0|\n",
      "|  65810|    Комедии|        0.0|\n",
      "|    326|      Ужасы|        3.0|\n",
      "|    336|      Ужасы|        3.0|\n",
      "|    357|    Комедии|        0.0|\n",
      "+-------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(inputCol=\"genre_Index\", outputCol=\"genre_vector\")\n",
    "item_genre_vector = encoder.transform(indexed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------+---------------+\n",
      "|item_id|first_genre|genre_Index|   genre_vector|\n",
      "+-------+-----------+-----------+---------------+\n",
      "|  65667|    Эротика|        9.0| (63,[9],[1.0])|\n",
      "|  65669|    Эротика|        9.0| (63,[9],[1.0])|\n",
      "|  65668|    Эротика|        9.0| (63,[9],[1.0])|\n",
      "|  65671|    Эротика|        9.0| (63,[9],[1.0])|\n",
      "|  65670|    Эротика|        9.0| (63,[9],[1.0])|\n",
      "|  65809|    Комедии|        0.0| (63,[0],[1.0])|\n",
      "|  65810|    Комедии|        0.0| (63,[0],[1.0])|\n",
      "|    326|      Ужасы|        3.0| (63,[3],[1.0])|\n",
      "|    336|      Ужасы|        3.0| (63,[3],[1.0])|\n",
      "|    357|    Комедии|        0.0| (63,[0],[1.0])|\n",
      "|    396|  Детективы|        5.0| (63,[5],[1.0])|\n",
      "|    400| Фантастика|       14.0|(63,[14],[1.0])|\n",
      "|    423|  Детективы|        5.0| (63,[5],[1.0])|\n",
      "|    430|  Детективы|        5.0| (63,[5],[1.0])|\n",
      "|    449|      Ужасы|        3.0| (63,[3],[1.0])|\n",
      "|    453|    Комедии|        0.0| (63,[0],[1.0])|\n",
      "|    478|    Военные|        7.0| (63,[7],[1.0])|\n",
      "|    495|Приключения|        2.0| (63,[2],[1.0])|\n",
      "|    505|    Военные|        7.0| (63,[7],[1.0])|\n",
      "|    540|    Комедии|        0.0| (63,[0],[1.0])|\n",
      "+-------+-----------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_genre_vector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(q).count() #show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = \"\"\"\n",
    "SELECT   \n",
    " --genres\n",
    " distinct\n",
    "  item_id\n",
    ", split(genres,',')[0] as first_genre\n",
    " --, patindex(',',genres)\n",
    "FROM items_sql\n",
    "where content_type ==1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|item_id|first_genre|\n",
      "+-------+-----------+\n",
      "|   4419|      Ужасы|\n",
      "|   5084|    Боевики|\n",
      "|   8635|Мультфильмы|\n",
      "|   9040|      Драмы|\n",
      "|  11040|    Комедия|\n",
      "|  11071|    Комедии|\n",
      "|  66457|    Военные|\n",
      "|  66700|Мистические|\n",
      "|  72327|    Комедии|\n",
      "|  73568|      Ужасы|\n",
      "+-------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_genres = spark.sql(q2)  #.show(1000,False)\n",
    "item_genres = item_genres.na.fill('-')\n",
    "item_genres.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_genres.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = \"\"\"\n",
    "SELECT \n",
    " distinct item_id, split(genres,',') as all_genres\n",
    "--, region_id\n",
    "FROM items_sql\n",
    "\n",
    "where content_type ==1\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = spark.sql(q3).na.drop()  #.show(1000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|item_id|          all_genres|\n",
      "+-------+--------------------+\n",
      "|   9418|[Анимация, Для вз...|\n",
      "|   1789|[Анимация, Для вз...|\n",
      "|  97806|[Артхаус, Военные...|\n",
      "|  95573|[Артхаус, Военные...|\n",
      "|  71843|[Артхаус, Военные...|\n",
      "|  98235|[Артхаус, Детекти...|\n",
      "|  74555|[Артхаус, Драмы, ...|\n",
      "|  74272|[Артхаус, Драмы, ...|\n",
      "|  74478|[Артхаус, Драмы, ...|\n",
      "| 100735|[Артхаус, Драмы, ...|\n",
      "|  76264|[Артхаус, Драмы, ...|\n",
      "| 100715|[Артхаус, Драмы, ...|\n",
      "|  74425|[Артхаус, Драмы, ...|\n",
      "|  99471|[Артхаус, Комедии...|\n",
      "|  98274|[Артхаус, Комедии...|\n",
      "|  73981|[Артхаус, Коротко...|\n",
      "|  95278|[Артхаус, Мелодра...|\n",
      "|  95416|[Артхаус, Мистиче...|\n",
      "|  67318|[Артхаус, Мистиче...|\n",
      "|  87167|[Артхаус, Приключ...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genres.orderBy('all_genres').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer_04233f121c9f"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.setInputCol(\"all_genres\")\n",
    "cv.setOutputCol(\"all_genres_vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.fit(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3671"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(genres).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|item_id|      all_genres|  all_genres_vectors|\n",
      "+-------+----------------+--------------------+\n",
      "|  72214|[Драмы, Русские]|(83,[1,4],[1.0,1.0])|\n",
      "+-------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_genres_vectors = model.transform(genres)\n",
    "all_genres_vectors.where(\"item_id==72214\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|         first_genre|count_first_genres|\n",
      "+--------------------+------------------+\n",
      "|             Комедии|               597|\n",
      "|               Драмы|               362|\n",
      "|         Приключения|               341|\n",
      "|               Ужасы|               336|\n",
      "|            Триллеры|               267|\n",
      "|           Детективы|               256|\n",
      "|         Мультфильмы|               241|\n",
      "|             Военные|               172|\n",
      "| Русские мультфильмы|               169|\n",
      "|             Эротика|               121|\n",
      "|            Семейные|                72|\n",
      "|         Мистические|                70|\n",
      "|           Мелодрамы|                67|\n",
      "|      Полнометражные|                58|\n",
      "|          Фантастика|                53|\n",
      "|             Боевики|                48|\n",
      "|      Документальные|                46|\n",
      "|Западные мультфильмы|                42|\n",
      "|             Русские|                36|\n",
      "|                   -|                33|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_genres_df = item_genres.groupBy(\"first_genre\")\\\n",
    "                .agg(F.count(\"first_genre\").alias(\"count_first_genres\"))\\\n",
    "                .orderBy(\"count_first_genres\", ascending=False)\n",
    "group_genres_df.show(20)                            #where('first_genre<>\"General\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "items2.createOrReplaceTempView(\"items2_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = \"\"\"\n",
    "SELECT   distinct\n",
    " first_genre\n",
    " , count(item_id) over (partition by first_genre) as count_genres\n",
    "FROM items2_sql\n",
    "order by count_genres desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|         first_genre|count_genres|\n",
      "+--------------------+------------+\n",
      "|             Комедии|         597|\n",
      "|               Драмы|         362|\n",
      "|         Приключения|         341|\n",
      "|               Ужасы|         336|\n",
      "|            Триллеры|         267|\n",
      "|           Детективы|         256|\n",
      "|         Мультфильмы|         241|\n",
      "|             Военные|         172|\n",
      "| Русские мультфильмы|         169|\n",
      "|             Эротика|         121|\n",
      "|            Семейные|          72|\n",
      "|         Мистические|          70|\n",
      "|           Мелодрамы|          67|\n",
      "|      Полнометражные|          58|\n",
      "|          Фантастика|          53|\n",
      "|             Боевики|          48|\n",
      "|      Документальные|          46|\n",
      "|Западные мультфильмы|          42|\n",
      "|             Русские|          36|\n",
      "|                null|          33|\n",
      "+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(q3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read\\\n",
    "          .format(\"csv\")\\\n",
    "          .option(\"header\",\"true\")\\\n",
    "          .option(\"sep\", \",\")\\\n",
    "          .load(\"/labs/slaba03/laba03_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5032624"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|item_id|purchase|\n",
      "+-------+-------+--------+\n",
      "| 747028|  72214|       1|\n",
      "| 747028|  94137|       0|\n",
      "| 747028|  10880|       0|\n",
      "| 747028| 100306|       0|\n",
      "| 747028|  99770|       0|\n",
      "| 747028|  94632|       0|\n",
      "| 747028|  66467|       0|\n",
      "| 747028|  82917|       1|\n",
      "| 747028|  99434|       0|\n",
      "| 747028|  99815|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.where(\"user_id ==747028\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView(\"train_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select *\n",
    ", sum_over_user_id/user_buy_frequency as one_hot_user_id_solvency\n",
    "from (\n",
    "\n",
    "SELECT distinct \n",
    "  user_id\n",
    ", count(user_id) over (partition by user_id) as user_buy_frequency\n",
    ", sum(purchase) over (partition by user_id) as sum_over_user_id\n",
    "FROM train_sql\n",
    ")\n",
    "order by sum_over_user_id desc\n",
    "--where user_id = 1654\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(query).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------------+------------------------+\n",
      "|user_id|user_buy_frequency|sum_over_user_id|one_hot_user_id_solvency|\n",
      "+-------+------------------+----------------+------------------------+\n",
      "| 747028|              2632|           490.0|     0.18617021276595744|\n",
      "| 588378|              2590|           138.0|     0.05328185328185328|\n",
      "| 865152|              2615|           116.0|    0.044359464627151055|\n",
      "| 845568|              2558|            97.0|     0.03792025019546521|\n",
      "| 857251|              2641|            95.0|     0.03597122302158273|\n",
      "| 910185|              2610|            82.0|    0.031417624521072794|\n",
      "| 899088|              2600|            79.0|    0.030384615384615385|\n",
      "| 822322|              2567|            79.0|     0.03077522399688352|\n",
      "| 892523|              2603|            76.0|    0.029197080291970802|\n",
      "| 898757|              2599|            75.0|    0.028857252789534438|\n",
      "| 754230|              2611|            72.0|    0.027575641516660282|\n",
      "| 916825|              2603|            70.0|     0.02689204763734153|\n",
      "| 762457|              2649|            69.0|    0.026047565118912798|\n",
      "| 874657|              2590|            66.0|    0.025482625482625483|\n",
      "| 841676|              2566|            63.0|    0.024551831644583008|\n",
      "| 885864|              2533|            53.0|    0.020923805763916305|\n",
      "| 895749|              2576|            53.0|    0.020574534161490684|\n",
      "| 874740|              2629|            49.0|    0.018638265500190185|\n",
      "| 920519|              2613|            47.0|    0.017986988136241867|\n",
      "| 746918|              2637|            47.0|     0.01782328403488813|\n",
      "+-------+------------------+----------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_hot_user_id_solvency = spark.sql(query)\n",
    "one_hot_user_id_solvency.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_user_id_solvency.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"\n",
    "select *,sum_over_item_id/count_item_id as one_hot_item_id_popularity \n",
    "from (\n",
    "\n",
    "SELECT distinct item_id\n",
    ", count(item_id) over (partition by item_id) as count_item_id\n",
    ",sum(purchase) over (partition by item_id) as sum_over_item_id\n",
    "FROM train_sql\n",
    ")\n",
    "order by sum_over_item_id desc\n",
    "\n",
    "--where user_id = 1654\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3704"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(query2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----------------+--------------------------+\n",
      "|item_id|count_item_id|sum_over_item_id|one_hot_item_id_popularity|\n",
      "+-------+-------------+----------------+--------------------------+\n",
      "|  72214|         1401|             2.0|      0.001427551748750...|\n",
      "+-------+-------------+----------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_hot_item_id_popularity = spark.sql(query2)\n",
    "one_hot_item_id_popularity.where(\"item_id==72214\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+-----+------+-------------+---------+\n",
      "|item_id|channel_id|datetime_availability_start|datetime_availability_stop|datetime_show_start|datetime_show_stop|content_type|title|year  |genres       |region_id|\n",
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+-----+------+-------------+---------+\n",
      "|72214  |null      |1970-01-01T00:00:00Z       |2099-12-31T21:00:00Z      |null               |null              |1           |мажор|2014.0|Драмы,Русские|null     |\n",
      "+-------+----------+---------------------------+--------------------------+-------------------+------------------+------------+-----+------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "items.filter(\"item_id==72214\").show(1,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4987875"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full_features = train.join(f.broadcast(one_hot_user_id_solvency), on=\"user_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(one_hot_item_id_popularity), on=\"item_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(all_genres_vectors), on=\"item_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(item_genre_vector), on=\"item_id\", how=\"inner\")\n",
    "train_full_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+---------------+\n",
      "|item_id|user_id|one_hot_user_id_solvency|one_hot_item_id_popularity|  all_genres_vectors|  genre_vector|purchase|      item_user|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+---------------+\n",
      "|  72214| 747028|     0.18617021276595744|      0.001427551748750...|(83,[1,4],[1.0,1.0])|(63,[1],[1.0])|       1|7.2214747028E10|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join1.orderBy(\"item_id\").show()\n",
    "select_features = train_full_features.select('item_id','user_id','one_hot_user_id_solvency','one_hot_item_id_popularity','all_genres_vectors','genre_vector','purchase')\\\n",
    ".withColumn(\"item_user\",f.concat(f.col('item_id'), f.col('user_id')))\n",
    "\n",
    "select_features = select_features.withColumn(\"item_id\", select_features[\"item_id\"].cast(IntegerType()))\n",
    "select_features = select_features.withColumn(\"user_id\", select_features[\"user_id\"].cast(IntegerType()))\n",
    "select_features = select_features.withColumn(\"purchase\", select_features[\"purchase\"].cast(IntegerType()))\n",
    "select_features = select_features.withColumn(\"item_user\", select_features[\"item_user\"].cast(DoubleType()))\n",
    "\n",
    "select_features.where(\"user_id=747028\").show(1)\n",
    "# train_full_features = train_full_features.withColumn(\"user_id2\", train_full_features[\"user_id\"].cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- one_hot_user_id_solvency: double (nullable = true)\n",
      " |-- one_hot_item_id_popularity: double (nullable = true)\n",
      " |-- all_genres_vectors: vector (nullable = true)\n",
      " |-- genre_vector: vector (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      " |-- item_user: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10576"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_features.where(\"purchase==1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4977299"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_features.where(\"purchase==0\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['user_id','item_id',\"one_hot_user_id_solvency\", \"one_hot_item_id_popularity\",\"all_genres_vectors\",\"genre_vector\",'purchase'],outputCol=\"features\") # \"all_genres_vectors\",,\"genre_vector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(select_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1, test1 = output.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"purchase\", featuresCol=\"features\", maxIter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gbt.fit(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------+\n",
      "|prediction|probability                              |\n",
      "+----------+-----------------------------------------+\n",
      "|0.0       |[0.9563534785730002,0.04364652142699976] |\n",
      "|0.0       |[0.9563534785729898,0.0436465214270102]  |\n",
      "|0.0       |[0.9563534785729929,0.04364652142700709] |\n",
      "|0.0       |[0.9563534785730108,0.043646521426989215]|\n",
      "|0.0       |[0.9563534785730179,0.04364652142698211] |\n",
      "|0.0       |[0.9563534785730108,0.043646521426989215]|\n",
      "|0.0       |[0.9563534785730216,0.043646521426978446]|\n",
      "|0.0       |[0.9563534785730383,0.04364652142696168] |\n",
      "|0.0       |[0.9563534785730179,0.04364652142698211] |\n",
      "|0.0       |[0.9563534785730329,0.04364652142696712] |\n",
      "|0.0       |[0.9563534785730223,0.04364652142697767] |\n",
      "|0.0       |[0.9563534785729694,0.04364652142703063] |\n",
      "|0.0       |[0.9563534785730228,0.043646521426977225]|\n",
      "|0.0       |[0.9563534785730179,0.04364652142698211] |\n",
      "|0.0       |[0.9563534785730412,0.043646521426958795]|\n",
      "|0.0       |[0.9563534785730528,0.04364652142694725] |\n",
      "|0.0       |[0.9563534785730106,0.04364652142698944] |\n",
      "|0.0       |[0.9563534785730108,0.043646521426989215]|\n",
      "|0.0       |[0.9563534785730554,0.043646521426944584]|\n",
      "|0.0       |[0.9563534785730554,0.043646521426944584]|\n",
      "|0.0       |[0.9563534785730108,0.043646521426989215]|\n",
      "|0.0       |[0.9563534785730223,0.04364652142697767] |\n",
      "|0.0       |[0.9563534785730284,0.04364652142697156] |\n",
      "|0.0       |[0.9563534785730179,0.04364652142698211] |\n",
      "|0.0       |[0.9563534785730179,0.04364652142698211] |\n",
      "+----------+-----------------------------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.where('user_id==1654').select('prediction', 'probability').show(25,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_eval = BinaryClassificationEvaluator(rawPredictionCol=\"probability\",labelCol=\"purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 1.0000\n"
     ]
    }
   ],
   "source": [
    "gbt_AUC  = gbt_eval.evaluate(predictions)\n",
    "print(\"AUC = %.4f\" % gbt_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+------------+--------------------+--------------------+--------------------+----------+\n",
      "|item_id|user_id|one_hot_user_id_solvency|one_hot_item_id_popularity|  all_genres_vectors|  genre_vector|purchase|   item_user|            features|       rawPrediction|         probability|prediction|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+------------+--------------------+--------------------+--------------------+----------+\n",
      "|    326| 613775|    3.894080996884735E-4|      7.320644216691069E-4|(83,[0,1,3,10,12]...|(63,[3],[1.0])|       0|3.26613775E8|(151,[0,1,2,3,4,5...|[1.32556415050051...|[0.93408049868664...|       0.0|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"purchase\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2137536"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_features = test_df.join(f.broadcast(one_hot_user_id_solvency), on=\"user_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(one_hot_item_id_popularity), on=\"item_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(all_genres_vectors), on=\"item_id\", how=\"inner\")\\\n",
    ".join(f.broadcast(item_genre_vector), on=\"item_id\", how=\"inner\")\n",
    "test_full_features.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156840"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_features_FULL = test_df.join(f.broadcast(one_hot_user_id_solvency), on=\"user_id\", how=\"left\")\\\n",
    ".join(f.broadcast(one_hot_item_id_popularity), on=\"item_id\", how=\"left\")\\\n",
    ".join(f.broadcast(all_genres_vectors), on=\"item_id\", how=\"left\")\\\n",
    ".join(f.broadcast(item_genre_vector), on=\"item_id\", how=\"left\")\n",
    "test_full_features_FULL.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- purchase: string (nullable = true)\n",
      " |-- user_buy_frequency: long (nullable = false)\n",
      " |-- sum_over_user_id: double (nullable = true)\n",
      " |-- one_hot_user_id_solvency: double (nullable = true)\n",
      " |-- count_item_id: long (nullable = false)\n",
      " |-- sum_over_item_id: double (nullable = true)\n",
      " |-- one_hot_item_id_popularity: double (nullable = true)\n",
      " |-- all_genres: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- all_genres_vectors: vector (nullable = true)\n",
      " |-- first_genre: string (nullable = true)\n",
      " |-- genre_Index: double (nullable = false)\n",
      " |-- genre_vector: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_full_features.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19304"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_features_FULL.filter(test_full_features_FULL.all_genres.isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_features = test_full_features.na.fill(0,[\"all_genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19304"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_full_features_NOT_FOUND = test_full_features_FULL.where(\"all_genres is null\")\n",
    "test_full_features_NOT_FOUND.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+----------------+\n",
      "|item_id|user_id|one_hot_user_id_solvency|one_hot_item_id_popularity|  all_genres_vectors|  genre_vector|purchase|       item_user|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+----------------+\n",
      "| 102279| 747028|     0.18617021276595744|      7.468259895444362E-4|(83,[2,4],[1.0,1.0])|(63,[0],[1.0])|    null|1.02279747028E11|\n",
      "+-------+-------+------------------------+--------------------------+--------------------+--------------+--------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "select_features2 = test_full_features.select('item_id','user_id','one_hot_user_id_solvency','one_hot_item_id_popularity','all_genres_vectors','genre_vector','purchase')\\\n",
    ".withColumn(\"item_user\",f.concat(f.col('item_id'), f.col('user_id')))\n",
    "\n",
    "select_features2 = select_features2.withColumn(\"item_id\", select_features2[\"item_id\"].cast(IntegerType()))\n",
    "select_features2 = select_features2.withColumn(\"user_id\", select_features2[\"user_id\"].cast(IntegerType()))\n",
    "select_features2 = select_features2.withColumn(\"purchase\", select_features2[\"purchase\"].cast(IntegerType()))\n",
    "select_features2 = select_features2.withColumn(\"item_user\", select_features2[\"item_user\"].cast(DoubleType()))\n",
    "\n",
    "select_features2.where(\"user_id=747028\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler2 = VectorAssembler(inputCols=[\"item_id\", \"user_id\",\"item_user\", \"one_hot_user_id_solvency\", \"one_hot_item_id_popularity\",\"all_genres_vectors\",\"genre_vector\"],outputCol=\"features\") # \"all_genres_vectors\",\n",
    "output2 = assembler2.transform(select_features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model.transform(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- one_hot_user_id_solvency: double (nullable = true)\n",
      " |-- one_hot_item_id_popularity: double (nullable = true)\n",
      " |-- all_genres_vectors: vector (nullable = true)\n",
      " |-- genre_vector: vector (nullable = true)\n",
      " |-- purchase: integer (nullable = true)\n",
      " |-- item_user: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "predictions2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "predictions2 = predictions2.withColumn(\"probability\", predictions2[\"probability\"].cast(\"string\"))    # First conversion this column data format\n",
    "predictions2 = predictions2.withColumn('probabilityre',f.split(regexp_replace(\"probability\", \"^\\[|\\]\", \"\"), \",\")[1].cast('double'))\\\n",
    "                                             .select('user_id','item_id','probabilityre')\\\n",
    "                                             .withColumnRenamed(\"probabilityre\",\"probability\")   # Extract String Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+\n",
      "|user_id|item_id|         probability|\n",
      "+-------+-------+--------------------+\n",
      "|   1654|  94814|0.043646521427027074|\n",
      "|   1654|  93629| 0.04364652142697256|\n",
      "|   1654|   9980| 0.04364652142695613|\n",
      "|   1654|  95099| 0.04364652142696179|\n",
      "|   1654|  11265| 0.04364652142701164|\n",
      "|   1654|  88896| 0.04364652142697156|\n",
      "|   1654|  67740| 0.04364652142697156|\n",
      "|   1654|  74271|  0.0436465214270213|\n",
      "|   1654|  99871| 0.04364652142695591|\n",
      "|   1654|  78570| 0.04364652142697156|\n",
      "+-------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+-------+\n",
      "|user_id|item_id|         probability|row_num|\n",
      "+-------+-------+--------------------+-------+\n",
      "|   1654|  94814|0.043646521427027074|      1|\n",
      "|   1654|  93629| 0.04364652142697256|      2|\n",
      "|   1654|   9980| 0.04364652142695613|      3|\n",
      "|   1654|  95099| 0.04364652142696179|      4|\n",
      "|   1654|  11265| 0.04364652142701164|      5|\n",
      "|   1654|  88896| 0.04364652142697156|      6|\n",
      "|   1654|  67740| 0.04364652142697156|      7|\n",
      "|   1654|  74271|  0.0436465214270213|      8|\n",
      "|   1654|  99871| 0.04364652142695591|      9|\n",
      "|   1654|  78570| 0.04364652142697156|     10|\n",
      "+-------+-------+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "w = Window().orderBy('user_id')\n",
    "predictions2 = predictions2.withColumn(\"row_num\", F.row_number().over(w))\n",
    "predictions2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+--------------------+\n",
      "|row_num|user_id|item_id|         probability|\n",
      "+-------+-------+-------+--------------------+\n",
      "|      1|   1654|  94814|0.043646521427027074|\n",
      "|      2|   1654|  93629| 0.04364652142697256|\n",
      "|      3|   1654|   9980| 0.04364652142695613|\n",
      "|      4|   1654|  95099| 0.04364652142696179|\n",
      "|      5|   1654|  11265| 0.04364652142701164|\n",
      "|      6|   1654|  88896| 0.04364652142697156|\n",
      "|      7|   1654|  67740| 0.04364652142697156|\n",
      "|      8|   1654|  74271|  0.0436465214270213|\n",
      "|      9|   1654|  99871| 0.04364652142695591|\n",
      "|     10|   1654|  78570| 0.04364652142697156|\n",
      "+-------+-------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2 = predictions2.select('row_num','user_id','item_id','probability')\n",
    "predictions2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2.write.format(\"csv\").save(\"lab03.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full_features_NOT_FOUND = test_full_features_NOT_FOUND.select('user_id','item_id').repartition(1)\n",
    "test_full_features_NOT_FOUND.write.format(\"csv\").save(\"lab03_NOT_FOUND2.csv\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
