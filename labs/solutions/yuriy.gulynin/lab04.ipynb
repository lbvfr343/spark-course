{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 3 --executor-memory 3g --executor-cores 3 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as t\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, StringIndexer, IndexToString\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.sql.functions import col, desc, pandas_udf, PandasUDFType, udf, regexp_replace, when, asc, lit, broadcast\n",
    "from pyspark.sql.types import StructType, IntegerType, StructField, DateType, StringType, TimestampType, FloatType, ArrayType, LongType\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.sql.functions import struct, to_json\n",
    "from pyspark.sql.functions import shuffle, array, lit\n",
    "from pyspark.sql.functions import col, explode\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import struct, to_json\n",
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"age\", StringType()),\n",
    "    StructField(\"uid\", StringType()),\n",
    "    StructField(\"user_json\", StringType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/labs/slaba04/gender_age_dataset.txt\", header=True, schema=schema,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_visit = t.StructType([\n",
    "    t.StructField('visits', t.ArrayType(\n",
    "        t.StructType([\n",
    "        t.StructField('url', StringType(), True),\n",
    "        t.StructField('timestamp', LongType(), True)\n",
    "                      ])\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=(\n",
    "    df\n",
    "    .select('gender','age','uid', f.col('user_json').cast('string').alias('value'))\n",
    "    .select('gender','age','uid', from_json(f.col('value'), schema_visit).alias('visits'))\n",
    "    \n",
    ")\n",
    "df1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.select('gender','age','uid','visits.visits')\n",
    "df2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.select('gender','age','uid', explode(df2.visits.url).alias('url'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.withColumn('site', f.regexp_extract(df3.url, r'\\w+:\\/\\/(www\\.)?(([\\w-]+)(\\.[\\w-]+)*)\\/?', 2)).drop('url').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.groupBy(\"gender\",\"age\",\"uid\").\\\n",
    "                    agg(f.collect_list(\"site\").alias(\"site\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.filter(df.gender != '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexGender = StringIndexer(inputCol='gender', outputCol='gender_i')\n",
    "indexAge = StringIndexer(inputCol='age', outputCol='age_i')\n",
    "indexModelGender = indexGender.fit(df5)\n",
    "indexModelAge = indexAge.fit(df5)\n",
    "df_i = indexModelGender.transform(df5)\n",
    "df_i = indexModelAge.transform(df_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.where('gender=\"M\"').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(numFeatures=100000, binary=False, inputCol=\"site\", outputCol=\"site_h\")\n",
    "forestG = RandomForestClassifier(featuresCol='site_h', labelCol='gender_i', predictionCol='predictionG',\n",
    "                                 probabilityCol='probabilityG', rawPredictionCol='rawPredictionG')\n",
    "forestA = RandomForestClassifier(featuresCol='site_h', labelCol='age_i', predictionCol='predictionA',\n",
    "                                 probabilityCol='probabilityA', rawPredictionCol='rawPredictionA')\n",
    "strindG = IndexToString(inputCol='predictionG', outputCol='gender_p', labels=indexModelGender.labels)\n",
    "strindA = IndexToString(inputCol='predictionA', outputCol='age_p', labels=indexModelAge.labels)\n",
    "\n",
    "pipeline = Pipeline(stages=[   \n",
    "    hashingTF,\n",
    "    forestG,\n",
    "    forestA,\n",
    "    strindG,\n",
    "    strindA\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_i.sampleBy('gender_i', fractions={0: 0.8, 1: 0.8}, seed=42).cache()\n",
    "val = df_i.join(train, on=['uid'], how='leftanti').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipiline_model=pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=pipiline_model.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.show(2)\n",
    "valid.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"predictionG\", labelCol=\"gender_i\", metricName='areaUnderROC')\n",
    "\n",
    "evaluator.evaluate(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    if streams:\n",
    "        for s in streams:\n",
    "            desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "            s.stop()\n",
    "            print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVERS='spark-master-1.newprolab.com:6667'\n",
    "KAFKA_INPUT_TOPIC='input_yuriy.gulynin'\n",
    "KAFKA_OUTPUT_TOPIC='yuriy.gulynin'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_schema=t.StructType([   \n",
    "        t.StructField(\"uid\", t.StringType(), True),\n",
    "        t.StructField(\"visits\", t.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_schema =  t.ArrayType(\n",
    "    t.StructType([  \n",
    "        t.StructField(\"url\", StringType(), True),\n",
    "        t.StructField(\"timestamp\", LongType(), True)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_read_df = (spark\n",
    "    .readStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVERS)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    ")\n",
    "clean_df = (kafka_read_df\n",
    "    .select(f.col('value').cast('string').alias('value'))\n",
    "    .select(f.from_json(f.col('value'), event_schema).alias('event'))\n",
    "    .select('evenT.uid', f.from_json(f.col('evenT.visits'), visit_schema).alias('visits'))\n",
    "    .withColumn('url', f.col('visits.url'))\n",
    "    .drop('visits')\n",
    ")\n",
    "clean_df2=clean_df.select('uid', explode(clean_df.url).alias('url'))\n",
    "\n",
    "clean_df2=clean_df2.withColumn('site', f.regexp_extract('url', r'\\w+:\\/\\/(www\\.)?(([\\w-]+)(\\.[\\w-]+)*)\\/?', 2)).distinct().drop(\"url\")\n",
    "\n",
    "clean_df2 = clean_df2.groupBy(\"uid\").agg(f.collect_list(\"site\").alias(\"site\"))\n",
    "\n",
    "predictions_df = pipiline_model.transform(clean_df2)\n",
    "\n",
    "predictions_df=predictions_df.select('uid', f.col('gender_p').alias('gender'), f.col('age_p').alias('age'))\n",
    "\n",
    "kafka_out_df = predictions_df.select(to_json(struct(*predictions_df.columns)).alias('value'))\n",
    "\n",
    "kafka_write_stream = (\n",
    "    kafka_out_df\n",
    "    .writeStream\n",
    "    .format(\"kafka\")\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", \"tmp/lab04/checkpointLocation\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVERS)\n",
    "    .option(\"topic\", KAFKA_OUTPUT_TOPIC)\n",
    ")\n",
    "kafka_write_stream.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
