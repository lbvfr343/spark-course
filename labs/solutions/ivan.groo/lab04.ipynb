{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"]='/opt/anaconda/envs/bd9/bin/python'\n",
    "os.environ[\"SPARK_HOME\"]='/usr/hdp/current/spark2-client'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"]='--num-executors 2 --executor-memory 1g --executor-cores 1 --driver-memory 3g pyspark-shell'\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.7-src.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"local[2]\") \\\n",
    "                    .appName(\"spark-course\") \\\n",
    "                    .config(\"spark.driver.memory\", \"512m\") \\\n",
    "                    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct, to_json\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.sql.functions import shuffle, array, lit\n",
    "from pyspark.sql.functions import max, col\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, Normalizer, StopWordsRemover, StringIndexer, IndexToString\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import udf, col, isnan, isnull, broadcast, desc, lower\n",
    "from pyspark.sql.types import StructType,StructField, FloatType, ArrayType, StringType, LongType\n",
    "import json\n",
    "import re\n",
    "import pyspark.sql.functions as f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": \"spark-master-1.newprolab.com:6667\",\n",
    "    \"subscribe\": \"input_ivan.groo\"\n",
    "}\n",
    "\n",
    "df = spark.read.format(\"kafka\").options(**kafka_params).load()\n",
    "\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.select(col(\"value\").cast(\"string\"))\n",
    "test.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .load(\"/labs/slaba04/gender_age_dataset.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = StructType([ \n",
    "    StructField(\"url\",StringType(),True), \n",
    "    StructField(\"timestamp\",StringType(),True)\n",
    "\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \n",
    "    StructField(\"visits\",ArrayType(schema1),True),\n",
    "    \n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfJSON = data.withColumn(\"visits\",from_json(col(\"user_json\"),schema)) \\\n",
    "                   \n",
    "dfJSON.printSchema()\n",
    "dfJSON.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasOutputCol\n",
    "from pyspark.ml.param.shared import HasInputCol\n",
    "from pyspark import keyword_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTransformer(Transformer, HasInputCol, HasOutputCol):\n",
    "\n",
    "            \n",
    "    def _transform(self, dataset):\n",
    "        return dataset.select(col(\"gender\"), col(\"age\"), col(\"uid\"),col(\"visits.*\")).filter(\"gender == 'M' or gender == 'F'\").filter(\"age == '18-24' or age == '25-34' or age == '35-44' or age == '45-54' or age == '>=55'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ClearTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transformer.transform(dfJSON)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp=df.withColumn('exploded', f.explode(col(\"visits\")))\n",
    "df_exp.printSchema()\n",
    "df_exp.show(5)\n",
    "df_train = df_exp.select(col(\"gender\"), col(\"age\"), col(\"uid\"),col(\"exploded.*\")).drop(\"timestamp\")\n",
    "df_train.printSchema()\n",
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = df_train.withColumn(\"url_parse\", f.expr(\"parse_url(url, 'HOST')\")) \\\n",
    "    .groupBy(\"gender\",\"age\", \"uid\") \\\n",
    "    .agg(f.collect_list('url_parse').alias(\"collect_url\")) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htf = HashingTF(inputCol=\"collect_url\", outputCol=\"tf\", numFeatures= 10000, binary = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = htf.transform(df_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.show(5, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers_age = StringIndexer(inputCol=\"age\", outputCol=\"age_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers_gender = StringIndexer(inputCol=\"gender\", outputCol=\"gender_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind = indexers_age.fit(df_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df_ind.transform(df_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ind2 = indexers_gender.fit(df_ind.transform(df_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_ind2.transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_age = RandomForestClassifier(featuresCol = 'tf', labelCol = 'age_index', predictionCol = \"age_predict\",  rawPredictionCol = \"age_rawPredictionCol\",  probabilityCol = \"age_probabilityCol\", seed=42, numTrees=40, maxDepth=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gender = RandomForestClassifier(featuresCol = 'tf', labelCol = 'gender_index', predictionCol = \"gender_predict\", rawPredictionCol = \"gender_rawPredictionCol\",  probabilityCol = \"gender_probabilityCol\", seed=42, numTrees=40, maxDepth=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfModel_age = rf_age.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel_age.numClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rfModel_gender = rf_gender.fit(predictions_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rfModel_gender.transform(df_train).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_age = rfModel_age.transform(df_train).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_age.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema1 = ArrayType(\n",
    "    StructType([ \n",
    "        StructField(\"url\",StringType(),True), \n",
    "        StructField(\"timestamp\",StringType(),True)\n",
    "        ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_test = StructType([\n",
    "    StructField(\"uid\",StringType(),True),\n",
    "    StructField(\"visits\",StringType(),True),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.withColumn(\"visits_col\",from_json(col(\"value\"),schema_test))\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.printSchema()\n",
    "df_test.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.select(col(\"visits_col\").uid, f.col(\"visits_col\").visits).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df_test.select(col(\"visits_col\").uid.alias(\"uid\"), f.from_json(f.col(\"visits_col\").visits, schema1).alias(\"visits\")).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_t=df6.withColumn('exploded', f.explode(col(\"visits\")))\n",
    "df_exp_t.printSchema()\n",
    "df_exp_t.show(5)\n",
    "df_test_t = df_exp_t.select(col(\"uid\"),col(\"exploded.*\")).drop(\"timestamp\")\n",
    "df_test_t.printSchema()\n",
    "df_test_t.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t1 = df_test_t.withColumn(\"url_parse\", f.expr(\"parse_url(url, 'HOST')\")) \\\n",
    "    .groupBy(\"uid\") \\\n",
    "    .agg(f.collect_list('url_parse').alias(\"collect_url\")) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tf = htf.transform(df_test_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_g = rfModel_gender.transform(test_tf).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_a = rfModel_age.transform(test_tf).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_age = IndexToString(inputCol=\"age_predict\", outputCol=\"age\", labels=df_ind.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter_gender = IndexToString(inputCol=\"gender_predict\", outputCol=\"gender\", labels=df_ind2.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_a = converter_age.transform(prediction_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_g = converter_gender.transform(prediction_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[htf, rf_age, rf_gender, converter_age, converter_gender])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"/user/ivan.groo/lab04_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import  PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelineModel.load(\"/user/ivan.groo/lab04_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(df_test_t1).select(\"uid\", \"Age\", \"gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = 'spark-node-1.newprolab.com:6667'\n",
    "KAFKA_INPUT_TOPIC = 'input_ivan.groo'\n",
    "KAFKA_OUTPUT_TOPIC = 'ivan.groo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение в статическом режиме\n",
    "\n",
    "kafka_read_df = (\n",
    "    spark.read\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    "    .cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_test = kafka_read_df.select(col(\"value\").cast(\"string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_test.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_test.show(15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_all():\n",
    "    streams = SparkSession.builder.getOrCreate().streams.active\n",
    "    if streams:\n",
    "        for s in streams:\n",
    "            desc = s.lastProgress[\"sources\"][0][\"description\"]\n",
    "            s.stop()\n",
    "            print(\"Stopped {s}\".format(s=desc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_schema = StructType([\n",
    "    StructField('uid', StringType(), True),\n",
    "    StructField('visits', StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "visit_schema = ArrayType(\n",
    "    StructType([\n",
    "        StructField('url', StringType(), True),\n",
    "        StructField('timestamp', LongType(), True)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = (\n",
    "    kafka_read_df\n",
    "    .select(f.col('value').cast('string').alias('value'))\n",
    "    .select(f.from_json(f.col('value'), event_schema).alias('event'))\n",
    "    .select(\n",
    "        'event.uid', \n",
    "        f.from_json(f.col('event.visits'), visit_schema).alias('visits')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_t=clean_df.withColumn('exploded', f.explode(col(\"visits\")))\n",
    "df_exp_t.printSchema()\n",
    "df_exp_t.show(5)\n",
    "df_test_t = df_exp_t.select(col(\"uid\"),col(\"exploded.*\")).drop(\"timestamp\")\n",
    "df_test_t.printSchema()\n",
    "df_test_t.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_t1 = df_test_t.withColumn(\"url_parse\", f.expr(\"parse_url(url, 'HOST')\")) \\\n",
    "    .groupBy(\"uid\") \\\n",
    "    .agg(f.collect_list('url_parse').alias(\"collect_url\")) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = model.transform(df_test_t1).select(\"uid\", \"gender\", \"Age\".alias('age'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оборачивание предсказания обратно в json\n",
    "\n",
    "kafka_out_df = (\n",
    "    predictions_df.select(f.to_json(f.struct(*predictions_df.columns)).alias('value')).limit(5)\n",
    ")\n",
    "\n",
    "# Запись в выходной топик в батчевом режиме\n",
    "\n",
    "(\n",
    "    kafka_out_df\n",
    "    .write\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('topic', KAFKA_OUTPUT_TOPIC)\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтение стрима\n",
    "\n",
    "kafka_stream = (\n",
    "    spark\n",
    "    .readStream\n",
    "    .format('kafka')\n",
    "    .option('kafka.bootstrap.servers', KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option('subscribe', KAFKA_INPUT_TOPIC)\n",
    "    .option('startingOffsets', 'earliest')\n",
    "    .option('failOnDataLoss', 'False')\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_s = (\n",
    "    kafka_stream\n",
    "    .select(f.col('value').cast('string').alias('value'), \"timestamp\")\n",
    "    .select(f.from_json(f.col('value'), event_schema).alias('event'), \"timestamp\")\n",
    "    .select(\n",
    "        'event.uid', \n",
    "        f.from_json(f.col('event.visits'), visit_schema).alias('visits'), \"timestamp\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_s=clean_df_s.withColumn('exploded', f.explode(col(\"visits\")))\n",
    "df_test_s = df_exp_s.select(col(\"uid\"),col(\"exploded.*\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_s1 = df_test_s.withColumn(\"url_parse\", f.expr(\"parse_url(url, 'HOST')\")) \\\n",
    "    .groupBy(\"uid\", ) \\\n",
    "    .agg(f.collect_list('url_parse').alias(\"collect_url\")\n",
    "        ) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dfs = model.transform(df_test_s1).select(\"uid\", \"gender\", col('Age').alias('age'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# предсказание и запись\n",
    "\n",
    "kafka_write_stream = (\n",
    "    predictions_dfs\n",
    "    .select(f.to_json(f.struct(*predictions_dfs.columns)).alias('value'))\n",
    "    .writeStream\n",
    "    .format(\"kafka\")\n",
    "    .outputMode(\"complete\")\n",
    "    .option(\"checkpointLocation\", \"checkpoints/checkpoints_lab04/groo\")\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVER)\n",
    "    .option(\"topic\", KAFKA_OUTPUT_TOPIC)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_w = kafka_write_stream.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_w.isActive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
